

<!DOCTYPE html>


<html lang="zh-CN" data-content_root="" >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="generator" content="Docutils 0.19: https://docutils.sourceforge.io/" />

    <title>Ray作业调度和调优 &#8212; Isaac Lab 文档</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "";
  </script>
  <!--
    this give us a css class that will be invisible only if js is disabled
  -->
  <noscript>
    <style>
      .pst-js-only { display: none !important; }

    </style>
  </noscript>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="../../_static/styles/theme.css?digest=8878045cc6db502f8baf" rel="stylesheet" />
<link href="../../_static/styles/pydata-sphinx-theme.css?digest=8878045cc6db502f8baf" rel="stylesheet" />

    <link rel="stylesheet" type="text/css" href="../../_static/pygments.css" />
    <link rel="stylesheet" href="../../_static/styles/sphinx-book-theme.css?digest=14f4ca6b54d191a8c7657f6c759bf11a5fb86285" type="text/css" />
    <link rel="stylesheet" type="text/css" href="/opt/hostedtoolcache/Python/3.13.7/x64/lib/python3.13/site-packages/sphinxcontrib/icon/node_modules/@fortawesome/fontawesome-free/css/all.min.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/custom.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/sphinx-design.4cbf315f70debaebd550c87a6162cf0f.min.css" />
  
  <!-- So that users can add custom icons -->
  <script src="../../_static/scripts/fontawesome.js?digest=8878045cc6db502f8baf"></script>
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../../_static/scripts/bootstrap.js?digest=8878045cc6db502f8baf" />
<link rel="preload" as="script" href="../../_static/scripts/pydata-sphinx-theme.js?digest=8878045cc6db502f8baf" />

    <script data-url_root="../../" id="documentation_options" src="../../_static/documentation_options.js"></script>
    <script src="../../_static/doctools.js"></script>
    <script src="../../_static/sphinx_highlight.js"></script>
    <script src="/opt/hostedtoolcache/Python/3.13.7/x64/lib/python3.13/site-packages/sphinxcontrib/icon/node_modules/@fortawesome/fontawesome-free/js/all.min.js"></script>
    <script src="../../_static/clipboard.min.js"></script>
    <script src="../../_static/copybutton.js"></script>
    <script src="../../_static/scripts/sphinx-book-theme.js?digest=5a5c038af52cf7bc1a1ec88eea08e6366ee68824"></script>
    <script src="../../_static/translations.js"></script>
    <script src="../../_static/design-tabs.js"></script>
    <script>DOCUMENTATION_OPTIONS.pagename = 'source/features/ray';</script>
    <link rel="icon" href="../../_static/favicon.ico"/>
    <link rel="index" title="索引" href="../../genindex.html" />
    <link rel="search" title="搜索" href="../../search.html" />
    <link rel="next" title="可重现性和确定性" href="reproducibility.html" />
    <link rel="prev" title="多GPU和多节点训练" href="multi_gpu.html" />
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="zh-CN"/>
  <meta name="docsearch:version" content="2.2.1" />
    <meta name="docbuild:last-update" content="2025 年 09 月 05 日"/>
  </head>
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <div id="pst-skip-link" class="skip-link d-print-none"><a href="#main-content">跳转至主要内容</a></div>
  
  <div id="pst-scroll-pixel-helper"></div>
  
  <button type="button" class="btn rounded-pill" id="pst-back-to-top">
    <i class="fa-solid fa-arrow-up"></i>回到顶部</button>

  
  <dialog id="pst-search-dialog">
    
<form class="bd-search d-flex align-items-center"
      action="../../search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         placeholder="Search..."
         aria-label="Search..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form>
  </dialog>

  <div class="pst-async-banner-revealer d-none">
  <aside id="bd-header-version-warning" class="d-none d-print-none" aria-label="版本警告"></aside>
</div>

  
    <header class="bd-header navbar navbar-expand-lg bd-navbar d-print-none">
    </header>
  

  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      
      
      <dialog id="pst-primary-sidebar-modal"></dialog>
      <div id="pst-primary-sidebar" class="bd-sidebar-primary bd-sidebar">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
    
    
  </div>
  
    <div class="sidebar-primary-items__start sidebar-primary__section">
        <div class="sidebar-primary-item">

  
    
  

<a class="navbar-brand logo" href="../../index.html">
  
  
  
  
  
    
    
      
    
    
    <img src="../../_static/NVIDIA-logo-white.png" class="logo__image only-light" alt=""/>
    <img src="../../_static/NVIDIA-logo-black.png" class="logo__image only-dark pst-js-only" alt=""/>
  
  
    <p class="title logo__title">Isaac Lab 文档</p>
  
</a></div>
        <div class="sidebar-primary-item"><ul class="navbar-icon-links"
    aria-label="Quick Links">
        <li class="nav-item">
          
          
          
          
          
          
          
          
          <a href="https://github.com/isaac-sim/IsaacLab" title="GitHub" class="nav-link pst-navbar-icon" rel="noopener" target="_blank" data-bs-toggle="tooltip" data-bs-placement="bottom"><i class="fa-brands fa-square-github fa-lg" aria-hidden="true"></i>
            <span class="sr-only">GitHub</span></a>
        </li>
        <li class="nav-item">
          
          
          
          
          
          
          
          
          <a href="https://developer.nvidia.com/isaac-sim" title="Isaac Sim" class="nav-link pst-navbar-icon" rel="noopener" target="_blank" data-bs-toggle="tooltip" data-bs-placement="bottom"><img src="https://img.shields.io/badge/IsaacSim-5.0.0-silver.svg" class="icon-link-image" alt="Isaac Sim"/></a>
        </li>
        <li class="nav-item">
          
          
          
          
          
          
          
          
          <a href="https://img.shields.io/github/stars/isaac-sim/IsaacLab?color=fedcba" title="Stars" class="nav-link pst-navbar-icon" rel="noopener" target="_blank" data-bs-toggle="tooltip" data-bs-placement="bottom"><img src="https://img.shields.io/github/stars/isaac-sim/IsaacLab?color=fedcba" class="icon-link-image" alt="Stars"/></a>
        </li>
</ul></div>
        <div class="sidebar-primary-item">
<form class="bd-search d-flex align-items-center"
      action="../../search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         placeholder="Search..."
         aria-label="Search..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form></div>
        <div class="sidebar-primary-item"><nav class="bd-links" id="bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item navbar-nav active">
        <p aria-level="2" class="caption" role="heading"><span class="caption-text">Isaac Lab</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../setup/translation.html">【非官方】关于翻译</a></li>
<li class="toctree-l1"><a class="reference internal" href="../setup/wechat.html">【非官方】微信交流群</a></li>
<li class="toctree-l1"><a class="reference internal" href="../setup/oneclick_installation.html">【非官方】一键安装脚本(pip)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../setup/ecosystem.html">Isaac Lab 生态系统</a></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../setup/installation/index.html">本地安装</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../setup/installation/pip_installation.html">Pip 安装（推荐）</a></li>
<li class="toctree-l2"><a class="reference internal" href="../setup/installation/binaries_installation.html">二进制安装</a></li>
<li class="toctree-l2"><a class="reference internal" href="../setup/installation/isaaclab_pip_installation.html">高级安装 (Isaac Lab pip)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../setup/installation/asset_caching.html">资产缓存</a></li>
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../deployment/index.html">容器部署</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../deployment/docker.html">Docker 指南</a></li>
<li class="toctree-l2"><a class="reference internal" href="../deployment/cluster.html">集群指南</a></li>
<li class="toctree-l2"><a class="reference internal" href="../deployment/cloudxr_teleoperation_cluster.html">在 Kubernetes 上部署 CloudXR 远程操作</a></li>
<li class="toctree-l2"><a class="reference internal" href="../deployment/run_docker_example.html">使用 Docker 运行示例</a></li>
</ul>
</details></li>
<li class="toctree-l1"><a class="reference internal" href="../refs/reference_architecture/index.html">参考架构</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">开始</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../setup/quickstart.html">快速入门指南</a></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../overview/own-project/index.html">建立自己的项目或任务</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../overview/own-project/template.html">创建新项目或任务</a></li>
<li class="toctree-l2"><a class="reference internal" href="../overview/own-project/project_structure.html">项目结构</a></li>
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../setup/walkthrough/index.html">演练</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../setup/walkthrough/concepts_env_design.html">环境设计背景</a></li>
<li class="toctree-l2"><a class="reference internal" href="../setup/walkthrough/api_env_design.html">类和配置</a></li>
<li class="toctree-l2"><a class="reference internal" href="../setup/walkthrough/technical_env_design.html">环境设计</a></li>
<li class="toctree-l2"><a class="reference internal" href="../setup/walkthrough/training_jetbot_gt.html">训练 Jetbot: 基准真相</a></li>
<li class="toctree-l2"><a class="reference internal" href="../setup/walkthrough/training_jetbot_reward_exploration.html">探索 RL 问题</a></li>
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../tutorials/index.html">教程</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../tutorials/00_sim/create_empty.html">创建一个空场景</a></li>
<li class="toctree-l2"><a class="reference internal" href="../tutorials/00_sim/spawn_prims.html">生成基本物体到场景中</a></li>
<li class="toctree-l2"><a class="reference internal" href="../tutorials/00_sim/launch_app.html">深入了解AppLauncher</a></li>
<li class="toctree-l2"><a class="reference internal" href="../tutorials/01_assets/add_new_robot.html">将新机器人添加到 Isaac Lab</a></li>
<li class="toctree-l2"><a class="reference internal" href="../tutorials/01_assets/run_rigid_object.html">与刚性物体交互</a></li>
<li class="toctree-l2"><a class="reference internal" href="../tutorials/01_assets/run_articulation.html">与关节交互</a></li>
<li class="toctree-l2"><a class="reference internal" href="../tutorials/01_assets/run_deformable_object.html">与可变形对象交互</a></li>
<li class="toctree-l2"><a class="reference internal" href="../tutorials/01_assets/run_surface_gripper.html">与表面夹爪互动</a></li>
<li class="toctree-l2"><a class="reference internal" href="../tutorials/02_scene/create_scene.html">使用交互式场景</a></li>
<li class="toctree-l2"><a class="reference internal" href="../tutorials/03_envs/create_manager_base_env.html">创建基于管理器的基础环境</a></li>
<li class="toctree-l2"><a class="reference internal" href="../tutorials/03_envs/create_manager_rl_env.html">创建基于管理器的强化学习环境</a></li>
<li class="toctree-l2"><a class="reference internal" href="../tutorials/03_envs/create_direct_rl_env.html">创建直接工作流RL环境</a></li>
<li class="toctree-l2"><a class="reference internal" href="../tutorials/03_envs/register_rl_env_gym.html">注册环境</a></li>
<li class="toctree-l2"><a class="reference internal" href="../tutorials/03_envs/run_rl_training.html">与 RL Agent 进行训练</a></li>
<li class="toctree-l2"><a class="reference internal" href="../tutorials/03_envs/configuring_rl_training.html">配置一个RL Agent</a></li>
<li class="toctree-l2"><a class="reference internal" href="../tutorials/03_envs/modify_direct_rl_env.html">修改现有的 Direct RL 环境</a></li>
<li class="toctree-l2"><a class="reference internal" href="../tutorials/03_envs/policy_inference_in_usd.html">USD 环境中的策略推理</a></li>
<li class="toctree-l2"><a class="reference internal" href="../tutorials/04_sensors/add_sensors_on_robot.html">向机器人添加传感器</a></li>
<li class="toctree-l2"><a class="reference internal" href="../tutorials/05_controllers/run_diff_ik.html">使用任务空间控制器</a></li>
<li class="toctree-l2"><a class="reference internal" href="../tutorials/05_controllers/run_osc.html">使用运动空间控制器</a></li>
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../how-to/index.html">操作指南</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../how-to/import_new_asset.html">导入新资产</a></li>
<li class="toctree-l2"><a class="reference internal" href="../how-to/write_articulation_cfg.html">编写资产配置</a></li>
<li class="toctree-l2"><a class="reference internal" href="../how-to/make_fixed_prim.html">使仿真中的物理基本体固定</a></li>
<li class="toctree-l2"><a class="reference internal" href="../how-to/multi_asset_spawning.html">生成多个资产</a></li>
<li class="toctree-l2"><a class="reference internal" href="../how-to/save_camera_output.html">保存渲染图像和3D重投影</a></li>
<li class="toctree-l2"><a class="reference internal" href="../how-to/estimate_how_many_cameras_can_run.html">找出你应该用多少/什么相机训练</a></li>
<li class="toctree-l2"><a class="reference internal" href="../how-to/configure_rendering.html">配置渲染设置</a></li>
<li class="toctree-l2"><a class="reference internal" href="../how-to/draw_markers.html">创建可视化标记</a></li>
<li class="toctree-l2"><a class="reference internal" href="../how-to/wrap_rl_env.html">包装环境</a></li>
<li class="toctree-l2"><a class="reference internal" href="../how-to/add_own_library.html">添加您自己的学习库</a></li>
<li class="toctree-l2"><a class="reference internal" href="../how-to/record_animation.html">录制仿真动画</a></li>
<li class="toctree-l2"><a class="reference internal" href="../how-to/record_video.html">在训练期间录制视频剪辑</a></li>
<li class="toctree-l2"><a class="reference internal" href="../how-to/curriculums.html">Curriculum 工具</a></li>
<li class="toctree-l2"><a class="reference internal" href="../how-to/master_omniverse.html">掌握机器人的 Omniverse</a></li>
<li class="toctree-l2"><a class="reference internal" href="../how-to/cloudxr_teleoperation.html">设置 CloudXR 远程操作</a></li>
<li class="toctree-l2"><a class="reference internal" href="../how-to/simulation_performance.html">仿真性能优化</a></li>
<li class="toctree-l2"><a class="reference internal" href="../how-to/optimize_stage_creation.html">优化场景创建</a></li>
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../overview/developer-guide/index.html">开发者指南</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../overview/developer-guide/vs_code.html">在使用Visual Studio Code前的设置</a></li>

<li class="toctree-l2"><a class="reference internal" href="../overview/developer-guide/repo_structure.html">存储库组织</a></li>
<li class="toctree-l2"><a class="reference internal" href="../overview/developer-guide/development.html">扩展开发</a></li>
</ul>
</details></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">概述</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1 has-children"><a class="reference internal" href="../overview/core-concepts/index.html">核心概念</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../overview/core-concepts/task_workflows.html">任务设计工作流程</a></li>
<li class="toctree-l2"><a class="reference internal" href="../overview/core-concepts/actuators.html">执行器</a></li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../overview/core-concepts/sensors/index.html">传感器</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l3"><a class="reference internal" href="../overview/core-concepts/sensors/camera.html">相机</a></li>
<li class="toctree-l3"><a class="reference internal" href="../overview/core-concepts/sensors/contact_sensor.html">接触传感器</a></li>
<li class="toctree-l3"><a class="reference internal" href="../overview/core-concepts/sensors/frame_transformer.html">坐标变换器</a></li>
<li class="toctree-l3"><a class="reference internal" href="../overview/core-concepts/sensors/imu.html">惯性测量单元 (IMU)</a></li>
<li class="toctree-l3"><a class="reference internal" href="../overview/core-concepts/sensors/ray_caster.html">射线投射器</a></li>
</ul>
</details></li>
<li class="toctree-l2"><a class="reference internal" href="../overview/core-concepts/motion_generators.html">运动生成器</a></li>
</ul>
</details></li>
<li class="toctree-l1"><a class="reference internal" href="../overview/environments.html">可用环境</a></li>

<li class="toctree-l1 has-children"><a class="reference internal" href="../overview/reinforcement-learning/index.html">强化学习</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../overview/reinforcement-learning/rl_existing_scripts.html">强化学习脚本</a></li>
<li class="toctree-l2"><a class="reference internal" href="../overview/reinforcement-learning/rl_frameworks.html">强化学习库比较</a></li>
<li class="toctree-l2"><a class="reference internal" href="../overview/reinforcement-learning/performance_benchmarks.html">性能基准</a></li>
<li class="toctree-l2"><a class="reference internal" href="../overview/reinforcement-learning/training_guide.html">调试和训练指南</a></li>
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../overview/imitation-learning/index.html">模仿学习</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../overview/imitation-learning/augmented_imitation.html">增强模仿学习</a></li>
<li class="toctree-l2"><a class="reference internal" href="../overview/imitation-learning/teleop_imitation.html">​​Isaac Lab Mimic 中的遥操作与模仿学习​</a></li>
</ul>
</details></li>
<li class="toctree-l1"><a class="reference internal" href="../overview/showroom.html">示例演示</a></li>
<li class="toctree-l1"><a class="reference internal" href="../overview/simple_agents.html">简单智能体</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">特点</span></p>
<ul class="current nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="hydra.html">Hydra 配置系统</a></li>
<li class="toctree-l1"><a class="reference internal" href="multi_gpu.html">多GPU和多节点训练</a></li>
<li class="toctree-l1"><a class="reference internal" href="../overview/core-concepts/sensors/camera.html">分块渲染</a></li>
<li class="toctree-l1 current active"><a class="current reference internal" href="#">Ray作业调度和调优</a></li>
<li class="toctree-l1"><a class="reference internal" href="reproducibility.html">可重现性和确定性</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">实验性功能</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../experimental-features/bleeding-edge.html">欢迎来到最前沿！</a></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../experimental-features/newton-physics-integration/index.html">Newton Physics集成</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../experimental-features/newton-physics-integration/installation.html">安装</a></li>
<li class="toctree-l2"><a class="reference internal" href="../experimental-features/newton-physics-integration/training-environments.html">训练环境</a></li>
<li class="toctree-l2"><a class="reference internal" href="../experimental-features/newton-physics-integration/newton-visualizer.html">Newton 可视化工具</a></li>
<li class="toctree-l2"><a class="reference internal" href="../experimental-features/newton-physics-integration/limitations-and-known-bugs.html">限制</a></li>
<li class="toctree-l2"><a class="reference internal" href="../experimental-features/newton-physics-integration/solver-transitioning.html">求解器过渡</a></li>
<li class="toctree-l2"><a class="reference internal" href="../experimental-features/newton-physics-integration/sim-to-sim.html">Sim-to-Sim 策略转移</a></li>
<li class="toctree-l2"><a class="reference internal" href="../experimental-features/newton-physics-integration/sim-to-real.html">Sim-to-Real 策略转移</a></li>
</ul>
</details></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">资源</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../setup/installation/cloud_installation.html">在云中运行Isaac Lab</a></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../policy_deployment/index.html">Isaac Lab 训练策略的仿真到现实部署</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../policy_deployment/00_hover/hover_policy.html">训练和部署 HOVER 策略</a></li>
<li class="toctree-l2"><a class="reference internal" href="../policy_deployment/01_io_descriptors/io_descriptors_101.html">IO 描述符 101</a></li>
</ul>
</details></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">迁移指南</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../migration/migrating_from_isaacgymenvs.html">从IsaacGymEnvs迁移</a></li>
<li class="toctree-l1"><a class="reference internal" href="../migration/migrating_from_omniisaacgymenvs.html">从OmniIsaacGymEnvs迁移</a></li>
<li class="toctree-l1"><a class="reference internal" href="../migration/migrating_from_orbit.html">从Orbit迁移</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">源码 API</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1 has-children"><a class="reference internal" href="../api/index.html">API参考</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../api/lab/isaaclab.app.html">isaaclab.app</a></li>
<li class="toctree-l2"><a class="reference internal" href="../api/lab/isaaclab.actuators.html">isaaclab.actuators</a></li>
<li class="toctree-l2"><a class="reference internal" href="../api/lab/isaaclab.assets.html">isaaclab.assets</a></li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../api/lab/isaaclab.controllers.html">isaaclab.controllers</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul class="simple">
</ul>
</details></li>
<li class="toctree-l2"><a class="reference internal" href="../api/lab/isaaclab.devices.html">isaaclab.devices</a></li>
<li class="toctree-l2"><a class="reference internal" href="../api/lab/isaaclab.envs.html">isaaclab.envs</a></li>
<li class="toctree-l2"><a class="reference internal" href="../api/lab/isaaclab.managers.html">isaaclab.managers</a></li>
<li class="toctree-l2"><a class="reference internal" href="../api/lab/isaaclab.markers.html">isaaclab.markers</a></li>
<li class="toctree-l2"><a class="reference internal" href="../api/lab/isaaclab.scene.html">isaaclab.scene</a></li>
<li class="toctree-l2"><a class="reference internal" href="../api/lab/isaaclab.sensors.html">isaaclab.sensors</a></li>
<li class="toctree-l2"><a class="reference internal" href="../api/lab/isaaclab.sim.html">isaaclab.sim</a></li>
<li class="toctree-l2"><a class="reference internal" href="../api/lab/isaaclab.terrains.html">isaaclab.terrains</a></li>
<li class="toctree-l2"><a class="reference internal" href="../api/lab/isaaclab.utils.html">isaaclab.utils</a></li>
<li class="toctree-l2"><a class="reference internal" href="../api/lab/isaaclab.envs.mdp.html">isaaclab.envs.mdp</a></li>
<li class="toctree-l2"><a class="reference internal" href="../api/lab/isaaclab.envs.ui.html">isaaclab.envs.ui</a></li>
<li class="toctree-l2"><a class="reference internal" href="../api/lab/isaaclab.sensors.patterns.html">isaaclab.sensors.patterns</a></li>
<li class="toctree-l2"><a class="reference internal" href="../api/lab/isaaclab.sim.converters.html">isaaclab.sim.converters</a></li>
<li class="toctree-l2"><a class="reference internal" href="../api/lab/isaaclab.sim.schemas.html">isaaclab.sim.schemas</a></li>
<li class="toctree-l2"><a class="reference internal" href="../api/lab/isaaclab.sim.spawners.html">isaaclab.sim.spawners</a></li>
<li class="toctree-l2"><a class="reference internal" href="../api/lab_rl/isaaclab_rl.html">isaaclab_rl</a></li>
<li class="toctree-l2"><a class="reference internal" href="../api/lab_mimic/isaaclab_mimic.datagen.html">isaaclab_mimic.datagen</a></li>
<li class="toctree-l2"><a class="reference internal" href="../api/lab_mimic/isaaclab_mimic.envs.html">isaaclab_mimic.envs</a></li>
<li class="toctree-l2"><a class="reference internal" href="../api/lab_tasks/isaaclab_tasks.utils.html">isaaclab_tasks.utils</a></li>
</ul>
</details></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">参考资料</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../refs/additional_resources.html">附加资源</a></li>
<li class="toctree-l1"><a class="reference internal" href="../refs/contributing.html">贡献指南</a></li>
<li class="toctree-l1"><a class="reference internal" href="../refs/troubleshooting.html">技巧和故障排除</a></li>
<li class="toctree-l1"><a class="reference internal" href="../refs/migration.html">迁移指南（Isaac Sim）</a></li>
<li class="toctree-l1"><a class="reference internal" href="../refs/issues.html">已知问题</a></li>
<li class="toctree-l1"><a class="reference internal" href="../refs/release_notes.html">发行说明</a></li>
<li class="toctree-l1"><a class="reference internal" href="../refs/changelog.html">扩展更新日志</a></li>
<li class="toctree-l1"><a class="reference internal" href="../refs/license.html">许可证</a></li>
<li class="toctree-l1"><a class="reference internal" href="../refs/bibliography.html">参考资料</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">项目链接</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference external" href="https://github.com/isaac-sim/IsaacLab">GitHub</a></li>
<li class="toctree-l1"><a class="reference external" href="https://docs.isaacsim.omniverse.nvidia.com/latest/index.html">NVIDIA Isaac Sim</a></li>
<li class="toctree-l1"><a class="reference external" href="https://nvidia-omniverse.github.io/PhysX/physx/5.4.1/index.html">NVIDIA PhysX</a></li>
</ul>

    </div>
</nav></div>
    </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
      <div class="sidebar-primary-item">
<div id="ethical-ad-placement"
      class="flat"
      data-ea-publisher="readthedocs"
      data-ea-type="readthedocs-sidebar"
      data-ea-manual="true">
</div></div>
  </div>


      </div>
      
      <main id="main-content" class="bd-main" role="main">
        
        

<div class="sbt-scroll-pixel-helper"></div>

          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article d-print-none">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item"><label class="sidebar-toggle primary-toggle btn btn-sm" for="__primary" title="Toggle primary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
  <span class="fa-solid fa-bars"></span>
</label></div>
      
    </div>
  
  
    <div class="header-article-items__end">
      
        <div class="header-article-item">

<div class="article-header-buttons">





<div class="dropdown dropdown-source-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Source repositories">
    <i class="fab fa-github"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="https://github.com/isaac-sim/IsaacLab" target="_blank"
   class="btn btn-sm btn-source-repository-button dropdown-item"
   title="源码库"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fab fa-github"></i>
  </span>
<span class="btn__text-container">Repository</span>
</a>
</li>
      
      
      
      
      <li><a href="https://github.com/isaac-sim/IsaacLab/edit/main/docs/source/features/ray.rst" target="_blank"
   class="btn btn-sm btn-source-edit-button dropdown-item"
   title="Suggest edit"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-pencil-alt"></i>
  </span>
<span class="btn__text-container">Suggest edit</span>
</a>
</li>
      
      
      
      
      <li><a href="https://github.com/isaac-sim/IsaacLab/issues/new?title=Issue%20on%20page%20%2Fsource/features/ray.html&body=Your%20issue%20content%20here." target="_blank"
   class="btn btn-sm btn-source-issues-button dropdown-item"
   title="创建议题"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-lightbulb"></i>
  </span>
<span class="btn__text-container">Open issue</span>
</a>
</li>
      
  </ul>
</div>






<div class="dropdown dropdown-download-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="下载此页面">
    <i class="fas fa-download"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="../../_sources/source/features/ray.rst" target="_blank"
   class="btn btn-sm btn-download-source-button dropdown-item"
   title="下载源文件"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="btn__text-container">.rst</span>
</a>
</li>
      
      
      
      
      <li>
<button onclick="window.print()"
  class="btn btn-sm btn-download-pdf-button dropdown-item"
  title="列印成 PDF"
  data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="btn__text-container">.pdf</span>
</button>
</li>
      
  </ul>
</div>




<button onclick="toggleFullScreen()"
  class="btn btn-sm btn-fullscreen-button"
  title="全屏模式"
  data-bs-placement="bottom" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>



<button class="btn btn-sm nav-link pst-navbar-icon theme-switch-button pst-js-only" aria-label="Color mode" data-bs-title="Color mode"  data-bs-placement="bottom" data-bs-toggle="tooltip">
  <i class="theme-switch fa-solid fa-sun                fa-lg" data-mode="light" title="亮色"></i>
  <i class="theme-switch fa-solid fa-moon               fa-lg" data-mode="dark"  title="暗色"></i>
  <i class="theme-switch fa-solid fa-circle-half-stroke fa-lg" data-mode="auto"  title="System Settings"></i>
</button>


<button class="btn btn-sm pst-navbar-icon search-button search-button__button pst-js-only" title="搜索" aria-label="搜索" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass fa-lg"></i>
</button>
<label class="sidebar-toggle secondary-toggle btn btn-sm" for="__secondary"title="Toggle secondary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="fa-solid fa-list"></span>
</label>
</div></div>
      
    </div>
  
</div>
</div>
              
              

<div id="jb-print-docs-body" class="onlyprint">
    <h1>Ray作业调度和调优</h1>
    <!-- Table of contents -->
    <div id="print-main-content">
        <div id="jb-print-toc">
            
            <div>
                <h2> 目录 </h2>
            </div>
            <nav aria-label="Page">
                <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#overview">概述</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#docker-based-local-quickstart">基于 Docker 的本地快速启动</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#remote-clusters">远程集群</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#kuberay-setup">KubeRay 安装</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#ray-clusters-without-kubernetes-setup">Ray 集群（不使用 Kubernetes）安装</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#shared-steps-between-kuberay-and-pure-ray-part-i">KubeRay 和纯 Ray 之间的共享步骤 第 I 部分</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#kuberay-clusters-only">仅限KubeRay集群</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#ray-clusters-only-without-kubernetes">仅限Ray Clusters（不含Kubernetes）</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#dispatching-steps-shared-between-kuberay-and-pure-ray-part-ii">KubeRay与Pure Ray共享调度步骤 第 II 部分</a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#kubernetes-cluster-cleanup">Kubernetes集群清理</a></li>
</ul>
</li>
</ul>
</li>
</ul>
            </nav>
        </div>
    </div>
</div>

              
                
<div id="searchbox"></div>
                <article class="bd-article">
                  
  <section id="ray-job-dispatch-and-tuning">
<h1>Ray作业调度和调优<a class="headerlink" href="#ray-job-dispatch-and-tuning" title="此标题的永久链接">#</a></h1>
<p>Isaac Lab 支持 <a class="reference external" href="https://docs.ray.io/en/latest/index.html">Ray</a> ，用于简化多个训练任务的调度（包括并行和串行），以及超参数调优，适用于本地和远程配置。</p>
<p>这个 <a class="reference external" href="https://youtu.be/z7MDgSga2Ho?feature=shared">独立社区贡献的操作视频</a> 演示了本概述中介绍的 Ray 集成功能的一些核心内容。尽管自视频制作以来，代码库中可能存在一些差异（例如文件名被简化），但总体工作流程是相同的。</p>
<div class="admonition attention">
<p class="admonition-title">注意</p>
<p>此功能为实验性功能，仅在 Linux 上进行过测试。</p>
</div>
<section id="overview">
<h2>概述<a class="headerlink" href="#overview" title="此标题的永久链接">#</a></h2>
<p>Ray 集成对于以下内容非常有用:</p>
<ul class="simple">
<li><p>以最小的交互并行或顺序调度多个训练作业。</p></li>
<li><p>调优超参数；支持多 GPU 和/或多个 GPU 节点的并行或顺序调优。</p></li>
<li><p>在各个环境中使用相同的训练设置（云端和本地），并尽量减少开销。</p></li>
<li><p>训练任务的资源隔离（资源包装作业）。</p></li>
</ul>
<p>Ray 工作流的核心功能由两个主要脚本组成，这些脚本使得资源封装和调优聚合作业的编排成为可能。在资源封装的聚合作业中，每个子作业及其资源需求都是手动定义的，从而实现资源隔离。对于调优聚合作业，个别作业是根据超参数搜索配置自动生成的。</p>
<p>资源包装作业和调优聚合作业将单个作业调度到指定的 <cite>Ray</cite> 集群，该集群利用集群的资源（例如，单个工作站节点或多个节点）以并行和/或顺序方式执行这些作业。</p>
<p>默认情况下，作业会在每个 可用的 GPU 启用节点上为每个子作业工作者使用所有可用资源。这可以通过为资源封装作业指定 <code class="docutils literal notranslate"><span class="pre">--num_workers</span></code> 参数，或为调优作业指定 <code class="docutils literal notranslate"><span class="pre">--num_workers_per_node</span></code> 参数来更改，这对于在本地/虚拟多 GPU 机器上进行并行聚合作业处理尤其重要。调优作业假设具有 GPU 的节点具有同质的节点资源组成。</p>
<p>以下三个文件包含了 Ray 集成的核心功能。</p>
<details class="sd-sphinx-override sd-dropdown sd-card sd-mb-3">
<summary class="sd-summary-title sd-card-header">
<span class="sd-summary-icon"><svg version="1.1" width="1.0em" height="1.0em" class="sd-octicon sd-octicon-code" viewBox="0 0 16 16" aria-hidden="true"><path d="m11.28 3.22 4.25 4.25a.75.75 0 0 1 0 1.06l-4.25 4.25a.749.749 0 0 1-1.275-.326.749.749 0 0 1 .215-.734L13.94 8l-3.72-3.72a.749.749 0 0 1 .326-1.275.749.749 0 0 1 .734.215Zm-6.56 0a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042L2.06 8l3.72 3.72a.749.749 0 0 1-.326 1.275.749.749 0 0 1-.734-.215L.47 8.53a.75.75 0 0 1 0-1.06Z"></path></svg></span><span class="sd-summary-text">scripts/reinforcement_learning/ray/wrap_resources.py</span><span class="sd-summary-state-marker sd-summary-chevron-right"><svg version="1.1" width="1.5em" height="1.5em" class="sd-octicon sd-octicon-chevron-right" viewBox="0 0 24 24" aria-hidden="true"><path d="M8.72 18.78a.75.75 0 0 1 0-1.06L14.44 12 8.72 6.28a.751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018l6.25 6.25a.75.75 0 0 1 0 1.06l-6.25 6.25a.75.75 0 0 1-1.06 0Z"></path></svg></span></summary><div class="sd-summary-content sd-card-body docutils">
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># Copyright (c) 2022-2025, The Isaac Lab Project Developers (https://github.com/isaac-sim/IsaacLab/blob/main/CONTRIBUTORS.md).</span>
<span class="c1"># All rights reserved.</span>
<span class="c1">#</span>
<span class="c1"># SPDX-License-Identifier: BSD-3-Clause</span>

<span class="sd">&quot;&quot;&quot;</span>
<span class="sd">This script dispatches sub-job(s) (individual jobs, use :file:`tuner.py` for tuning jobs)</span>
<span class="sd">to worker(s) on GPU-enabled node(s) of a specific cluster as part of an resource-wrapped aggregate</span>
<span class="sd">job. If no desired compute resources for each sub-job are specified,</span>
<span class="hll"><span class="sd">this script creates one worker per available node for each node with GPU(s) in the cluster.</span>
</span><span class="hll"><span class="sd">If the desired resources for each sub-job is specified,</span>
</span><span class="hll"><span class="sd">the maximum number of workers possible with the desired resources are created for each node</span>
</span><span class="hll"><span class="sd">with GPU(s) in the cluster. It is also possible to split available node resources for each node</span>
</span><span class="hll"><span class="sd">into the desired number of workers with the ``--num_workers`` flag, to be able to easily</span>
</span><span class="hll"><span class="sd">parallelize sub-jobs on multi-GPU nodes. Due to Isaac Lab requiring a GPU,</span>
</span><span class="hll"><span class="sd">this ignores all CPU only nodes such as loggers.</span>
</span><span class="hll">
</span><span class="hll"><span class="sd">Sub-jobs are matched with node(s) in a cluster via the following relation:</span>
</span><span class="hll"><span class="sd">sorted_nodes = Node sorted by descending GPUs, then descending CPUs, then descending RAM, then node ID</span>
</span><span class="hll"><span class="sd">node_submitted_to = sorted_nodes[job_index % total_node_count]</span>
</span><span class="hll">
</span><span class="hll"><span class="sd">To check the ordering of sorted nodes, supply the ``--test`` argument and run the script.</span>
</span><span class="hll">
</span><span class="hll"><span class="sd">Sub-jobs are separated by the + delimiter. The ``--sub_jobs`` argument must be the last</span>
</span><span class="hll"><span class="sd">argument supplied to the script.</span>
</span><span class="hll">
</span><span class="hll"><span class="sd">If there is more than one available worker, and more than one sub-job,</span>
</span><span class="hll"><span class="sd">sub-jobs will be executed in parallel. If there are more sub-jobs than workers, sub-jobs will</span>
</span><span class="hll"><span class="sd">be dispatched to workers as they become available. There is no limit on the number</span>
</span><span class="hll"><span class="sd">of sub-jobs that can be near-simultaneously submitted.</span>
</span><span class="hll">
</span><span class="hll"><span class="sd">This script is meant to be executed on a Ray cluster head node as an aggregate cluster job.</span>
</span><span class="hll"><span class="sd">To submit aggregate cluster jobs such as this script to one or more remote clusters,</span>
</span><span class="hll"><span class="sd">see :file:`../submit_isaac_ray_job.py`.</span>
</span><span class="hll">
</span><span class="hll"><span class="sd">KubeRay clusters on Google GKE can be created with :file:`../launch.py`</span>
</span><span class="hll">
</span><span class="hll"><span class="sd">Usage:</span>
</span><span class="hll">
</span><span class="hll"><span class="sd">.. code-block:: bash</span>
</span><span class="hll"><span class="sd">    # **Ensure that sub-jobs are separated by the ``+`` delimiter.**</span>
</span><span class="hll"><span class="sd">    # Generic Templates-----------------------------------</span>
</span><span class="hll"><span class="sd">    ./isaaclab.sh -p scripts/reinforcement_learning/ray/wrap_resources.py -h</span>
</span><span class="hll"><span class="sd">    # No resource isolation; no parallelization:</span>
</span><span class="hll"><span class="sd">    ./isaaclab.sh -p scripts/reinforcement_learning/ray/wrap_resources.py</span>
</span><span class="hll"><span class="sd">    --sub_jobs &lt;JOB0&gt;+&lt;JOB1&gt;+&lt;JOB2&gt;</span>
</span><span class="hll"><span class="sd">    # Automatic Resource Isolation; Example A: needed for parallelization</span>
</span><span class="hll"><span class="sd">    ./isaaclab.sh -p scripts/reinforcement_learning/ray/wrap_resources.py \</span>
</span><span class="hll"><span class="sd">    --num_workers &lt;NUM_TO_DIVIDE_TOTAL_RESOURCES_BY&gt; \</span>
</span><span class="hll"><span class="sd">    --sub_jobs &lt;JOB0&gt;+&lt;JOB1&gt;</span>
</span><span class="hll"><span class="sd">    # Manual Resource Isolation; Example B:  needed for parallelization</span>
</span><span class="hll"><span class="sd">    ./isaaclab.sh -p scripts/reinforcement_learning/ray/wrap_resources.py --num_cpu_per_worker &lt;CPU&gt; \</span>
</span><span class="hll"><span class="sd">    --gpu_per_worker &lt;GPU&gt; --ram_gb_per_worker &lt;RAM&gt; --sub_jobs &lt;JOB0&gt;+&lt;JOB1&gt;</span>
</span><span class="hll"><span class="sd">    # Manual Resource Isolation; Example C: Needed for parallelization, for heterogeneous workloads</span>
</span><span class="hll"><span class="sd">    ./isaaclab.sh -p scripts/reinforcement_learning/ray/wrap_resources.py --num_cpu_per_worker &lt;CPU&gt; \</span>
</span><span class="hll"><span class="sd">    --gpu_per_worker &lt;GPU1&gt; &lt;GPU2&gt; --ram_gb_per_worker &lt;RAM&gt; --sub_jobs &lt;JOB0&gt;+&lt;JOB1&gt;</span>
</span><span class="hll"><span class="sd">    # to see all arguments</span>
</span><span class="hll"><span class="sd">    ./isaaclab.sh -p scripts/reinforcement_learning/ray/wrap_resources.py -h</span>
</span><span class="hll"><span class="sd">&quot;&quot;&quot;</span>
</span><span class="hll">
</span><span class="hll"><span class="kn">import</span><span class="w"> </span><span class="nn">argparse</span>
</span><span class="hll">
</span><span class="hll"><span class="kn">import</span><span class="w"> </span><span class="nn">util</span>
</span>

<span class="k">def</span><span class="w"> </span><span class="nf">wrap_resources_to_jobs</span><span class="p">(</span><span class="n">jobs</span><span class="p">:</span> <span class="nb">list</span><span class="p">[</span><span class="nb">str</span><span class="p">],</span> <span class="n">args</span><span class="p">:</span> <span class="n">argparse</span><span class="o">.</span><span class="n">Namespace</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Provided a list of jobs, dispatch jobs to one worker per available node,</span>
<span class="sd">    unless otherwise specified by resource constraints.</span>

<span class="sd">    Args:</span>
<span class="sd">        jobs: bash commands to execute on a Ray cluster</span>
<span class="sd">        args: The arguments for resource allocation</span>

<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">job_objs</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">util</span><span class="o">.</span><span class="n">ray_init</span><span class="p">(</span>
        <span class="n">ray_address</span><span class="o">=</span><span class="n">args</span><span class="o">.</span><span class="n">ray_address</span><span class="p">,</span>
        <span class="n">runtime_env</span><span class="o">=</span><span class="p">{</span>
            <span class="s2">&quot;py_modules&quot;</span><span class="p">:</span> <span class="kc">None</span> <span class="k">if</span> <span class="ow">not</span> <span class="n">args</span><span class="o">.</span><span class="n">py_modules</span> <span class="k">else</span> <span class="n">args</span><span class="o">.</span><span class="n">py_modules</span><span class="p">,</span>
        <span class="p">},</span>
        <span class="n">log_to_driver</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
    <span class="p">)</span>
    <span class="n">gpu_node_resources</span> <span class="o">=</span> <span class="n">util</span><span class="o">.</span><span class="n">get_gpu_node_resources</span><span class="p">(</span><span class="n">include_id</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">include_gb_ram</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

    <span class="k">if</span> <span class="nb">any</span><span class="p">([</span><span class="n">args</span><span class="o">.</span><span class="n">gpu_per_worker</span><span class="p">,</span> <span class="n">args</span><span class="o">.</span><span class="n">cpu_per_worker</span><span class="p">,</span> <span class="n">args</span><span class="o">.</span><span class="n">ram_gb_per_worker</span><span class="p">])</span> <span class="ow">and</span> <span class="n">args</span><span class="o">.</span><span class="n">num_workers</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;Either specify only num_workers or only granular resources(GPU,CPU,RAM_GB).&quot;</span><span class="p">)</span>

    <span class="n">num_nodes</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">gpu_node_resources</span><span class="p">)</span>
    <span class="c1"># Populate arguments</span>
    <span class="n">formatted_node_resources</span> <span class="o">=</span> <span class="p">{</span>
        <span class="s2">&quot;gpu_per_worker&quot;</span><span class="p">:</span> <span class="p">[</span><span class="n">gpu_node_resources</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="s2">&quot;GPU&quot;</span><span class="p">]</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">num_nodes</span><span class="p">)],</span>
        <span class="s2">&quot;cpu_per_worker&quot;</span><span class="p">:</span> <span class="p">[</span><span class="n">gpu_node_resources</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="s2">&quot;CPU&quot;</span><span class="p">]</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">num_nodes</span><span class="p">)],</span>
        <span class="s2">&quot;ram_gb_per_worker&quot;</span><span class="p">:</span> <span class="p">[</span><span class="n">gpu_node_resources</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="s2">&quot;ram_gb&quot;</span><span class="p">]</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">num_nodes</span><span class="p">)],</span>
        <span class="s2">&quot;num_workers&quot;</span><span class="p">:</span> <span class="n">args</span><span class="o">.</span><span class="n">num_workers</span><span class="p">,</span>  <span class="c1"># By default, 1 worker por node</span>
    <span class="p">}</span>
    <span class="n">args</span> <span class="o">=</span> <span class="n">util</span><span class="o">.</span><span class="n">fill_in_missing_resources</span><span class="p">(</span><span class="n">args</span><span class="p">,</span> <span class="n">resources</span><span class="o">=</span><span class="n">formatted_node_resources</span><span class="p">,</span> <span class="n">policy</span><span class="o">=</span><span class="nb">min</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;[INFO]: Number of GPU nodes found: </span><span class="si">{</span><span class="n">num_nodes</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">args</span><span class="o">.</span><span class="n">test</span><span class="p">:</span>
        <span class="n">jobs</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;nvidia-smi&quot;</span><span class="p">]</span> <span class="o">*</span> <span class="n">num_nodes</span>
    <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">job</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">jobs</span><span class="p">):</span>
        <span class="n">gpu_node</span> <span class="o">=</span> <span class="n">gpu_node_resources</span><span class="p">[</span><span class="n">i</span> <span class="o">%</span> <span class="n">num_nodes</span><span class="p">]</span>
        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;[INFO]: Creating job </span><span class="si">{</span><span class="n">i</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="mi">1</span><span class="si">}</span><span class="s2"> of </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">jobs</span><span class="p">)</span><span class="si">}</span><span class="s2"> with job &#39;</span><span class="si">{</span><span class="n">job</span><span class="si">}</span><span class="s2">&#39; to node </span><span class="si">{</span><span class="n">gpu_node</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
        <span class="nb">print</span><span class="p">(</span>
            <span class="sa">f</span><span class="s2">&quot;[INFO]: Resource parameters: GPU: </span><span class="si">{</span><span class="n">args</span><span class="o">.</span><span class="n">gpu_per_worker</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="si">}</span><span class="s2">&quot;</span>
            <span class="sa">f</span><span class="s2">&quot; CPU: </span><span class="si">{</span><span class="n">args</span><span class="o">.</span><span class="n">cpu_per_worker</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="si">}</span><span class="s2"> RAM </span><span class="si">{</span><span class="n">args</span><span class="o">.</span><span class="n">ram_gb_per_worker</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="si">}</span><span class="s2">&quot;</span>
        <span class="p">)</span>
        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;[INFO] For the node parameters, creating </span><span class="si">{</span><span class="n">args</span><span class="o">.</span><span class="n">num_workers</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="si">}</span><span class="s2"> workers&quot;</span><span class="p">)</span>
        <span class="n">num_gpus</span> <span class="o">=</span> <span class="n">args</span><span class="o">.</span><span class="n">gpu_per_worker</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">/</span> <span class="n">args</span><span class="o">.</span><span class="n">num_workers</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>
        <span class="n">num_cpus</span> <span class="o">=</span> <span class="n">args</span><span class="o">.</span><span class="n">cpu_per_worker</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">/</span> <span class="n">args</span><span class="o">.</span><span class="n">num_workers</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>
        <span class="n">memory</span> <span class="o">=</span> <span class="p">(</span><span class="n">args</span><span class="o">.</span><span class="n">ram_gb_per_worker</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">*</span> <span class="mi">1024</span><span class="o">**</span><span class="mi">3</span><span class="p">)</span> <span class="o">/</span> <span class="n">args</span><span class="o">.</span><span class="n">num_workers</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>
        <span class="n">job_objs</span><span class="o">.</span><span class="n">append</span><span class="p">(</span>
            <span class="n">util</span><span class="o">.</span><span class="n">Job</span><span class="p">(</span>
                <span class="n">cmd</span><span class="o">=</span><span class="n">job</span><span class="p">,</span>
                <span class="n">name</span><span class="o">=</span><span class="sa">f</span><span class="s2">&quot;Job-</span><span class="si">{</span><span class="n">i</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="mi">1</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">,</span>
                <span class="n">resources</span><span class="o">=</span><span class="n">util</span><span class="o">.</span><span class="n">JobResource</span><span class="p">(</span><span class="n">num_gpus</span><span class="o">=</span><span class="n">num_gpus</span><span class="p">,</span> <span class="n">num_cpus</span><span class="o">=</span><span class="n">num_cpus</span><span class="p">,</span> <span class="n">memory</span><span class="o">=</span><span class="n">memory</span><span class="p">),</span>
                <span class="n">node</span><span class="o">=</span><span class="n">util</span><span class="o">.</span><span class="n">JobNode</span><span class="p">(</span>
                    <span class="n">specific</span><span class="o">=</span><span class="s2">&quot;node_id&quot;</span><span class="p">,</span>
                    <span class="n">node_id</span><span class="o">=</span><span class="n">gpu_node</span><span class="p">[</span><span class="s2">&quot;id&quot;</span><span class="p">],</span>
                <span class="p">),</span>
            <span class="p">)</span>
        <span class="p">)</span>
    <span class="c1"># submit jobs</span>
    <span class="n">util</span><span class="o">.</span><span class="n">submit_wrapped_jobs</span><span class="p">(</span><span class="n">jobs</span><span class="o">=</span><span class="n">job_objs</span><span class="p">,</span> <span class="n">test_mode</span><span class="o">=</span><span class="n">args</span><span class="o">.</span><span class="n">test</span><span class="p">,</span> <span class="n">concurrent</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>


<span class="k">if</span> <span class="vm">__name__</span> <span class="o">==</span> <span class="s2">&quot;__main__&quot;</span><span class="p">:</span>
    <span class="n">parser</span> <span class="o">=</span> <span class="n">argparse</span><span class="o">.</span><span class="n">ArgumentParser</span><span class="p">(</span><span class="n">description</span><span class="o">=</span><span class="s2">&quot;Submit multiple jobs with optional GPU testing.&quot;</span><span class="p">)</span>
    <span class="n">parser</span> <span class="o">=</span> <span class="n">util</span><span class="o">.</span><span class="n">add_resource_arguments</span><span class="p">(</span><span class="n">arg_parser</span><span class="o">=</span><span class="n">parser</span><span class="p">)</span>
    <span class="n">parser</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span><span class="s2">&quot;--ray_address&quot;</span><span class="p">,</span> <span class="nb">type</span><span class="o">=</span><span class="nb">str</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="s2">&quot;auto&quot;</span><span class="p">,</span> <span class="n">help</span><span class="o">=</span><span class="s2">&quot;the Ray address.&quot;</span><span class="p">)</span>
    <span class="n">parser</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span>
        <span class="s2">&quot;--test&quot;</span><span class="p">,</span>
        <span class="n">action</span><span class="o">=</span><span class="s2">&quot;store_true&quot;</span><span class="p">,</span>
        <span class="n">help</span><span class="o">=</span><span class="p">(</span>
            <span class="s2">&quot;Run nvidia-smi test instead of the arbitrary job,&quot;</span>
            <span class="s2">&quot;can use as a sanity check prior to any jobs to check &quot;</span>
            <span class="s2">&quot;that GPU resources are correctly isolated.&quot;</span>
        <span class="p">),</span>
    <span class="p">)</span>
    <span class="n">parser</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span>
        <span class="s2">&quot;--py_modules&quot;</span><span class="p">,</span>
        <span class="nb">type</span><span class="o">=</span><span class="nb">str</span><span class="p">,</span>
        <span class="n">nargs</span><span class="o">=</span><span class="s2">&quot;*&quot;</span><span class="p">,</span>
        <span class="n">default</span><span class="o">=</span><span class="p">[],</span>
        <span class="n">help</span><span class="o">=</span><span class="p">(</span>
            <span class="s2">&quot;List of python modules or paths to add before running the job. Example: --py_modules my_package/my_package&quot;</span>
        <span class="p">),</span>
    <span class="p">)</span>
    <span class="n">parser</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span>
        <span class="s2">&quot;--sub_jobs&quot;</span><span class="p">,</span>
        <span class="nb">type</span><span class="o">=</span><span class="nb">str</span><span class="p">,</span>
        <span class="n">nargs</span><span class="o">=</span><span class="n">argparse</span><span class="o">.</span><span class="n">REMAINDER</span><span class="p">,</span>
        <span class="n">help</span><span class="o">=</span><span class="s2">&quot;This should be last wrapper argument. Jobs separated by the + delimiter to run on a cluster.&quot;</span><span class="p">,</span>
    <span class="p">)</span>
    <span class="n">args</span> <span class="o">=</span> <span class="n">parser</span><span class="o">.</span><span class="n">parse_args</span><span class="p">()</span>
    <span class="k">if</span> <span class="n">args</span><span class="o">.</span><span class="n">sub_jobs</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">jobs</span> <span class="o">=</span> <span class="s2">&quot; &quot;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">args</span><span class="o">.</span><span class="n">sub_jobs</span><span class="p">)</span>
        <span class="n">formatted_jobs</span> <span class="o">=</span> <span class="n">jobs</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s2">&quot;+&quot;</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">formatted_jobs</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;[INFO]: Isaac Ray Wrapper received jobs </span><span class="si">{</span><span class="n">formatted_jobs</span><span class="si">=}</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="n">wrap_resources_to_jobs</span><span class="p">(</span><span class="n">jobs</span><span class="o">=</span><span class="n">formatted_jobs</span><span class="p">,</span> <span class="n">args</span><span class="o">=</span><span class="n">args</span><span class="p">)</span>
</pre></div>
</div>
</div>
</details><details class="sd-sphinx-override sd-dropdown sd-card sd-mb-3">
<summary class="sd-summary-title sd-card-header">
<span class="sd-summary-icon"><svg version="1.1" width="1.0em" height="1.0em" class="sd-octicon sd-octicon-code" viewBox="0 0 16 16" aria-hidden="true"><path d="m11.28 3.22 4.25 4.25a.75.75 0 0 1 0 1.06l-4.25 4.25a.749.749 0 0 1-1.275-.326.749.749 0 0 1 .215-.734L13.94 8l-3.72-3.72a.749.749 0 0 1 .326-1.275.749.749 0 0 1 .734.215Zm-6.56 0a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042L2.06 8l3.72 3.72a.749.749 0 0 1-.326 1.275.749.749 0 0 1-.734-.215L.47 8.53a.75.75 0 0 1 0-1.06Z"></path></svg></span><span class="sd-summary-text">scripts/reinforcement_learning/ray/tuner.py</span><span class="sd-summary-state-marker sd-summary-chevron-right"><svg version="1.1" width="1.5em" height="1.5em" class="sd-octicon sd-octicon-chevron-right" viewBox="0 0 24 24" aria-hidden="true"><path d="M8.72 18.78a.75.75 0 0 1 0-1.06L14.44 12 8.72 6.28a.751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018l6.25 6.25a.75.75 0 0 1 0 1.06l-6.25 6.25a.75.75 0 0 1-1.06 0Z"></path></svg></span></summary><div class="sd-summary-content sd-card-body docutils">
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># Copyright (c) 2022-2025, The Isaac Lab Project Developers (https://github.com/isaac-sim/IsaacLab/blob/main/CONTRIBUTORS.md).</span>
<span class="c1"># All rights reserved.</span>
<span class="c1">#</span>
<span class="c1"># SPDX-License-Identifier: BSD-3-Clause</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">argparse</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">importlib.util</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">os</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">subprocess</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">sys</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">time</span><span class="w"> </span><span class="kn">import</span> <span class="n">sleep</span><span class="p">,</span> <span class="n">time</span>

<span class="kn">import</span><span class="w"> </span><span class="nn">ray</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">util</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">ray</span><span class="w"> </span><span class="kn">import</span> <span class="n">air</span><span class="p">,</span> <span class="n">tune</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">ray.tune.search.optuna</span><span class="w"> </span><span class="kn">import</span> <span class="n">OptunaSearch</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">ray.tune.search.repeater</span><span class="w"> </span><span class="kn">import</span> <span class="n">Repeater</span>

<span class="hll"><span class="sd">&quot;&quot;&quot;</span>
</span><span class="hll"><span class="sd">This script breaks down an aggregate tuning job, as defined by a hyperparameter sweep configuration,</span>
</span><span class="hll"><span class="sd">into individual jobs (shell commands) to run on the GPU-enabled nodes of the cluster.</span>
</span><span class="hll"><span class="sd">By default, one worker is created for each GPU-enabled node in the cluster for each individual job.</span>
</span><span class="hll"><span class="sd">To use more than one worker per node (likely the case for multi-GPU machines), supply the</span>
</span><span class="hll"><span class="sd">num_workers_per_node argument.</span>
</span><span class="hll">
</span><span class="hll"><span class="sd">Each hyperparameter sweep configuration should include the workflow,</span>
</span><span class="hll"><span class="sd">runner arguments, and hydra arguments to vary.</span>
</span><span class="hll">
</span><span class="hll"><span class="sd">This assumes that all workers in a cluster are homogeneous. For heterogeneous workloads,</span>
</span><span class="hll"><span class="sd">create several heterogeneous clusters (with homogeneous nodes in each cluster),</span>
</span><span class="hll"><span class="sd">then submit several overall-cluster jobs with :file:`../submit_job.py`.</span>
</span><span class="hll"><span class="sd">KubeRay clusters on Google GKE can be created with :file:`../launch.py`</span>
</span><span class="hll">
</span><span class="hll"><span class="sd">To report tune metrics on clusters, a running MLFlow server with a known URI that the cluster has</span>
</span><span class="hll"><span class="sd">access to is required. For KubeRay clusters configured with :file:`../launch.py`, this is included</span>
</span><span class="hll"><span class="sd">automatically, and can be easily found with with :file:`grok_cluster_with_kubectl.py`</span>
</span><span class="hll">
</span><span class="hll"><span class="sd">Usage:</span>
</span><span class="hll">
</span><span class="hll"><span class="sd">.. code-block:: bash</span>
</span><span class="hll">
</span><span class="hll"><span class="sd">    ./isaaclab.sh -p scripts/reinforcement_learning/ray/tuner.py -h</span>
</span><span class="hll">
</span><span class="hll"><span class="sd">    # Examples</span>
</span><span class="hll"><span class="sd">    # Local</span>
</span><span class="hll"><span class="sd">    ./isaaclab.sh -p scripts/reinforcement_learning/ray/tuner.py --run_mode local \</span>
</span><span class="hll"><span class="sd">    --cfg_file scripts/reinforcement_learning/ray/hyperparameter_tuning/vision_cartpole_cfg.py \</span>
</span><span class="hll"><span class="sd">    --cfg_class CartpoleTheiaJobCfg</span>
</span><span class="hll"><span class="sd">    # Remote (run grok cluster or create config file mentioned in :file:`submit_job.py`)</span>
</span><span class="hll"><span class="sd">    ./isaaclab.sh -p scripts/reinforcement_learning/ray/submit_job.py \</span>
</span><span class="hll"><span class="sd">    --aggregate_jobs tuner.py \</span>
</span><span class="hll"><span class="sd">    --cfg_file hyperparameter_tuning/vision_cartpole_cfg.py \</span>
</span><span class="hll"><span class="sd">    --cfg_class CartpoleTheiaJobCfg --mlflow_uri &lt;MLFLOW_URI_FROM_GROK_OR_MANUAL&gt;</span>
</span><span class="hll">
</span><span class="hll"><span class="sd">&quot;&quot;&quot;</span>
</span>
<span class="n">DOCKER_PREFIX</span> <span class="o">=</span> <span class="s2">&quot;/workspace/isaaclab/&quot;</span>
<span class="n">BASE_DIR</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">expanduser</span><span class="p">(</span><span class="s2">&quot;~&quot;</span><span class="p">)</span>
<span class="n">PYTHON_EXEC</span> <span class="o">=</span> <span class="s2">&quot;./isaaclab.sh -p&quot;</span>
<span class="n">WORKFLOW</span> <span class="o">=</span> <span class="s2">&quot;scripts/reinforcement_learning/rl_games/train.py&quot;</span>
<span class="n">NUM_WORKERS_PER_NODE</span> <span class="o">=</span> <span class="mi">1</span>  <span class="c1"># needed for local parallelism</span>
<span class="n">PROCESS_RESPONSE_TIMEOUT</span> <span class="o">=</span> <span class="mf">200.0</span>  <span class="c1"># seconds to wait before killing the process when it stops responding</span>
<span class="n">MAX_LINES_TO_SEARCH_EXPERIMENT_LOGS</span> <span class="o">=</span> <span class="mi">1000</span>  <span class="c1"># maximum number of lines to read from the training process logs</span>
<span class="n">MAX_LOG_EXTRACTION_ERRORS</span> <span class="o">=</span> <span class="mi">2</span>  <span class="c1"># maximum allowed LogExtractionErrors before we abort the whole training</span>


<span class="k">class</span><span class="w"> </span><span class="nc">IsaacLabTuneTrainable</span><span class="p">(</span><span class="n">tune</span><span class="o">.</span><span class="n">Trainable</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;The Isaac Lab Ray Tune Trainable.</span>
<span class="sd">    This class uses the standalone workflows to start jobs, along with the hydra integration.</span>
<span class="sd">    This class achieves Ray-based logging through reading the tensorboard logs from</span>
<span class="sd">    the standalone workflows. This depends on a config generated in the format of</span>
<span class="sd">    :class:`JobCfg`</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">setup</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">config</span><span class="p">:</span> <span class="nb">dict</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Get the invocation command, return quick for easy scheduling.&quot;&quot;&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">data</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">time_since_last_proc_response</span> <span class="o">=</span> <span class="mf">0.0</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">invoke_cmd</span> <span class="o">=</span> <span class="n">util</span><span class="o">.</span><span class="n">get_invocation_command_from_cfg</span><span class="p">(</span><span class="n">cfg</span><span class="o">=</span><span class="n">config</span><span class="p">,</span> <span class="n">python_cmd</span><span class="o">=</span><span class="n">PYTHON_EXEC</span><span class="p">,</span> <span class="n">workflow</span><span class="o">=</span><span class="n">WORKFLOW</span><span class="p">)</span>
        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;[INFO]: Recovered invocation with </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">invoke_cmd</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">experiment</span> <span class="o">=</span> <span class="kc">None</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">reset_config</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">new_config</span><span class="p">:</span> <span class="nb">dict</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Allow environments to be re-used by fetching a new invocation command&quot;&quot;&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">setup</span><span class="p">(</span><span class="n">new_config</span><span class="p">)</span>
        <span class="k">return</span> <span class="kc">True</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">step</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">dict</span><span class="p">:</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">experiment</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>  <span class="c1"># start experiment</span>
            <span class="c1"># When including this as first step instead of setup, experiments get scheduled faster</span>
            <span class="c1"># Don&#39;t want to block the scheduler while the experiment spins up</span>
            <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;[INFO]: Invoking experiment as first step with </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">invoke_cmd</span><span class="si">}</span><span class="s2">...&quot;</span><span class="p">)</span>
            <span class="k">try</span><span class="p">:</span>
                <span class="n">experiment</span> <span class="o">=</span> <span class="n">util</span><span class="o">.</span><span class="n">execute_job</span><span class="p">(</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">invoke_cmd</span><span class="p">,</span>
                    <span class="n">identifier_string</span><span class="o">=</span><span class="s2">&quot;&quot;</span><span class="p">,</span>
                    <span class="n">extract_experiment</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>  <span class="c1"># Keep this as True to return a valid dictionary</span>
                    <span class="n">persistent_dir</span><span class="o">=</span><span class="n">BASE_DIR</span><span class="p">,</span>
                    <span class="n">max_lines_to_search_logs</span><span class="o">=</span><span class="n">MAX_LINES_TO_SEARCH_EXPERIMENT_LOGS</span><span class="p">,</span>
                    <span class="n">max_time_to_search_logs</span><span class="o">=</span><span class="n">PROCESS_RESPONSE_TIMEOUT</span><span class="p">,</span>
                <span class="p">)</span>
            <span class="k">except</span> <span class="n">util</span><span class="o">.</span><span class="n">LogExtractionError</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">data</span> <span class="o">=</span> <span class="p">{</span>
                    <span class="s2">&quot;LOG_EXTRACTION_ERROR_STOPPER_FLAG&quot;</span><span class="p">:</span> <span class="kc">True</span><span class="p">,</span>
                    <span class="s2">&quot;done&quot;</span><span class="p">:</span> <span class="kc">True</span><span class="p">,</span>
                <span class="p">}</span>
                <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">data</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">experiment</span> <span class="o">=</span> <span class="n">experiment</span>
            <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;[INFO]: Tuner recovered experiment info </span><span class="si">{</span><span class="n">experiment</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">proc</span> <span class="o">=</span> <span class="n">experiment</span><span class="p">[</span><span class="s2">&quot;proc&quot;</span><span class="p">]</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">experiment_name</span> <span class="o">=</span> <span class="n">experiment</span><span class="p">[</span><span class="s2">&quot;experiment_name&quot;</span><span class="p">]</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">isaac_logdir</span> <span class="o">=</span> <span class="n">experiment</span><span class="p">[</span><span class="s2">&quot;logdir&quot;</span><span class="p">]</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">tensorboard_logdir</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">isaac_logdir</span> <span class="o">+</span> <span class="s2">&quot;/&quot;</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">experiment_name</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">done</span> <span class="o">=</span> <span class="kc">False</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">proc</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;Could not start trial.&quot;</span><span class="p">)</span>
        <span class="n">proc_status</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">proc</span><span class="o">.</span><span class="n">poll</span><span class="p">()</span>
        <span class="k">if</span> <span class="n">proc_status</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>  <span class="c1"># process finished, signal finish</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">data</span><span class="p">[</span><span class="s2">&quot;done&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="kc">True</span>
            <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;[INFO]: Process finished with </span><span class="si">{</span><span class="n">proc_status</span><span class="si">}</span><span class="s2">, returning...&quot;</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>  <span class="c1"># wait until the logs are ready or fresh</span>
            <span class="n">data</span> <span class="o">=</span> <span class="n">util</span><span class="o">.</span><span class="n">load_tensorboard_logs</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">tensorboard_logdir</span><span class="p">)</span>

            <span class="k">while</span> <span class="n">data</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
                <span class="n">data</span> <span class="o">=</span> <span class="n">util</span><span class="o">.</span><span class="n">load_tensorboard_logs</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">tensorboard_logdir</span><span class="p">)</span>
                <span class="n">proc_status</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">proc</span><span class="o">.</span><span class="n">poll</span><span class="p">()</span>
                <span class="k">if</span> <span class="n">proc_status</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                    <span class="k">break</span>
                <span class="n">sleep</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span>  <span class="c1"># Lazy report metrics to avoid performance overhead</span>

            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">data</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                <span class="n">data_</span> <span class="o">=</span> <span class="p">{</span><span class="n">k</span><span class="p">:</span> <span class="n">v</span> <span class="k">for</span> <span class="n">k</span><span class="p">,</span> <span class="n">v</span> <span class="ow">in</span> <span class="n">data</span><span class="o">.</span><span class="n">items</span><span class="p">()</span> <span class="k">if</span> <span class="n">k</span> <span class="o">!=</span> <span class="s2">&quot;done&quot;</span><span class="p">}</span>
                <span class="n">self_data_</span> <span class="o">=</span> <span class="p">{</span><span class="n">k</span><span class="p">:</span> <span class="n">v</span> <span class="k">for</span> <span class="n">k</span><span class="p">,</span> <span class="n">v</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">items</span><span class="p">()</span> <span class="k">if</span> <span class="n">k</span> <span class="o">!=</span> <span class="s2">&quot;done&quot;</span><span class="p">}</span>
                <span class="n">unresponsiveness_start_time</span> <span class="o">=</span> <span class="n">time</span><span class="p">()</span>
                <span class="k">while</span> <span class="n">util</span><span class="o">.</span><span class="n">_dicts_equal</span><span class="p">(</span><span class="n">data_</span><span class="p">,</span> <span class="n">self_data_</span><span class="p">):</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">time_since_last_proc_response</span> <span class="o">=</span> <span class="n">time</span><span class="p">()</span> <span class="o">-</span> <span class="n">unresponsiveness_start_time</span>
                    <span class="n">data</span> <span class="o">=</span> <span class="n">util</span><span class="o">.</span><span class="n">load_tensorboard_logs</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">tensorboard_logdir</span><span class="p">)</span>
                    <span class="n">data_</span> <span class="o">=</span> <span class="p">{</span><span class="n">k</span><span class="p">:</span> <span class="n">v</span> <span class="k">for</span> <span class="n">k</span><span class="p">,</span> <span class="n">v</span> <span class="ow">in</span> <span class="n">data</span><span class="o">.</span><span class="n">items</span><span class="p">()</span> <span class="k">if</span> <span class="n">k</span> <span class="o">!=</span> <span class="s2">&quot;done&quot;</span><span class="p">}</span>
                    <span class="n">proc_status</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">proc</span><span class="o">.</span><span class="n">poll</span><span class="p">()</span>
                    <span class="k">if</span> <span class="n">proc_status</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                        <span class="k">break</span>
                    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">time_since_last_proc_response</span> <span class="o">&gt;</span> <span class="n">PROCESS_RESPONSE_TIMEOUT</span><span class="p">:</span>
                        <span class="bp">self</span><span class="o">.</span><span class="n">time_since_last_proc_response</span> <span class="o">=</span> <span class="mf">0.0</span>
                        <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;[WARNING]: Training workflow process is not responding, terminating...&quot;</span><span class="p">)</span>
                        <span class="bp">self</span><span class="o">.</span><span class="n">proc</span><span class="o">.</span><span class="n">terminate</span><span class="p">()</span>
                        <span class="k">try</span><span class="p">:</span>
                            <span class="bp">self</span><span class="o">.</span><span class="n">proc</span><span class="o">.</span><span class="n">wait</span><span class="p">(</span><span class="n">timeout</span><span class="o">=</span><span class="mi">20</span><span class="p">)</span>
                        <span class="k">except</span> <span class="n">subprocess</span><span class="o">.</span><span class="n">TimeoutExpired</span><span class="p">:</span>
                            <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;[ERROR]: The process did not terminate within timeout duration.&quot;</span><span class="p">)</span>
                            <span class="bp">self</span><span class="o">.</span><span class="n">proc</span><span class="o">.</span><span class="n">kill</span><span class="p">()</span>
                            <span class="bp">self</span><span class="o">.</span><span class="n">proc</span><span class="o">.</span><span class="n">wait</span><span class="p">()</span>
                        <span class="bp">self</span><span class="o">.</span><span class="n">data</span> <span class="o">=</span> <span class="n">data</span>
                        <span class="bp">self</span><span class="o">.</span><span class="n">data</span><span class="p">[</span><span class="s2">&quot;done&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="kc">True</span>
                        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">data</span>
                    <span class="n">sleep</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span>  <span class="c1"># Lazy report metrics to avoid performance overhead</span>

            <span class="bp">self</span><span class="o">.</span><span class="n">data</span> <span class="o">=</span> <span class="n">data</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">data</span><span class="p">[</span><span class="s2">&quot;done&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="kc">False</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">data</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">default_resource_request</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;How many resources each trainable uses. Assumes homogeneous resources across gpu nodes,</span>
<span class="sd">        and that each trainable is meant for one node, where it uses all available resources.&quot;&quot;&quot;</span>
        <span class="n">resources</span> <span class="o">=</span> <span class="n">util</span><span class="o">.</span><span class="n">get_gpu_node_resources</span><span class="p">(</span><span class="n">one_node_only</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">NUM_WORKERS_PER_NODE</span> <span class="o">!=</span> <span class="mi">1</span><span class="p">:</span>
            <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;[WARNING]: Splitting node into more than one worker&quot;</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">tune</span><span class="o">.</span><span class="n">PlacementGroupFactory</span><span class="p">(</span>
            <span class="p">[{</span><span class="s2">&quot;CPU&quot;</span><span class="p">:</span> <span class="n">resources</span><span class="p">[</span><span class="s2">&quot;CPU&quot;</span><span class="p">]</span> <span class="o">/</span> <span class="n">NUM_WORKERS_PER_NODE</span><span class="p">,</span> <span class="s2">&quot;GPU&quot;</span><span class="p">:</span> <span class="n">resources</span><span class="p">[</span><span class="s2">&quot;GPU&quot;</span><span class="p">]</span> <span class="o">/</span> <span class="n">NUM_WORKERS_PER_NODE</span><span class="p">}],</span>
            <span class="n">strategy</span><span class="o">=</span><span class="s2">&quot;STRICT_PACK&quot;</span><span class="p">,</span>
        <span class="p">)</span>


<span class="k">class</span><span class="w"> </span><span class="nc">LogExtractionErrorStopper</span><span class="p">(</span><span class="n">tune</span><span class="o">.</span><span class="n">Stopper</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Stopper that stops all trials if multiple LogExtractionErrors occur.</span>

<span class="sd">    Args:</span>
<span class="sd">        max_errors: The maximum number of LogExtractionErrors allowed before terminating the experiment.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">max_errors</span><span class="p">:</span> <span class="nb">int</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">max_errors</span> <span class="o">=</span> <span class="n">max_errors</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">error_count</span> <span class="o">=</span> <span class="mi">0</span>

    <span class="k">def</span><span class="w"> </span><span class="fm">__call__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">trial_id</span><span class="p">,</span> <span class="n">result</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Increments the error count if trial has encountered a LogExtractionError.</span>

<span class="sd">        It does not stop the trial based on the metrics, always returning False.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="n">result</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;LOG_EXTRACTION_ERROR_STOPPER_FLAG&quot;</span><span class="p">,</span> <span class="kc">False</span><span class="p">):</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">error_count</span> <span class="o">+=</span> <span class="mi">1</span>
            <span class="nb">print</span><span class="p">(</span>
                <span class="sa">f</span><span class="s2">&quot;[ERROR]: Encountered LogExtractionError </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">error_count</span><span class="si">}</span><span class="s2"> times. &quot;</span>
                <span class="sa">f</span><span class="s2">&quot;Maximum allowed is </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">max_errors</span><span class="si">}</span><span class="s2">.&quot;</span>
            <span class="p">)</span>
        <span class="k">return</span> <span class="kc">False</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">stop_all</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Returns true if number of LogExtractionErrors exceeds the maximum allowed, terminating the experiment.&quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">error_count</span> <span class="o">&gt;</span> <span class="bp">self</span><span class="o">.</span><span class="n">max_errors</span><span class="p">:</span>
            <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;[FATAL]: Encountered LogExtractionError more than allowed, aborting entire tuning run... &quot;</span><span class="p">)</span>
            <span class="k">return</span> <span class="kc">True</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">return</span> <span class="kc">False</span>


<span class="k">def</span><span class="w"> </span><span class="nf">invoke_tuning_run</span><span class="p">(</span><span class="n">cfg</span><span class="p">:</span> <span class="nb">dict</span><span class="p">,</span> <span class="n">args</span><span class="p">:</span> <span class="n">argparse</span><span class="o">.</span><span class="n">Namespace</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Invoke an Isaac-Ray tuning run.</span>

<span class="sd">    Log either to a local directory or to MLFlow.</span>
<span class="sd">    Args:</span>
<span class="sd">        cfg: Configuration dictionary extracted from job setup</span>
<span class="sd">        args: Command-line arguments related to tuning.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="c1"># Allow for early exit</span>
    <span class="n">os</span><span class="o">.</span><span class="n">environ</span><span class="p">[</span><span class="s2">&quot;TUNE_DISABLE_STRICT_METRIC_CHECKING&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="s2">&quot;1&quot;</span>

    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;[WARNING]: Not saving checkpoints, just running experiment...&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;[INFO]: Model parameters and metrics will be preserved.&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;[WARNING]: For homogeneous cluster resources only...&quot;</span><span class="p">)</span>
    <span class="c1"># Get available resources</span>
    <span class="n">resources</span> <span class="o">=</span> <span class="n">util</span><span class="o">.</span><span class="n">get_gpu_node_resources</span><span class="p">()</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;[INFO]: Available resources </span><span class="si">{</span><span class="n">resources</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

    <span class="k">if</span> <span class="ow">not</span> <span class="n">ray</span><span class="o">.</span><span class="n">is_initialized</span><span class="p">():</span>
        <span class="n">ray</span><span class="o">.</span><span class="n">init</span><span class="p">(</span>
            <span class="n">address</span><span class="o">=</span><span class="n">args</span><span class="o">.</span><span class="n">ray_address</span><span class="p">,</span>
            <span class="n">log_to_driver</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
            <span class="n">num_gpus</span><span class="o">=</span><span class="nb">len</span><span class="p">(</span><span class="n">resources</span><span class="p">),</span>
        <span class="p">)</span>

    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;[INFO]: Using config </span><span class="si">{</span><span class="n">cfg</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

    <span class="c1"># Configure the search algorithm and the repeater</span>
    <span class="n">searcher</span> <span class="o">=</span> <span class="n">OptunaSearch</span><span class="p">(</span>
        <span class="n">metric</span><span class="o">=</span><span class="n">args</span><span class="o">.</span><span class="n">metric</span><span class="p">,</span>
        <span class="n">mode</span><span class="o">=</span><span class="n">args</span><span class="o">.</span><span class="n">mode</span><span class="p">,</span>
    <span class="p">)</span>
    <span class="n">repeat_search</span> <span class="o">=</span> <span class="n">Repeater</span><span class="p">(</span><span class="n">searcher</span><span class="p">,</span> <span class="n">repeat</span><span class="o">=</span><span class="n">args</span><span class="o">.</span><span class="n">repeat_run_count</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">args</span><span class="o">.</span><span class="n">run_mode</span> <span class="o">==</span> <span class="s2">&quot;local&quot;</span><span class="p">:</span>  <span class="c1"># Standard config, to file</span>
        <span class="n">run_config</span> <span class="o">=</span> <span class="n">air</span><span class="o">.</span><span class="n">RunConfig</span><span class="p">(</span>
            <span class="n">storage_path</span><span class="o">=</span><span class="s2">&quot;/tmp/ray&quot;</span><span class="p">,</span>
            <span class="n">name</span><span class="o">=</span><span class="sa">f</span><span class="s2">&quot;IsaacRay-</span><span class="si">{</span><span class="n">args</span><span class="o">.</span><span class="n">cfg_class</span><span class="si">}</span><span class="s2">-tune&quot;</span><span class="p">,</span>
            <span class="n">verbose</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
            <span class="n">checkpoint_config</span><span class="o">=</span><span class="n">air</span><span class="o">.</span><span class="n">CheckpointConfig</span><span class="p">(</span>
                <span class="n">checkpoint_frequency</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>  <span class="c1"># Disable periodic checkpointing</span>
                <span class="n">checkpoint_at_end</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>  <span class="c1"># Disable final checkpoint</span>
            <span class="p">),</span>
            <span class="n">stop</span><span class="o">=</span><span class="n">LogExtractionErrorStopper</span><span class="p">(</span><span class="n">max_errors</span><span class="o">=</span><span class="n">MAX_LOG_EXTRACTION_ERRORS</span><span class="p">),</span>
        <span class="p">)</span>

    <span class="k">elif</span> <span class="n">args</span><span class="o">.</span><span class="n">run_mode</span> <span class="o">==</span> <span class="s2">&quot;remote&quot;</span><span class="p">:</span>  <span class="c1"># MLFlow, to MLFlow server</span>
        <span class="n">mlflow_callback</span> <span class="o">=</span> <span class="n">MLflowLoggerCallback</span><span class="p">(</span>
            <span class="n">tracking_uri</span><span class="o">=</span><span class="n">args</span><span class="o">.</span><span class="n">mlflow_uri</span><span class="p">,</span>
            <span class="n">experiment_name</span><span class="o">=</span><span class="sa">f</span><span class="s2">&quot;IsaacRay-</span><span class="si">{</span><span class="n">args</span><span class="o">.</span><span class="n">cfg_class</span><span class="si">}</span><span class="s2">-tune&quot;</span><span class="p">,</span>
            <span class="n">save_artifact</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
            <span class="n">tags</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;run_mode&quot;</span><span class="p">:</span> <span class="s2">&quot;remote&quot;</span><span class="p">,</span> <span class="s2">&quot;cfg_class&quot;</span><span class="p">:</span> <span class="n">args</span><span class="o">.</span><span class="n">cfg_class</span><span class="p">},</span>
        <span class="p">)</span>

        <span class="n">run_config</span> <span class="o">=</span> <span class="n">ray</span><span class="o">.</span><span class="n">train</span><span class="o">.</span><span class="n">RunConfig</span><span class="p">(</span>
            <span class="n">name</span><span class="o">=</span><span class="s2">&quot;mlflow&quot;</span><span class="p">,</span>
            <span class="n">storage_path</span><span class="o">=</span><span class="s2">&quot;/tmp/ray&quot;</span><span class="p">,</span>
            <span class="n">callbacks</span><span class="o">=</span><span class="p">[</span><span class="n">mlflow_callback</span><span class="p">],</span>
            <span class="n">checkpoint_config</span><span class="o">=</span><span class="n">ray</span><span class="o">.</span><span class="n">train</span><span class="o">.</span><span class="n">CheckpointConfig</span><span class="p">(</span><span class="n">checkpoint_frequency</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">checkpoint_at_end</span><span class="o">=</span><span class="kc">False</span><span class="p">),</span>
            <span class="n">stop</span><span class="o">=</span><span class="n">LogExtractionErrorStopper</span><span class="p">(</span><span class="n">max_errors</span><span class="o">=</span><span class="n">MAX_LOG_EXTRACTION_ERRORS</span><span class="p">),</span>
        <span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;Unrecognized run mode.&quot;</span><span class="p">)</span>

    <span class="c1"># Configure the tuning job</span>
    <span class="n">tuner</span> <span class="o">=</span> <span class="n">tune</span><span class="o">.</span><span class="n">Tuner</span><span class="p">(</span>
        <span class="n">IsaacLabTuneTrainable</span><span class="p">,</span>
        <span class="n">param_space</span><span class="o">=</span><span class="n">cfg</span><span class="p">,</span>
        <span class="n">tune_config</span><span class="o">=</span><span class="n">tune</span><span class="o">.</span><span class="n">TuneConfig</span><span class="p">(</span>
            <span class="n">metric</span><span class="o">=</span><span class="n">args</span><span class="o">.</span><span class="n">metric</span><span class="p">,</span>
            <span class="n">mode</span><span class="o">=</span><span class="n">args</span><span class="o">.</span><span class="n">mode</span><span class="p">,</span>
            <span class="n">search_alg</span><span class="o">=</span><span class="n">repeat_search</span><span class="p">,</span>
            <span class="n">num_samples</span><span class="o">=</span><span class="n">args</span><span class="o">.</span><span class="n">num_samples</span><span class="p">,</span>
            <span class="n">reuse_actors</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
        <span class="p">),</span>
        <span class="n">run_config</span><span class="o">=</span><span class="n">run_config</span><span class="p">,</span>
    <span class="p">)</span>

    <span class="c1"># Execute the tuning</span>
    <span class="n">tuner</span><span class="o">.</span><span class="n">fit</span><span class="p">()</span>

    <span class="c1"># Save results to mounted volume</span>
    <span class="k">if</span> <span class="n">args</span><span class="o">.</span><span class="n">run_mode</span> <span class="o">==</span> <span class="s2">&quot;local&quot;</span><span class="p">:</span>
        <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;[DONE!]: Check results with tensorboard dashboard&quot;</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;[DONE!]: Check results with MLFlow dashboard&quot;</span><span class="p">)</span>


<span class="k">class</span><span class="w"> </span><span class="nc">JobCfg</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;To be compatible with :meth: invoke_tuning_run and :class:IsaacLabTuneTrainable,</span>
<span class="sd">    at a minimum, the tune job should inherit from this class.&quot;&quot;&quot;</span>

    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">cfg</span><span class="p">:</span> <span class="nb">dict</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Runner args include command line arguments passed to the task.</span>
<span class="sd">        For example:</span>
<span class="sd">        cfg[&quot;runner_args&quot;][&quot;headless_singleton&quot;] = &quot;--headless&quot;</span>
<span class="sd">        cfg[&quot;runner_args&quot;][&quot;enable_cameras_singleton&quot;] = &quot;--enable_cameras&quot;</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">assert</span> <span class="s2">&quot;runner_args&quot;</span> <span class="ow">in</span> <span class="n">cfg</span><span class="p">,</span> <span class="s2">&quot;No runner arguments specified.&quot;</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Task is the desired task to train on. For example:</span>
<span class="sd">        cfg[&quot;runner_args&quot;][&quot;--task&quot;] = tune.choice([&quot;Isaac-Cartpole-RGB-TheiaTiny-v0&quot;])</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">assert</span> <span class="s2">&quot;--task&quot;</span> <span class="ow">in</span> <span class="n">cfg</span><span class="p">[</span><span class="s2">&quot;runner_args&quot;</span><span class="p">],</span> <span class="s2">&quot;No task specified.&quot;</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Hydra args define the hyperparameters varied within the sweep. For example:</span>
<span class="sd">        cfg[&quot;hydra_args&quot;][&quot;agent.params.network.cnn.activation&quot;] = tune.choice([&quot;relu&quot;, &quot;elu&quot;])</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">assert</span> <span class="s2">&quot;hydra_args&quot;</span> <span class="ow">in</span> <span class="n">cfg</span><span class="p">,</span> <span class="s2">&quot;No hyperparameters specified.&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">cfg</span> <span class="o">=</span> <span class="n">cfg</span>


<span class="k">if</span> <span class="vm">__name__</span> <span class="o">==</span> <span class="s2">&quot;__main__&quot;</span><span class="p">:</span>
    <span class="n">parser</span> <span class="o">=</span> <span class="n">argparse</span><span class="o">.</span><span class="n">ArgumentParser</span><span class="p">(</span><span class="n">description</span><span class="o">=</span><span class="s2">&quot;Tune Isaac Lab hyperparameters.&quot;</span><span class="p">)</span>
    <span class="n">parser</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span><span class="s2">&quot;--ray_address&quot;</span><span class="p">,</span> <span class="nb">type</span><span class="o">=</span><span class="nb">str</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="s2">&quot;auto&quot;</span><span class="p">,</span> <span class="n">help</span><span class="o">=</span><span class="s2">&quot;the Ray address.&quot;</span><span class="p">)</span>
    <span class="n">parser</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span>
        <span class="s2">&quot;--cfg_file&quot;</span><span class="p">,</span>
        <span class="nb">type</span><span class="o">=</span><span class="nb">str</span><span class="p">,</span>
        <span class="n">default</span><span class="o">=</span><span class="s2">&quot;hyperparameter_tuning/vision_cartpole_cfg.py&quot;</span><span class="p">,</span>
        <span class="n">required</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
        <span class="n">help</span><span class="o">=</span><span class="s2">&quot;The relative filepath where a hyperparameter sweep is defined&quot;</span><span class="p">,</span>
    <span class="p">)</span>
    <span class="n">parser</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span>
        <span class="s2">&quot;--cfg_class&quot;</span><span class="p">,</span>
        <span class="nb">type</span><span class="o">=</span><span class="nb">str</span><span class="p">,</span>
        <span class="n">default</span><span class="o">=</span><span class="s2">&quot;CartpoleRGBNoTuneJobCfg&quot;</span><span class="p">,</span>
        <span class="n">required</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
        <span class="n">help</span><span class="o">=</span><span class="s2">&quot;Name of the hyperparameter sweep class to use&quot;</span><span class="p">,</span>
    <span class="p">)</span>
    <span class="n">parser</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span>
        <span class="s2">&quot;--run_mode&quot;</span><span class="p">,</span>
        <span class="n">choices</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;local&quot;</span><span class="p">,</span> <span class="s2">&quot;remote&quot;</span><span class="p">],</span>
        <span class="n">default</span><span class="o">=</span><span class="s2">&quot;remote&quot;</span><span class="p">,</span>
        <span class="n">help</span><span class="o">=</span><span class="p">(</span>
            <span class="s2">&quot;Set to local to use ./isaaclab.sh -p python, set to &quot;</span>
            <span class="s2">&quot;remote to use /workspace/isaaclab/isaaclab.sh -p python&quot;</span>
        <span class="p">),</span>
    <span class="p">)</span>
    <span class="n">parser</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span>
        <span class="s2">&quot;--workflow&quot;</span><span class="p">,</span>
        <span class="n">default</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>  <span class="c1"># populated with RL Games</span>
        <span class="n">help</span><span class="o">=</span><span class="s2">&quot;The absolute path of the workflow to use for the experiment. By default, RL Games is used.&quot;</span><span class="p">,</span>
    <span class="p">)</span>
    <span class="n">parser</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span>
        <span class="s2">&quot;--mlflow_uri&quot;</span><span class="p">,</span>
        <span class="nb">type</span><span class="o">=</span><span class="nb">str</span><span class="p">,</span>
        <span class="n">default</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
        <span class="n">required</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
        <span class="n">help</span><span class="o">=</span><span class="s2">&quot;The MLFlow Uri.&quot;</span><span class="p">,</span>
    <span class="p">)</span>
    <span class="n">parser</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span>
        <span class="s2">&quot;--num_workers_per_node&quot;</span><span class="p">,</span>
        <span class="nb">type</span><span class="o">=</span><span class="nb">int</span><span class="p">,</span>
        <span class="n">default</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">help</span><span class="o">=</span><span class="s2">&quot;Number of workers to run on each GPU node. Only supply for parallelism on multi-gpu nodes&quot;</span><span class="p">,</span>
    <span class="p">)</span>

    <span class="n">parser</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span><span class="s2">&quot;--metric&quot;</span><span class="p">,</span> <span class="nb">type</span><span class="o">=</span><span class="nb">str</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="s2">&quot;rewards/time&quot;</span><span class="p">,</span> <span class="n">help</span><span class="o">=</span><span class="s2">&quot;What metric to tune for.&quot;</span><span class="p">)</span>

    <span class="n">parser</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span>
        <span class="s2">&quot;--mode&quot;</span><span class="p">,</span>
        <span class="n">choices</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;max&quot;</span><span class="p">,</span> <span class="s2">&quot;min&quot;</span><span class="p">],</span>
        <span class="n">default</span><span class="o">=</span><span class="s2">&quot;max&quot;</span><span class="p">,</span>
        <span class="n">help</span><span class="o">=</span><span class="s2">&quot;What to optimize the metric to while tuning&quot;</span><span class="p">,</span>
    <span class="p">)</span>
    <span class="n">parser</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span>
        <span class="s2">&quot;--num_samples&quot;</span><span class="p">,</span>
        <span class="nb">type</span><span class="o">=</span><span class="nb">int</span><span class="p">,</span>
        <span class="n">default</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span>
        <span class="n">help</span><span class="o">=</span><span class="s2">&quot;How many hyperparameter runs to try total.&quot;</span><span class="p">,</span>
    <span class="p">)</span>
    <span class="n">parser</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span>
        <span class="s2">&quot;--repeat_run_count&quot;</span><span class="p">,</span>
        <span class="nb">type</span><span class="o">=</span><span class="nb">int</span><span class="p">,</span>
        <span class="n">default</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span>
        <span class="n">help</span><span class="o">=</span><span class="s2">&quot;How many times to repeat each hyperparameter config.&quot;</span><span class="p">,</span>
    <span class="p">)</span>
    <span class="n">parser</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span>
        <span class="s2">&quot;--process_response_timeout&quot;</span><span class="p">,</span>
        <span class="nb">type</span><span class="o">=</span><span class="nb">float</span><span class="p">,</span>
        <span class="n">default</span><span class="o">=</span><span class="n">PROCESS_RESPONSE_TIMEOUT</span><span class="p">,</span>
        <span class="n">help</span><span class="o">=</span><span class="s2">&quot;Training workflow process response timeout.&quot;</span><span class="p">,</span>
    <span class="p">)</span>
    <span class="n">parser</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span>
        <span class="s2">&quot;--max_lines_to_search_experiment_logs&quot;</span><span class="p">,</span>
        <span class="nb">type</span><span class="o">=</span><span class="nb">float</span><span class="p">,</span>
        <span class="n">default</span><span class="o">=</span><span class="n">MAX_LINES_TO_SEARCH_EXPERIMENT_LOGS</span><span class="p">,</span>
        <span class="n">help</span><span class="o">=</span><span class="s2">&quot;Max number of lines to search for experiment logs before terminating the training workflow process.&quot;</span><span class="p">,</span>
    <span class="p">)</span>
    <span class="n">parser</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span>
        <span class="s2">&quot;--max_log_extraction_errors&quot;</span><span class="p">,</span>
        <span class="nb">type</span><span class="o">=</span><span class="nb">float</span><span class="p">,</span>
        <span class="n">default</span><span class="o">=</span><span class="n">MAX_LOG_EXTRACTION_ERRORS</span><span class="p">,</span>
        <span class="n">help</span><span class="o">=</span><span class="s2">&quot;Max number number of LogExtractionError failures before we abort the whole tuning run.&quot;</span><span class="p">,</span>
    <span class="p">)</span>

    <span class="n">args</span> <span class="o">=</span> <span class="n">parser</span><span class="o">.</span><span class="n">parse_args</span><span class="p">()</span>
    <span class="n">PROCESS_RESPONSE_TIMEOUT</span> <span class="o">=</span> <span class="n">args</span><span class="o">.</span><span class="n">process_response_timeout</span>
    <span class="n">MAX_LINES_TO_SEARCH_EXPERIMENT_LOGS</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">args</span><span class="o">.</span><span class="n">max_lines_to_search_experiment_logs</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span>
        <span class="s2">&quot;[INFO]: The max number of lines to search for experiment logs before (early) terminating the training &quot;</span>
        <span class="sa">f</span><span class="s2">&quot;workflow process is set to </span><span class="si">{</span><span class="n">MAX_LINES_TO_SEARCH_EXPERIMENT_LOGS</span><span class="si">}</span><span class="s2">.</span><span class="se">\n</span><span class="s2">&quot;</span>
        <span class="s2">&quot;[INFO]: The process response timeout, used while updating tensorboard scalars and searching for &quot;</span>
        <span class="sa">f</span><span class="s2">&quot;experiment logs, is set to </span><span class="si">{</span><span class="n">PROCESS_RESPONSE_TIMEOUT</span><span class="si">}</span><span class="s2"> seconds.&quot;</span>
    <span class="p">)</span>
    <span class="n">MAX_LOG_EXTRACTION_ERRORS</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">args</span><span class="o">.</span><span class="n">max_log_extraction_errors</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span>
        <span class="s2">&quot;[INFO]: Max number of LogExtractionError failures before we abort the whole tuning run is &quot;</span>
        <span class="sa">f</span><span class="s2">&quot;set to </span><span class="si">{</span><span class="n">MAX_LOG_EXTRACTION_ERRORS</span><span class="si">}</span><span class="s2">.</span><span class="se">\n</span><span class="s2">&quot;</span>
    <span class="p">)</span>
    <span class="n">NUM_WORKERS_PER_NODE</span> <span class="o">=</span> <span class="n">args</span><span class="o">.</span><span class="n">num_workers_per_node</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;[INFO]: Using </span><span class="si">{</span><span class="n">NUM_WORKERS_PER_NODE</span><span class="si">}</span><span class="s2"> workers per node.&quot;</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">args</span><span class="o">.</span><span class="n">run_mode</span> <span class="o">==</span> <span class="s2">&quot;remote&quot;</span><span class="p">:</span>
        <span class="n">BASE_DIR</span> <span class="o">=</span> <span class="n">DOCKER_PREFIX</span>  <span class="c1"># ensure logs are dumped to persistent location</span>
        <span class="n">PYTHON_EXEC</span> <span class="o">=</span> <span class="n">DOCKER_PREFIX</span> <span class="o">+</span> <span class="n">PYTHON_EXEC</span><span class="p">[</span><span class="mi">2</span><span class="p">:]</span>
        <span class="k">if</span> <span class="n">args</span><span class="o">.</span><span class="n">workflow</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">WORKFLOW</span> <span class="o">=</span> <span class="n">DOCKER_PREFIX</span> <span class="o">+</span> <span class="n">WORKFLOW</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">WORKFLOW</span> <span class="o">=</span> <span class="n">args</span><span class="o">.</span><span class="n">workflow</span>
        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;[INFO]: Using remote mode </span><span class="si">{</span><span class="n">PYTHON_EXEC</span><span class="si">=}</span><span class="s2"> </span><span class="si">{</span><span class="n">WORKFLOW</span><span class="si">=}</span><span class="s2">&quot;</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">args</span><span class="o">.</span><span class="n">mlflow_uri</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="kn">import</span><span class="w"> </span><span class="nn">mlflow</span>

            <span class="n">mlflow</span><span class="o">.</span><span class="n">set_tracking_uri</span><span class="p">(</span><span class="n">args</span><span class="o">.</span><span class="n">mlflow_uri</span><span class="p">)</span>
            <span class="kn">from</span><span class="w"> </span><span class="nn">ray.air.integrations.mlflow</span><span class="w"> </span><span class="kn">import</span> <span class="n">MLflowLoggerCallback</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;Please provide a result MLFLow URI server.&quot;</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>  <span class="c1"># local</span>
        <span class="n">PYTHON_EXEC</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">getcwd</span><span class="p">()</span> <span class="o">+</span> <span class="s2">&quot;/&quot;</span> <span class="o">+</span> <span class="n">PYTHON_EXEC</span><span class="p">[</span><span class="mi">2</span><span class="p">:]</span>
        <span class="k">if</span> <span class="n">args</span><span class="o">.</span><span class="n">workflow</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">WORKFLOW</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">getcwd</span><span class="p">()</span> <span class="o">+</span> <span class="s2">&quot;/&quot;</span> <span class="o">+</span> <span class="n">WORKFLOW</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">WORKFLOW</span> <span class="o">=</span> <span class="n">args</span><span class="o">.</span><span class="n">workflow</span>
        <span class="n">BASE_DIR</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">getcwd</span><span class="p">()</span>
        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;[INFO]: Using local mode </span><span class="si">{</span><span class="n">PYTHON_EXEC</span><span class="si">=}</span><span class="s2"> </span><span class="si">{</span><span class="n">WORKFLOW</span><span class="si">=}</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="n">file_path</span> <span class="o">=</span> <span class="n">args</span><span class="o">.</span><span class="n">cfg_file</span>
    <span class="n">class_name</span> <span class="o">=</span> <span class="n">args</span><span class="o">.</span><span class="n">cfg_class</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;[INFO]: Attempting to use sweep config from </span><span class="si">{</span><span class="n">file_path</span><span class="si">=}</span><span class="s2"> </span><span class="si">{</span><span class="n">class_name</span><span class="si">=}</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="n">module_name</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">splitext</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">basename</span><span class="p">(</span><span class="n">file_path</span><span class="p">))[</span><span class="mi">0</span><span class="p">]</span>

    <span class="n">spec</span> <span class="o">=</span> <span class="n">importlib</span><span class="o">.</span><span class="n">util</span><span class="o">.</span><span class="n">spec_from_file_location</span><span class="p">(</span><span class="n">module_name</span><span class="p">,</span> <span class="n">file_path</span><span class="p">)</span>
    <span class="n">module</span> <span class="o">=</span> <span class="n">importlib</span><span class="o">.</span><span class="n">util</span><span class="o">.</span><span class="n">module_from_spec</span><span class="p">(</span><span class="n">spec</span><span class="p">)</span>
    <span class="n">sys</span><span class="o">.</span><span class="n">modules</span><span class="p">[</span><span class="n">module_name</span><span class="p">]</span> <span class="o">=</span> <span class="n">module</span>
    <span class="n">spec</span><span class="o">.</span><span class="n">loader</span><span class="o">.</span><span class="n">exec_module</span><span class="p">(</span><span class="n">module</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;[INFO]: Successfully imported </span><span class="si">{</span><span class="n">module_name</span><span class="si">}</span><span class="s2"> from </span><span class="si">{</span><span class="n">file_path</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">module</span><span class="p">,</span> <span class="n">class_name</span><span class="p">):</span>
        <span class="n">ClassToInstantiate</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">module</span><span class="p">,</span> <span class="n">class_name</span><span class="p">)</span>
        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;[INFO]: Found correct class </span><span class="si">{</span><span class="n">ClassToInstantiate</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
        <span class="n">instance</span> <span class="o">=</span> <span class="n">ClassToInstantiate</span><span class="p">()</span>
        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;[INFO]: Successfully instantiated class &#39;</span><span class="si">{</span><span class="n">class_name</span><span class="si">}</span><span class="s2">&#39; from </span><span class="si">{</span><span class="n">file_path</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
        <span class="n">cfg</span> <span class="o">=</span> <span class="n">instance</span><span class="o">.</span><span class="n">cfg</span>
        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;[INFO]: Grabbed the following hyperparameter sweep config: </span><span class="se">\n</span><span class="s2"> </span><span class="si">{</span><span class="n">cfg</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
        <span class="n">invoke_tuning_run</span><span class="p">(</span><span class="n">cfg</span><span class="p">,</span> <span class="n">args</span><span class="p">)</span>

    <span class="k">else</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">AttributeError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;[ERROR]:Class &#39;</span><span class="si">{</span><span class="n">class_name</span><span class="si">}</span><span class="s2">&#39; not found in </span><span class="si">{</span><span class="n">file_path</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</details><details class="sd-sphinx-override sd-dropdown sd-card sd-mb-3">
<summary class="sd-summary-title sd-card-header">
<span class="sd-summary-icon"><svg version="1.1" width="1.0em" height="1.0em" class="sd-octicon sd-octicon-code" viewBox="0 0 16 16" aria-hidden="true"><path d="m11.28 3.22 4.25 4.25a.75.75 0 0 1 0 1.06l-4.25 4.25a.749.749 0 0 1-1.275-.326.749.749 0 0 1 .215-.734L13.94 8l-3.72-3.72a.749.749 0 0 1 .326-1.275.749.749 0 0 1 .734.215Zm-6.56 0a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042L2.06 8l3.72 3.72a.749.749 0 0 1-.326 1.275.749.749 0 0 1-.734-.215L.47 8.53a.75.75 0 0 1 0-1.06Z"></path></svg></span><span class="sd-summary-text">scripts/reinforcement_learning/ray/task_runner.py</span><span class="sd-summary-state-marker sd-summary-chevron-right"><svg version="1.1" width="1.5em" height="1.5em" class="sd-octicon sd-octicon-chevron-right" viewBox="0 0 24 24" aria-hidden="true"><path d="M8.72 18.78a.75.75 0 0 1 0-1.06L14.44 12 8.72 6.28a.751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018l6.25 6.25a.75.75 0 0 1 0 1.06l-6.25 6.25a.75.75 0 0 1-1.06 0Z"></path></svg></span></summary><div class="sd-summary-content sd-card-body docutils">
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># Copyright (c) 2022-2025, The Isaac Lab Project Developers (https://github.com/isaac-sim/IsaacLab/blob/main/CONTRIBUTORS.md).</span>
<span class="c1"># All rights reserved.</span>
<span class="c1">#</span>
<span class="c1"># SPDX-License-Identifier: BSD-3-Clause</span>

<span class="sd">&quot;&quot;&quot;</span>
<span class="sd">This script dispatches one or more user-defined Python tasks to workers in a Ray cluster.</span>
<span class="sd">Each task, along with its resource requirements and execution parameters, is specified in a YAML configuration file.</span>
<span class="sd">Users may define the number of CPUs, GPUs, and the amount of memory to allocate per task via the config file.</span>

<span class="sd">Key features:</span>
<span class="sd">-------------</span>
<span class="hll"><span class="sd">- Fine-grained, per-task resource management via config fields (`num_gpus`, `num_cpus`, `memory`).</span>
</span><span class="hll"><span class="sd">- Parallel execution of multiple tasks using available resources across the Ray cluster.</span>
</span><span class="hll"><span class="sd">- Option to specify node affinity for tasks, e.g., by hostname, node ID, or any node.</span>
</span><span class="hll"><span class="sd">- Optional batch (simultaneous) or independent scheduling of tasks.</span>
</span><span class="hll">
</span><span class="hll"><span class="sd">Task scheduling and distribution are handled via Ray’s built-in resource manager.</span>
</span><span class="hll">
</span><span class="hll"><span class="sd">YAML configuration fields:</span>
</span><span class="hll"><span class="sd">--------------------------</span>
</span><span class="hll"><span class="sd">- `pip`: List of extra pip packages to install before running any tasks.</span>
</span><span class="hll"><span class="sd">- `py_modules`: List of additional Python module paths (directories or files) to include in the runtime environment.</span>
</span><span class="hll"><span class="sd">- `concurrent`: (bool) It determines task dispatch semantics:</span>
</span><span class="hll"><span class="sd">    - If `concurrent: true`, **all tasks are scheduled as a batch**. The script waits until sufficient resources are available for every task in the batch, then launches all tasks together. If resources are insufficient, all tasks remain blocked until the cluster can support the full batch.</span>
</span><span class="hll"><span class="sd">    - If `concurrent: false`, tasks are launched as soon as resources are available for each individual task, and Ray independently schedules them. This may result in non-simultaneous task start times.</span>
</span><span class="hll"><span class="sd">- `tasks`: List of task specifications, each with:</span>
</span><span class="hll"><span class="sd">    - `name`: String identifier for the task.</span>
</span><span class="hll"><span class="sd">    - `py_args`: Arguments to the Python interpreter (e.g., script/module, flags, user arguments).</span>
</span><span class="hll"><span class="sd">    - `num_gpus`: Number of GPUs to allocate (float or string arithmetic, e.g., &quot;2*2&quot;).</span>
</span><span class="hll"><span class="sd">    - `num_cpus`: Number of CPUs to allocate (float or string).</span>
</span><span class="hll"><span class="sd">    - `memory`: Amount of RAM in bytes (int or string).</span>
</span><span class="hll"><span class="sd">    - `node` (optional): Node placement constraints.</span>
</span><span class="hll"><span class="sd">        - `specific` (str): Type of node placement, support `hostname`, `node_id`, or `any`.</span>
</span><span class="hll"><span class="sd">            - `any`: Place the task on any available node.</span>
</span><span class="hll"><span class="sd">            - `hostname`: Place the task on a specific hostname. `hostname` must be specified in the node field.</span>
</span><span class="hll"><span class="sd">            - `node_id`: Place the task on a specific node ID. `node_id` must be specified in the node field.</span>
</span><span class="hll"><span class="sd">        - `hostname` (str): Specific hostname to place the task on.</span>
</span><span class="hll"><span class="sd">        - `node_id` (str): Specific node ID to place the task on.</span>
</span><span class="hll">
</span><span class="hll">
</span><span class="hll"><span class="sd">Typical usage:</span>
</span><span class="hll"><span class="sd">---------------</span>
</span><span class="hll">
</span><span class="hll"><span class="sd">.. code-block:: bash</span>
</span><span class="hll">
</span><span class="hll"><span class="sd">    # Print help and argument details:</span>
</span><span class="hll"><span class="sd">    python task_runner.py -h</span>
</span><span class="hll">
</span><span class="hll"><span class="sd">    # Submit tasks defined in a YAML file to the Ray cluster (auto-detects Ray head address):</span>
</span><span class="hll"><span class="sd">    python task_runner.py --task_cfg /path/to/tasks.yaml</span>
</span><span class="hll">
</span><span class="hll"><span class="sd">YAML configuration example-1:</span>
</span><span class="hll"><span class="sd">---------------------------</span>
</span><span class="hll"><span class="sd">.. code-block:: yaml</span>
</span><span class="hll">
</span><span class="hll"><span class="sd">    pip: [&quot;xxx&quot;]</span>
</span><span class="hll"><span class="sd">    py_modules: [&quot;my_package/my_package&quot;]</span>
</span><span class="hll"><span class="sd">    concurrent: false</span>
</span><span class="hll"><span class="sd">    tasks:</span>
</span><span class="hll"><span class="sd">      - name: &quot;Isaac-Cartpole-v0&quot;</span>
</span><span class="hll"><span class="sd">        py_args: &quot;-m torch.distributed.run --nnodes=1 --nproc_per_node=2  --rdzv_endpoint=localhost:29501 /workspace/isaaclab/scripts/reinforcement_learning/rsl_rl/train.py --task=Isaac-Cartpole-v0 --max_iterations 200 --headless --distributed&quot;</span>
</span><span class="hll"><span class="sd">        num_gpus: 2</span>
</span><span class="hll"><span class="sd">        num_cpus: 10</span>
</span><span class="hll"><span class="sd">        memory: 10737418240</span>
</span><span class="hll"><span class="sd">      - name: &quot;script need some dependencies&quot;</span>
</span><span class="hll"><span class="sd">        py_args: &quot;script.py --option arg&quot;</span>
</span><span class="hll"><span class="sd">        num_gpus: 0</span>
</span><span class="hll"><span class="sd">        num_cpus: 1</span>
</span><span class="hll"><span class="sd">        memory: 10*1024*1024*1024</span>
</span><span class="hll">
</span><span class="hll"><span class="sd">YAML configuration example-2:</span>
</span><span class="hll"><span class="sd">---------------------------</span>
</span><span class="hll"><span class="sd">.. code-block:: yaml</span>
</span><span class="hll">
</span><span class="hll"><span class="sd">    pip: [&quot;xxx&quot;]</span>
</span><span class="hll"><span class="sd">    py_modules: [&quot;my_package/my_package&quot;]</span>
</span><span class="hll"><span class="sd">    concurrent: true</span>
</span><span class="hll"><span class="sd">    tasks:</span>
</span><span class="hll"><span class="sd">    - name: &quot;Isaac-Cartpole-v0-multi-node-train-1&quot;</span>
</span><span class="hll"><span class="sd">        py_args: &quot;-m torch.distributed.run --nproc_per_node=1 --nnodes=2 --node_rank=0 --rdzv_id=123 --rdzv_backend=c10d --rdzv_endpoint=localhost:5555 /workspace/isaaclab/scripts/reinforcement_learning/rsl_rl/train.py --task=Isaac-Cartpole-v0 --headless --distributed --max_iterations 1000&quot;</span>
</span><span class="hll"><span class="sd">        num_gpus: 1</span>
</span><span class="hll"><span class="sd">        num_cpus: 10</span>
</span><span class="hll"><span class="sd">        memory: 10*1024*1024*1024</span>
</span><span class="hll"><span class="sd">        node:</span>
</span><span class="hll"><span class="sd">          specific: &quot;hostname&quot;</span>
</span><span class="hll"><span class="sd">          hostname: &quot;xxx&quot;</span>
</span><span class="hll"><span class="sd">    - name: &quot;Isaac-Cartpole-v0-multi-node-train-2&quot;</span>
</span><span class="hll"><span class="sd">        py_args: &quot;-m torch.distributed.run --nproc_per_node=1 --nnodes=2 --node_rank=1 --rdzv_id=123 --rdzv_backend=c10d --rdzv_endpoint=x.x.x.x:5555 /workspace/isaaclab/scripts/reinforcement_learning/rsl_rl/train.py --task=Isaac-Cartpole-v0 --headless --distributed --max_iterations 1000&quot;</span>
</span><span class="hll"><span class="sd">        num_gpus: 1</span>
</span><span class="hll"><span class="sd">        num_cpus: 10</span>
</span><span class="hll"><span class="sd">        memory: 10*1024*1024*1024</span>
</span><span class="hll"><span class="sd">        node:</span>
</span><span class="hll"><span class="sd">          specific: &quot;hostname&quot;</span>
</span><span class="hll"><span class="sd">          hostname: &quot;xxx&quot;</span>
</span><span class="hll">
</span><span class="hll"><span class="sd">To stop all tasks early, press Ctrl+C; the script will cancel all running Ray tasks.</span>
</span><span class="hll"><span class="sd">&quot;&quot;&quot;</span>
</span><span class="hll">
</span><span class="hll"><span class="kn">import</span><span class="w"> </span><span class="nn">argparse</span>
</span><span class="hll"><span class="kn">import</span><span class="w"> </span><span class="nn">yaml</span>
</span><span class="hll"><span class="kn">from</span><span class="w"> </span><span class="nn">datetime</span><span class="w"> </span><span class="kn">import</span> <span class="n">datetime</span>
</span><span class="hll">
</span><span class="hll"><span class="kn">import</span><span class="w"> </span><span class="nn">util</span>
</span><span class="hll">
</span>
<span class="k">def</span><span class="w"> </span><span class="nf">parse_args</span><span class="p">()</span> <span class="o">-&gt;</span> <span class="n">argparse</span><span class="o">.</span><span class="n">Namespace</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Parse command-line arguments for the Ray task runner.</span>

<span class="sd">    Returns:</span>
<span class="sd">        argparse.Namespace: The namespace containing parsed CLI arguments:</span>
<span class="sd">            - task_cfg (str): Path to the YAML task file.</span>
<span class="sd">            - ray_address (str): Ray cluster address.</span>
<span class="sd">            - test (bool): Whether to run a GPU resource isolation sanity check.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">parser</span> <span class="o">=</span> <span class="n">argparse</span><span class="o">.</span><span class="n">ArgumentParser</span><span class="p">(</span><span class="n">description</span><span class="o">=</span><span class="s2">&quot;Run tasks from a YAML config file.&quot;</span><span class="p">)</span>
    <span class="n">parser</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span><span class="s2">&quot;--task_cfg&quot;</span><span class="p">,</span> <span class="nb">type</span><span class="o">=</span><span class="nb">str</span><span class="p">,</span> <span class="n">required</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">help</span><span class="o">=</span><span class="s2">&quot;Path to the YAML task file.&quot;</span><span class="p">)</span>
    <span class="n">parser</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span><span class="s2">&quot;--ray_address&quot;</span><span class="p">,</span> <span class="nb">type</span><span class="o">=</span><span class="nb">str</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="s2">&quot;auto&quot;</span><span class="p">,</span> <span class="n">help</span><span class="o">=</span><span class="s2">&quot;the Ray address.&quot;</span><span class="p">)</span>
    <span class="n">parser</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span>
        <span class="s2">&quot;--test&quot;</span><span class="p">,</span>
        <span class="n">action</span><span class="o">=</span><span class="s2">&quot;store_true&quot;</span><span class="p">,</span>
        <span class="n">help</span><span class="o">=</span><span class="p">(</span>
            <span class="s2">&quot;Run nvidia-smi test instead of the arbitrary job,&quot;</span>
            <span class="s2">&quot;can use as a sanity check prior to any jobs to check &quot;</span>
            <span class="s2">&quot;that GPU resources are correctly isolated.&quot;</span>
        <span class="p">),</span>
    <span class="p">)</span>
    <span class="k">return</span> <span class="n">parser</span><span class="o">.</span><span class="n">parse_args</span><span class="p">()</span>


<span class="k">def</span><span class="w"> </span><span class="nf">parse_task_resource</span><span class="p">(</span><span class="n">task</span><span class="p">:</span> <span class="nb">dict</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">util</span><span class="o">.</span><span class="n">JobResource</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Parse task resource requirements from the YAML configuration.</span>

<span class="sd">    Args:</span>
<span class="sd">        task (dict): Dictionary representing a single task&#39;s configuration.</span>
<span class="sd">            Keys may include `num_gpus`, `num_cpus`, and `memory`, each either</span>
<span class="sd">            as a number or evaluatable string expression.</span>

<span class="sd">    Returns:</span>
<span class="sd">        util.JobResource: Resource object with the parsed values.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">resource</span> <span class="o">=</span> <span class="n">util</span><span class="o">.</span><span class="n">JobResource</span><span class="p">()</span>
    <span class="k">if</span> <span class="s2">&quot;num_gpus&quot;</span> <span class="ow">in</span> <span class="n">task</span><span class="p">:</span>
        <span class="n">resource</span><span class="o">.</span><span class="n">num_gpus</span> <span class="o">=</span> <span class="nb">eval</span><span class="p">(</span><span class="n">task</span><span class="p">[</span><span class="s2">&quot;num_gpus&quot;</span><span class="p">])</span> <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">task</span><span class="p">[</span><span class="s2">&quot;num_gpus&quot;</span><span class="p">],</span> <span class="nb">str</span><span class="p">)</span> <span class="k">else</span> <span class="n">task</span><span class="p">[</span><span class="s2">&quot;num_gpus&quot;</span><span class="p">]</span>
    <span class="k">if</span> <span class="s2">&quot;num_cpus&quot;</span> <span class="ow">in</span> <span class="n">task</span><span class="p">:</span>
        <span class="n">resource</span><span class="o">.</span><span class="n">num_cpus</span> <span class="o">=</span> <span class="nb">eval</span><span class="p">(</span><span class="n">task</span><span class="p">[</span><span class="s2">&quot;num_cpus&quot;</span><span class="p">])</span> <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">task</span><span class="p">[</span><span class="s2">&quot;num_cpus&quot;</span><span class="p">],</span> <span class="nb">str</span><span class="p">)</span> <span class="k">else</span> <span class="n">task</span><span class="p">[</span><span class="s2">&quot;num_cpus&quot;</span><span class="p">]</span>
    <span class="k">if</span> <span class="s2">&quot;memory&quot;</span> <span class="ow">in</span> <span class="n">task</span><span class="p">:</span>
        <span class="n">resource</span><span class="o">.</span><span class="n">memory</span> <span class="o">=</span> <span class="nb">eval</span><span class="p">(</span><span class="n">task</span><span class="p">[</span><span class="s2">&quot;memory&quot;</span><span class="p">])</span> <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">task</span><span class="p">[</span><span class="s2">&quot;memory&quot;</span><span class="p">],</span> <span class="nb">str</span><span class="p">)</span> <span class="k">else</span> <span class="n">task</span><span class="p">[</span><span class="s2">&quot;memory&quot;</span><span class="p">]</span>
    <span class="k">return</span> <span class="n">resource</span>


<span class="k">def</span><span class="w"> </span><span class="nf">run_tasks</span><span class="p">(</span>
    <span class="n">tasks</span><span class="p">:</span> <span class="nb">list</span><span class="p">[</span><span class="nb">dict</span><span class="p">],</span> <span class="n">args</span><span class="p">:</span> <span class="n">argparse</span><span class="o">.</span><span class="n">Namespace</span><span class="p">,</span> <span class="n">runtime_env</span><span class="p">:</span> <span class="nb">dict</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span> <span class="n">concurrent</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Submit tasks to the Ray cluster for execution.</span>

<span class="sd">    Args:</span>
<span class="sd">        tasks (list[dict]): A list of task configuration dictionaries.</span>
<span class="sd">        args (argparse.Namespace): Parsed command-line arguments.</span>
<span class="sd">        runtime_env (dict | None): Ray runtime environment configuration containing:</span>
<span class="sd">            - pip (list[str] | None): Additional pip packages to install.</span>
<span class="sd">            - py_modules (list[str] | None): Python modules to include in the environment.</span>
<span class="sd">        concurrent (bool): Whether to launch tasks simultaneously as a batch,</span>
<span class="sd">                           or independently as resources become available.</span>

<span class="sd">    Returns:</span>
<span class="sd">        None</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">job_objs</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">util</span><span class="o">.</span><span class="n">ray_init</span><span class="p">(</span><span class="n">ray_address</span><span class="o">=</span><span class="n">args</span><span class="o">.</span><span class="n">ray_address</span><span class="p">,</span> <span class="n">runtime_env</span><span class="o">=</span><span class="n">runtime_env</span><span class="p">,</span> <span class="n">log_to_driver</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">task</span> <span class="ow">in</span> <span class="n">tasks</span><span class="p">:</span>
        <span class="n">resource</span> <span class="o">=</span> <span class="n">parse_task_resource</span><span class="p">(</span><span class="n">task</span><span class="p">)</span>
        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;[INFO] Creating job </span><span class="si">{</span><span class="n">task</span><span class="p">[</span><span class="s1">&#39;name&#39;</span><span class="p">]</span><span class="si">}</span><span class="s2"> with resource=</span><span class="si">{</span><span class="n">resource</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
        <span class="n">job</span> <span class="o">=</span> <span class="n">util</span><span class="o">.</span><span class="n">Job</span><span class="p">(</span>
            <span class="n">name</span><span class="o">=</span><span class="n">task</span><span class="p">[</span><span class="s2">&quot;name&quot;</span><span class="p">],</span>
            <span class="n">py_args</span><span class="o">=</span><span class="n">task</span><span class="p">[</span><span class="s2">&quot;py_args&quot;</span><span class="p">],</span>
            <span class="n">resources</span><span class="o">=</span><span class="n">resource</span><span class="p">,</span>
            <span class="n">node</span><span class="o">=</span><span class="n">util</span><span class="o">.</span><span class="n">JobNode</span><span class="p">(</span>
                <span class="n">specific</span><span class="o">=</span><span class="n">task</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;node&quot;</span><span class="p">,</span> <span class="p">{})</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;specific&quot;</span><span class="p">),</span>
                <span class="n">hostname</span><span class="o">=</span><span class="n">task</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;node&quot;</span><span class="p">,</span> <span class="p">{})</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;hostname&quot;</span><span class="p">),</span>
                <span class="n">node_id</span><span class="o">=</span><span class="n">task</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;node&quot;</span><span class="p">,</span> <span class="p">{})</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;node_id&quot;</span><span class="p">),</span>
            <span class="p">),</span>
        <span class="p">)</span>
        <span class="n">job_objs</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">job</span><span class="p">)</span>
    <span class="n">start</span> <span class="o">=</span> <span class="n">datetime</span><span class="o">.</span><span class="n">now</span><span class="p">()</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;[INFO] Creating </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">job_objs</span><span class="p">)</span><span class="si">}</span><span class="s2"> jobs at </span><span class="si">{</span><span class="n">start</span><span class="o">.</span><span class="n">strftime</span><span class="p">(</span><span class="s1">&#39;%H:%M:%S.</span><span class="si">%f</span><span class="s1">&#39;</span><span class="p">)</span><span class="si">}</span><span class="s2"> with runtime env=</span><span class="si">{</span><span class="n">runtime_env</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="c1"># submit jobs</span>
    <span class="n">util</span><span class="o">.</span><span class="n">submit_wrapped_jobs</span><span class="p">(</span>
        <span class="n">jobs</span><span class="o">=</span><span class="n">job_objs</span><span class="p">,</span>
        <span class="n">test_mode</span><span class="o">=</span><span class="n">args</span><span class="o">.</span><span class="n">test</span><span class="p">,</span>
        <span class="n">concurrent</span><span class="o">=</span><span class="n">concurrent</span><span class="p">,</span>
    <span class="p">)</span>
    <span class="n">end</span> <span class="o">=</span> <span class="n">datetime</span><span class="o">.</span><span class="n">now</span><span class="p">()</span>
    <span class="nb">print</span><span class="p">(</span>
        <span class="sa">f</span><span class="s2">&quot;[INFO] All jobs completed at </span><span class="si">{</span><span class="n">end</span><span class="o">.</span><span class="n">strftime</span><span class="p">(</span><span class="s1">&#39;%H:%M:%S.</span><span class="si">%f</span><span class="s1">&#39;</span><span class="p">)</span><span class="si">}</span><span class="s2">, took </span><span class="si">{</span><span class="p">(</span><span class="n">end</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="n">start</span><span class="p">)</span><span class="o">.</span><span class="n">total_seconds</span><span class="p">()</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2"> seconds.&quot;</span>
    <span class="p">)</span>


<span class="k">def</span><span class="w"> </span><span class="nf">main</span><span class="p">()</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Main entry point for the Ray task runner script.</span>

<span class="sd">    Reads the YAML task configuration file, parses CLI arguments,</span>
<span class="sd">    and dispatches tasks to the Ray cluster.</span>

<span class="sd">    Returns:</span>
<span class="sd">        None</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">args</span> <span class="o">=</span> <span class="n">parse_args</span><span class="p">()</span>
    <span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">args</span><span class="o">.</span><span class="n">task_cfg</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
        <span class="n">config</span> <span class="o">=</span> <span class="n">yaml</span><span class="o">.</span><span class="n">safe_load</span><span class="p">(</span><span class="n">f</span><span class="p">)</span>
    <span class="n">tasks</span> <span class="o">=</span> <span class="n">config</span><span class="p">[</span><span class="s2">&quot;tasks&quot;</span><span class="p">]</span>
    <span class="n">runtime_env</span> <span class="o">=</span> <span class="p">{</span>
        <span class="s2">&quot;pip&quot;</span><span class="p">:</span> <span class="kc">None</span> <span class="k">if</span> <span class="ow">not</span> <span class="n">config</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;pip&quot;</span><span class="p">)</span> <span class="k">else</span> <span class="n">config</span><span class="p">[</span><span class="s2">&quot;pip&quot;</span><span class="p">],</span>
        <span class="s2">&quot;py_modules&quot;</span><span class="p">:</span> <span class="kc">None</span> <span class="k">if</span> <span class="ow">not</span> <span class="n">config</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;py_modules&quot;</span><span class="p">)</span> <span class="k">else</span> <span class="n">config</span><span class="p">[</span><span class="s2">&quot;py_modules&quot;</span><span class="p">],</span>
    <span class="p">}</span>
    <span class="n">concurrent</span> <span class="o">=</span> <span class="n">config</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;concurrent&quot;</span><span class="p">,</span> <span class="kc">False</span><span class="p">)</span>
    <span class="n">run_tasks</span><span class="p">(</span>
        <span class="n">tasks</span><span class="o">=</span><span class="n">tasks</span><span class="p">,</span>
        <span class="n">args</span><span class="o">=</span><span class="n">args</span><span class="p">,</span>
        <span class="n">runtime_env</span><span class="o">=</span><span class="n">runtime_env</span><span class="p">,</span>
        <span class="n">concurrent</span><span class="o">=</span><span class="n">concurrent</span><span class="p">,</span>
    <span class="p">)</span>


<span class="k">if</span> <span class="vm">__name__</span> <span class="o">==</span> <span class="s2">&quot;__main__&quot;</span><span class="p">:</span>
    <span class="n">main</span><span class="p">()</span>
</pre></div>
</div>
</div>
</details><p>以下脚本可用于向一个或多个 Ray 集群提交聚合任务，这些任务可用于在远程集群上运行作业或同时运行具有异构资源要求的作业。</p>
<details class="sd-sphinx-override sd-dropdown sd-card sd-mb-3">
<summary class="sd-summary-title sd-card-header">
<span class="sd-summary-icon"><svg version="1.1" width="1.0em" height="1.0em" class="sd-octicon sd-octicon-code" viewBox="0 0 16 16" aria-hidden="true"><path d="m11.28 3.22 4.25 4.25a.75.75 0 0 1 0 1.06l-4.25 4.25a.749.749 0 0 1-1.275-.326.749.749 0 0 1 .215-.734L13.94 8l-3.72-3.72a.749.749 0 0 1 .326-1.275.749.749 0 0 1 .734.215Zm-6.56 0a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042L2.06 8l3.72 3.72a.749.749 0 0 1-.326 1.275.749.749 0 0 1-.734-.215L.47 8.53a.75.75 0 0 1 0-1.06Z"></path></svg></span><span class="sd-summary-text">脚本 <cite>reinforcement_learning</cite>/<cite>ray</cite>/<cite>submit_job.py</cite></span><span class="sd-summary-state-marker sd-summary-chevron-right"><svg version="1.1" width="1.5em" height="1.5em" class="sd-octicon sd-octicon-chevron-right" viewBox="0 0 24 24" aria-hidden="true"><path d="M8.72 18.78a.75.75 0 0 1 0-1.06L14.44 12 8.72 6.28a.751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018l6.25 6.25a.75.75 0 0 1 0 1.06l-6.25 6.25a.75.75 0 0 1-1.06 0Z"></path></svg></span></summary><div class="sd-summary-content sd-card-body docutils">
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># Copyright (c) 2022-2025, The Isaac Lab Project Developers (https://github.com/isaac-sim/IsaacLab/blob/main/CONTRIBUTORS.md).</span>
<span class="c1"># All rights reserved.</span>
<span class="c1">#</span>
<span class="c1"># SPDX-License-Identifier: BSD-3-Clause</span>

<span class="sd">&quot;&quot;&quot;</span>
<span class="sd">This script submits aggregate job(s) to cluster(s) described in a</span>
<span class="sd">config file containing ``name: &lt;NAME&gt; address: http://&lt;IP&gt;:&lt;PORT&gt;`` on</span>
<span class="sd">a new line for each cluster. For KubeRay clusters, this file</span>
<span class="sd">can be automatically created with :file:`grok_cluster_with_kubectl.py`</span>

<span class="sd">Aggregate job(s) are matched with cluster(s) via the following relation:</span>
<span class="hll"><span class="sd">cluster_line_index_submitted_to = job_index % total_cluster_count</span>
</span><span class="hll">
</span><span class="hll"><span class="sd">Aggregate jobs are separated by the * delimiter. The ``--aggregate_jobs`` argument must be</span>
</span><span class="hll"><span class="sd">the last argument supplied to the script.</span>
</span><span class="hll">
</span><span class="hll"><span class="sd">An aggregate job could be a :file:`../tuner.py` tuning job, which automatically</span>
</span><span class="hll"><span class="sd">creates several individual jobs when started on a cluster. Alternatively, an aggregate job</span>
</span><span class="hll"><span class="sd">could be a :file:&#39;../wrap_resources.py` resource-wrapped job,</span>
</span><span class="hll"><span class="sd">which may contain several individual sub-jobs separated by</span>
</span><span class="hll"><span class="sd">the + delimiter. An aggregate job could also be a :file:`../task_runner.py` multi-task submission job,</span>
</span><span class="hll"><span class="sd">where each sub-job and its resource requirements are defined in a YAML configuration file.</span>
</span><span class="hll"><span class="sd">In this mode, :file:`../task_runner.py` will read the YAML file (via --task_cfg), and</span>
</span><span class="hll"><span class="sd">submit all defined sub-tasks to the Ray cluster, supporting per-job resource specification and</span>
</span><span class="hll"><span class="sd">real-time streaming of sub-job outputs.</span>
</span><span class="hll">
</span><span class="hll"><span class="sd">If there are more aggregate jobs than cluster(s), aggregate jobs will be submitted</span>
</span><span class="hll"><span class="sd">as clusters become available via the defined relation above. If there are less aggregate job(s)</span>
</span><span class="hll"><span class="sd">than clusters, some clusters will not receive aggregate job(s). The maximum number of</span>
</span><span class="hll"><span class="sd">aggregate jobs that can be run simultaneously is equal to the number of workers created by</span>
</span><span class="hll"><span class="sd">default by a ThreadPoolExecutor on the machine submitting jobs due to fetching the log output after</span>
</span><span class="hll"><span class="sd">jobs finish, which is unlikely to constrain overall-job submission.</span>
</span><span class="hll">
</span><span class="hll"><span class="sd">Usage:</span>
</span><span class="hll">
</span><span class="hll"><span class="sd">.. code-block:: bash</span>
</span><span class="hll">
</span><span class="hll"><span class="sd">    # Example; submitting a tuning job</span>
</span><span class="hll"><span class="sd">    python3 scripts/reinforcement_learning/ray/submit_job.py \</span>
</span><span class="hll"><span class="sd">    --aggregate_jobs /workspace/isaaclab/scripts/reinforcement_learning/ray/tuner.py \</span>
</span><span class="hll"><span class="sd">        --cfg_file hyperparameter_tuning/vision_cartpole_cfg.py \</span>
</span><span class="hll"><span class="sd">        --cfg_class CartpoleTheiaJobCfg --mlflow_uri &lt;ML_FLOW_URI&gt;</span>
</span><span class="hll">
</span><span class="hll"><span class="sd">    # Example: Submitting resource wrapped job</span>
</span><span class="hll"><span class="sd">    python3 scripts/reinforcement_learning/ray/submit_job.py --aggregate_jobs wrap_resources.py --test</span>
</span><span class="hll">
</span><span class="hll"><span class="sd">    # Example: submitting tasks with specific resources, and supporting pip packages and py_modules</span>
</span><span class="hll"><span class="sd">    # You may use relative paths for task_cfg and py_modules, placing them in the scripts/reinforcement_learning/ray directory, which will be uploaded to the cluster.</span>
</span><span class="hll"><span class="sd">    python3 scripts/reinforcement_learning/ray/submit_job.py --aggregate_jobs task_runner.py --task_cfg tasks.yaml</span>
</span><span class="hll">
</span><span class="hll"><span class="sd">    # For all command line arguments</span>
</span><span class="hll"><span class="sd">    python3 scripts/reinforcement_learning/ray/submit_job.py -h</span>
</span><span class="hll"><span class="sd">&quot;&quot;&quot;</span>
</span><span class="hll">
</span><span class="hll"><span class="kn">import</span><span class="w"> </span><span class="nn">argparse</span>
</span><span class="hll"><span class="kn">import</span><span class="w"> </span><span class="nn">os</span>
</span><span class="hll"><span class="kn">import</span><span class="w"> </span><span class="nn">time</span>
</span><span class="hll"><span class="kn">from</span><span class="w"> </span><span class="nn">concurrent.futures</span><span class="w"> </span><span class="kn">import</span> <span class="n">ThreadPoolExecutor</span>
</span><span class="hll">
</span><span class="hll"><span class="kn">from</span><span class="w"> </span><span class="nn">ray</span><span class="w"> </span><span class="kn">import</span> <span class="n">job_submission</span>
</span>
<span class="n">script_directory</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">dirname</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">abspath</span><span class="p">(</span><span class="vm">__file__</span><span class="p">))</span>
<span class="n">CONFIG</span> <span class="o">=</span> <span class="p">{</span><span class="s2">&quot;working_dir&quot;</span><span class="p">:</span> <span class="n">script_directory</span><span class="p">,</span> <span class="s2">&quot;executable&quot;</span><span class="p">:</span> <span class="s2">&quot;/workspace/isaaclab/isaaclab.sh -p&quot;</span><span class="p">}</span>


<span class="k">def</span><span class="w"> </span><span class="nf">read_cluster_spec</span><span class="p">(</span><span class="n">fn</span><span class="p">:</span> <span class="nb">str</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">list</span><span class="p">[</span><span class="nb">dict</span><span class="p">]:</span>
    <span class="k">if</span> <span class="n">fn</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">cluster_spec_path</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">expanduser</span><span class="p">(</span><span class="s2">&quot;~/.cluster_config&quot;</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">cluster_spec_path</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">expanduser</span><span class="p">(</span><span class="n">fn</span><span class="p">)</span>

    <span class="k">if</span> <span class="ow">not</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">exists</span><span class="p">(</span><span class="n">cluster_spec_path</span><span class="p">):</span>
        <span class="k">raise</span> <span class="ne">FileNotFoundError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Cluster spec file not found at </span><span class="si">{</span><span class="n">cluster_spec_path</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

    <span class="n">clusters</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">cluster_spec_path</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
        <span class="k">for</span> <span class="n">line</span> <span class="ow">in</span> <span class="n">f</span><span class="p">:</span>
            <span class="n">parts</span> <span class="o">=</span> <span class="n">line</span><span class="o">.</span><span class="n">strip</span><span class="p">()</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s2">&quot; &quot;</span><span class="p">)</span>
            <span class="n">http_address</span> <span class="o">=</span> <span class="n">parts</span><span class="p">[</span><span class="mi">3</span><span class="p">]</span>
            <span class="n">cluster_info</span> <span class="o">=</span> <span class="p">{</span><span class="s2">&quot;name&quot;</span><span class="p">:</span> <span class="n">parts</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="s2">&quot;address&quot;</span><span class="p">:</span> <span class="n">http_address</span><span class="p">}</span>
            <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;[INFO] Setting </span><span class="si">{</span><span class="n">cluster_info</span><span class="p">[</span><span class="s1">&#39;name&#39;</span><span class="p">]</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>  <span class="c1"># with {cluster_info[&#39;num_gpu&#39;]} GPUs.&quot;)</span>
            <span class="n">clusters</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">cluster_info</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">clusters</span>


<span class="k">def</span><span class="w"> </span><span class="nf">submit_job</span><span class="p">(</span><span class="n">cluster</span><span class="p">:</span> <span class="nb">dict</span><span class="p">,</span> <span class="n">job_command</span><span class="p">:</span> <span class="nb">str</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Submits a job to a single cluster, prints the final result and Ray dashboard URL at the end.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">address</span> <span class="o">=</span> <span class="n">cluster</span><span class="p">[</span><span class="s2">&quot;address&quot;</span><span class="p">]</span>
    <span class="n">cluster_name</span> <span class="o">=</span> <span class="n">cluster</span><span class="p">[</span><span class="s2">&quot;name&quot;</span><span class="p">]</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;[INFO]: Submitting job to cluster &#39;</span><span class="si">{</span><span class="n">cluster_name</span><span class="si">}</span><span class="s2">&#39; at </span><span class="si">{</span><span class="n">address</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>  <span class="c1"># with {num_gpus} GPUs.&quot;)</span>
    <span class="n">client</span> <span class="o">=</span> <span class="n">job_submission</span><span class="o">.</span><span class="n">JobSubmissionClient</span><span class="p">(</span><span class="n">address</span><span class="p">)</span>
    <span class="n">runtime_env</span> <span class="o">=</span> <span class="p">{</span><span class="s2">&quot;working_dir&quot;</span><span class="p">:</span> <span class="n">CONFIG</span><span class="p">[</span><span class="s2">&quot;working_dir&quot;</span><span class="p">],</span> <span class="s2">&quot;executable&quot;</span><span class="p">:</span> <span class="n">CONFIG</span><span class="p">[</span><span class="s2">&quot;executable&quot;</span><span class="p">]}</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;[INFO]: Checking contents of the directory: </span><span class="si">{</span><span class="n">CONFIG</span><span class="p">[</span><span class="s1">&#39;working_dir&#39;</span><span class="p">]</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="k">try</span><span class="p">:</span>
        <span class="n">dir_contents</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">listdir</span><span class="p">(</span><span class="n">CONFIG</span><span class="p">[</span><span class="s2">&quot;working_dir&quot;</span><span class="p">])</span>
        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;[INFO]: Directory contents: </span><span class="si">{</span><span class="n">dir_contents</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="k">except</span> <span class="ne">Exception</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;[INFO]: Failed to list directory contents: </span><span class="si">{</span><span class="nb">str</span><span class="p">(</span><span class="n">e</span><span class="p">)</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="n">entrypoint</span> <span class="o">=</span> <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">CONFIG</span><span class="p">[</span><span class="s1">&#39;executable&#39;</span><span class="p">]</span><span class="si">}</span><span class="s2"> </span><span class="si">{</span><span class="n">job_command</span><span class="si">}</span><span class="s2">&quot;</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;[INFO]: Attempting entrypoint </span><span class="si">{</span><span class="n">entrypoint</span><span class="si">=}</span><span class="s2"> in cluster </span><span class="si">{</span><span class="n">cluster</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="n">job_id</span> <span class="o">=</span> <span class="n">client</span><span class="o">.</span><span class="n">submit_job</span><span class="p">(</span><span class="n">entrypoint</span><span class="o">=</span><span class="n">entrypoint</span><span class="p">,</span> <span class="n">runtime_env</span><span class="o">=</span><span class="n">runtime_env</span><span class="p">)</span>
    <span class="n">status</span> <span class="o">=</span> <span class="n">client</span><span class="o">.</span><span class="n">get_job_status</span><span class="p">(</span><span class="n">job_id</span><span class="p">)</span>
    <span class="k">while</span> <span class="n">status</span> <span class="ow">in</span> <span class="p">[</span><span class="n">job_submission</span><span class="o">.</span><span class="n">JobStatus</span><span class="o">.</span><span class="n">PENDING</span><span class="p">,</span> <span class="n">job_submission</span><span class="o">.</span><span class="n">JobStatus</span><span class="o">.</span><span class="n">RUNNING</span><span class="p">]:</span>
        <span class="n">time</span><span class="o">.</span><span class="n">sleep</span><span class="p">(</span><span class="mi">5</span><span class="p">)</span>
        <span class="n">status</span> <span class="o">=</span> <span class="n">client</span><span class="o">.</span><span class="n">get_job_status</span><span class="p">(</span><span class="n">job_id</span><span class="p">)</span>

    <span class="n">final_logs</span> <span class="o">=</span> <span class="n">client</span><span class="o">.</span><span class="n">get_job_logs</span><span class="p">(</span><span class="n">job_id</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;----------------------------------------------------&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;[INFO]: Cluster </span><span class="si">{</span><span class="n">cluster_name</span><span class="si">}</span><span class="s2"> Logs: </span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">final_logs</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;----------------------------------------------------&quot;</span><span class="p">)</span>


<span class="k">def</span><span class="w"> </span><span class="nf">submit_jobs_to_clusters</span><span class="p">(</span><span class="n">jobs</span><span class="p">:</span> <span class="nb">list</span><span class="p">[</span><span class="nb">str</span><span class="p">],</span> <span class="n">clusters</span><span class="p">:</span> <span class="nb">list</span><span class="p">[</span><span class="nb">dict</span><span class="p">])</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Submit all jobs to their respective clusters, cycling through clusters if there are more jobs than clusters.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="n">clusters</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;No clusters available for job submission.&quot;</span><span class="p">)</span>

    <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">jobs</span><span class="p">)</span> <span class="o">&lt;</span> <span class="nb">len</span><span class="p">(</span><span class="n">clusters</span><span class="p">):</span>
        <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;[INFO]: Less jobs than clusters, some clusters will not receive jobs&quot;</span><span class="p">)</span>
    <span class="k">elif</span> <span class="nb">len</span><span class="p">(</span><span class="n">jobs</span><span class="p">)</span> <span class="o">==</span> <span class="nb">len</span><span class="p">(</span><span class="n">clusters</span><span class="p">):</span>
        <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;[INFO]: Exactly one job per cluster&quot;</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;[INFO]: More jobs than clusters, jobs submitted as clusters become available.&quot;</span><span class="p">)</span>
    <span class="k">with</span> <span class="n">ThreadPoolExecutor</span><span class="p">()</span> <span class="k">as</span> <span class="n">executor</span><span class="p">:</span>
        <span class="k">for</span> <span class="n">idx</span><span class="p">,</span> <span class="n">job_command</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">jobs</span><span class="p">):</span>
            <span class="c1"># Cycle through clusters using modulus to wrap around if there are more jobs than clusters</span>
            <span class="n">cluster</span> <span class="o">=</span> <span class="n">clusters</span><span class="p">[</span><span class="n">idx</span> <span class="o">%</span> <span class="nb">len</span><span class="p">(</span><span class="n">clusters</span><span class="p">)]</span>
            <span class="n">executor</span><span class="o">.</span><span class="n">submit</span><span class="p">(</span><span class="n">submit_job</span><span class="p">,</span> <span class="n">cluster</span><span class="p">,</span> <span class="n">job_command</span><span class="p">)</span>


<span class="k">if</span> <span class="vm">__name__</span> <span class="o">==</span> <span class="s2">&quot;__main__&quot;</span><span class="p">:</span>
    <span class="n">parser</span> <span class="o">=</span> <span class="n">argparse</span><span class="o">.</span><span class="n">ArgumentParser</span><span class="p">(</span><span class="n">description</span><span class="o">=</span><span class="s2">&quot;Submit multiple GPU jobs to multiple Ray clusters.&quot;</span><span class="p">)</span>
    <span class="n">parser</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span><span class="s2">&quot;--config_file&quot;</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="s2">&quot;~/.cluster_config&quot;</span><span class="p">,</span> <span class="n">help</span><span class="o">=</span><span class="s2">&quot;The cluster config path.&quot;</span><span class="p">)</span>
    <span class="n">parser</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span>
        <span class="s2">&quot;--aggregate_jobs&quot;</span><span class="p">,</span>
        <span class="nb">type</span><span class="o">=</span><span class="nb">str</span><span class="p">,</span>
        <span class="n">nargs</span><span class="o">=</span><span class="n">argparse</span><span class="o">.</span><span class="n">REMAINDER</span><span class="p">,</span>
        <span class="n">help</span><span class="o">=</span><span class="s2">&quot;This should be last argument. The aggregate jobs to submit separated by the * delimiter.&quot;</span><span class="p">,</span>
    <span class="p">)</span>
    <span class="n">args</span> <span class="o">=</span> <span class="n">parser</span><span class="o">.</span><span class="n">parse_args</span><span class="p">()</span>
    <span class="k">if</span> <span class="n">args</span><span class="o">.</span><span class="n">aggregate_jobs</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">jobs</span> <span class="o">=</span> <span class="s2">&quot; &quot;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">args</span><span class="o">.</span><span class="n">aggregate_jobs</span><span class="p">)</span>
        <span class="n">formatted_jobs</span> <span class="o">=</span> <span class="n">jobs</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s2">&quot;*&quot;</span><span class="p">)</span>
        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">formatted_jobs</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">:</span>
            <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Warning; Split jobs by cluster with the * delimiter&quot;</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">formatted_jobs</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;[INFO]: Isaac Ray Wrapper received jobs </span><span class="si">{</span><span class="n">formatted_jobs</span><span class="si">=}</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="n">clusters</span> <span class="o">=</span> <span class="n">read_cluster_spec</span><span class="p">(</span><span class="n">args</span><span class="o">.</span><span class="n">config_file</span><span class="p">)</span>
    <span class="n">submit_jobs_to_clusters</span><span class="p">(</span><span class="n">formatted_jobs</span><span class="p">,</span> <span class="n">clusters</span><span class="p">)</span>
</pre></div>
</div>
</div>
</details><p>以下脚本可用于提取 KubeRay 集群信息，以便进行聚合作业提交。</p>
<details class="sd-sphinx-override sd-dropdown sd-card sd-mb-3">
<summary class="sd-summary-title sd-card-header">
<span class="sd-summary-icon"><svg version="1.1" width="1.0em" height="1.0em" class="sd-octicon sd-octicon-code" viewBox="0 0 16 16" aria-hidden="true"><path d="m11.28 3.22 4.25 4.25a.75.75 0 0 1 0 1.06l-4.25 4.25a.749.749 0 0 1-1.275-.326.749.749 0 0 1 .215-.734L13.94 8l-3.72-3.72a.749.749 0 0 1 .326-1.275.749.749 0 0 1 .734.215Zm-6.56 0a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042L2.06 8l3.72 3.72a.749.749 0 0 1-.326 1.275.749.749 0 0 1-.734-.215L.47 8.53a.75.75 0 0 1 0-1.06Z"></path></svg></span><span class="sd-summary-text">scripts/reinforcement_learning/ray/grok_cluster_with_kubectl.py</span><span class="sd-summary-state-marker sd-summary-chevron-right"><svg version="1.1" width="1.5em" height="1.5em" class="sd-octicon sd-octicon-chevron-right" viewBox="0 0 24 24" aria-hidden="true"><path d="M8.72 18.78a.75.75 0 0 1 0-1.06L14.44 12 8.72 6.28a.751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018l6.25 6.25a.75.75 0 0 1 0 1.06l-6.25 6.25a.75.75 0 0 1-1.06 0Z"></path></svg></span></summary><div class="sd-summary-content sd-card-body docutils">
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># Copyright (c) 2022-2025, The Isaac Lab Project Developers (https://github.com/isaac-sim/IsaacLab/blob/main/CONTRIBUTORS.md).</span>
<span class="c1"># All rights reserved.</span>
<span class="c1">#</span>
<span class="c1"># SPDX-License-Identifier: BSD-3-Clause</span>

<span class="kn">import</span><span class="w"> </span><span class="nn">argparse</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">os</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">re</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">subprocess</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">threading</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">time</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">concurrent.futures</span><span class="w"> </span><span class="kn">import</span> <span class="n">ThreadPoolExecutor</span><span class="p">,</span> <span class="n">as_completed</span>

<span class="hll"><span class="sd">&quot;&quot;&quot;</span>
</span><span class="hll"><span class="sd">This script requires that kubectl is installed and KubeRay was used to create the cluster.</span>
</span><span class="hll">
</span><span class="hll"><span class="sd">Creates a config file containing ``name: &lt;NAME&gt; address: http://&lt;IP&gt;:&lt;PORT&gt;`` on</span>
</span><span class="hll"><span class="sd">a new line for each cluster, and also fetches the MLFlow URI.</span>
</span><span class="hll">
</span><span class="hll"><span class="sd">Usage:</span>
</span><span class="hll">
</span><span class="hll"><span class="sd">.. code-block:: bash</span>
</span><span class="hll">
</span><span class="hll"><span class="sd">    python3 scripts/reinforcement_learning/ray/grok_cluster_with_kubectl.py</span>
</span><span class="hll"><span class="sd">    # For options, supply -h arg</span>
</span><span class="hll"><span class="sd">&quot;&quot;&quot;</span>
</span>

<span class="k">def</span><span class="w"> </span><span class="nf">get_namespace</span><span class="p">()</span> <span class="o">-&gt;</span> <span class="nb">str</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Get the current Kubernetes namespace from the context, fallback to default if not set&quot;&quot;&quot;</span>
    <span class="k">try</span><span class="p">:</span>
        <span class="n">namespace</span> <span class="o">=</span> <span class="p">(</span>
            <span class="n">subprocess</span><span class="o">.</span><span class="n">check_output</span><span class="p">([</span><span class="s2">&quot;kubectl&quot;</span><span class="p">,</span> <span class="s2">&quot;config&quot;</span><span class="p">,</span> <span class="s2">&quot;view&quot;</span><span class="p">,</span> <span class="s2">&quot;--minify&quot;</span><span class="p">,</span> <span class="s2">&quot;--output&quot;</span><span class="p">,</span> <span class="s2">&quot;jsonpath={..namespace}&quot;</span><span class="p">])</span>
            <span class="o">.</span><span class="n">decode</span><span class="p">()</span>
            <span class="o">.</span><span class="n">strip</span><span class="p">()</span>
        <span class="p">)</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="n">namespace</span><span class="p">:</span>
            <span class="n">namespace</span> <span class="o">=</span> <span class="s2">&quot;default&quot;</span>
    <span class="k">except</span> <span class="n">subprocess</span><span class="o">.</span><span class="n">CalledProcessError</span><span class="p">:</span>
        <span class="n">namespace</span> <span class="o">=</span> <span class="s2">&quot;default&quot;</span>
    <span class="k">return</span> <span class="n">namespace</span>


<span class="k">def</span><span class="w"> </span><span class="nf">get_pods</span><span class="p">(</span><span class="n">namespace</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s2">&quot;default&quot;</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">list</span><span class="p">[</span><span class="nb">tuple</span><span class="p">]:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Get a list of all of the pods in the namespace&quot;&quot;&quot;</span>
    <span class="n">cmd</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;kubectl&quot;</span><span class="p">,</span> <span class="s2">&quot;get&quot;</span><span class="p">,</span> <span class="s2">&quot;pods&quot;</span><span class="p">,</span> <span class="s2">&quot;-n&quot;</span><span class="p">,</span> <span class="n">namespace</span><span class="p">,</span> <span class="s2">&quot;--no-headers&quot;</span><span class="p">]</span>
    <span class="n">output</span> <span class="o">=</span> <span class="n">subprocess</span><span class="o">.</span><span class="n">check_output</span><span class="p">(</span><span class="n">cmd</span><span class="p">)</span><span class="o">.</span><span class="n">decode</span><span class="p">()</span>
    <span class="n">pods</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">line</span> <span class="ow">in</span> <span class="n">output</span><span class="o">.</span><span class="n">strip</span><span class="p">()</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">):</span>
        <span class="n">fields</span> <span class="o">=</span> <span class="n">line</span><span class="o">.</span><span class="n">split</span><span class="p">()</span>
        <span class="n">pod_name</span> <span class="o">=</span> <span class="n">fields</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
        <span class="n">status</span> <span class="o">=</span> <span class="n">fields</span><span class="p">[</span><span class="mi">2</span><span class="p">]</span>
        <span class="n">pods</span><span class="o">.</span><span class="n">append</span><span class="p">((</span><span class="n">pod_name</span><span class="p">,</span> <span class="n">status</span><span class="p">))</span>
    <span class="k">return</span> <span class="n">pods</span>


<span class="k">def</span><span class="w"> </span><span class="nf">get_clusters</span><span class="p">(</span><span class="n">pods</span><span class="p">:</span> <span class="nb">list</span><span class="p">,</span> <span class="n">cluster_name_prefix</span><span class="p">:</span> <span class="nb">str</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">set</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Get unique cluster name(s). Works for one or more clusters, based off of the number of head nodes.</span>
<span class="sd">    Excludes MLflow deployments.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">clusters</span> <span class="o">=</span> <span class="nb">set</span><span class="p">()</span>
    <span class="k">for</span> <span class="n">pod_name</span><span class="p">,</span> <span class="n">_</span> <span class="ow">in</span> <span class="n">pods</span><span class="p">:</span>
        <span class="c1"># Skip MLflow pods</span>
        <span class="k">if</span> <span class="s2">&quot;-mlflow&quot;</span> <span class="ow">in</span> <span class="n">pod_name</span><span class="p">:</span>
            <span class="k">continue</span>

        <span class="n">match</span> <span class="o">=</span> <span class="n">re</span><span class="o">.</span><span class="n">match</span><span class="p">(</span><span class="sa">r</span><span class="s2">&quot;(&quot;</span> <span class="o">+</span> <span class="n">re</span><span class="o">.</span><span class="n">escape</span><span class="p">(</span><span class="n">cluster_name_prefix</span><span class="p">)</span> <span class="o">+</span> <span class="sa">r</span><span class="s2">&quot;[-\w]+)&quot;</span><span class="p">,</span> <span class="n">pod_name</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">match</span><span class="p">:</span>
            <span class="c1"># Get base name without head/worker suffix (skip workers)</span>
            <span class="k">if</span> <span class="s2">&quot;head&quot;</span> <span class="ow">in</span> <span class="n">pod_name</span><span class="p">:</span>
                <span class="n">base_name</span> <span class="o">=</span> <span class="n">match</span><span class="o">.</span><span class="n">group</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s2">&quot;-head&quot;</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span>
                <span class="n">clusters</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">base_name</span><span class="p">)</span>
    <span class="k">return</span> <span class="nb">sorted</span><span class="p">(</span><span class="n">clusters</span><span class="p">)</span>


<span class="k">def</span><span class="w"> </span><span class="nf">get_mlflow_info</span><span class="p">(</span><span class="n">namespace</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span> <span class="n">cluster_prefix</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s2">&quot;isaacray&quot;</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">str</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Get MLflow service information if it exists in the namespace with the given prefix.</span>
<span class="sd">    Only works for a single cluster instance.</span>
<span class="sd">    Args:</span>
<span class="sd">        namespace: Kubernetes namespace</span>
<span class="sd">        cluster_prefix: Base cluster name (without -head/-worker suffixes)</span>
<span class="sd">    Returns:</span>
<span class="sd">        MLflow service URL</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="c1"># Strip any -head or -worker suffixes to get base name</span>
    <span class="k">if</span> <span class="n">namespace</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">namespace</span> <span class="o">=</span> <span class="n">get_namespace</span><span class="p">()</span>
    <span class="n">pods</span> <span class="o">=</span> <span class="n">get_pods</span><span class="p">(</span><span class="n">namespace</span><span class="o">=</span><span class="n">namespace</span><span class="p">)</span>
    <span class="n">clusters</span> <span class="o">=</span> <span class="n">get_clusters</span><span class="p">(</span><span class="n">pods</span><span class="o">=</span><span class="n">pods</span><span class="p">,</span> <span class="n">cluster_name_prefix</span><span class="o">=</span><span class="n">cluster_prefix</span><span class="p">)</span>
    <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">clusters</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;More than one cluster matches prefix, could not automatically determine mlflow info.&quot;</span><span class="p">)</span>
    <span class="n">mlflow_name</span> <span class="o">=</span> <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">cluster_prefix</span><span class="si">}</span><span class="s2">-mlflow&quot;</span>

    <span class="n">cmd</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;kubectl&quot;</span><span class="p">,</span> <span class="s2">&quot;get&quot;</span><span class="p">,</span> <span class="s2">&quot;svc&quot;</span><span class="p">,</span> <span class="n">mlflow_name</span><span class="p">,</span> <span class="s2">&quot;-n&quot;</span><span class="p">,</span> <span class="n">namespace</span><span class="p">,</span> <span class="s2">&quot;--no-headers&quot;</span><span class="p">]</span>
    <span class="k">try</span><span class="p">:</span>
        <span class="n">output</span> <span class="o">=</span> <span class="n">subprocess</span><span class="o">.</span><span class="n">check_output</span><span class="p">(</span><span class="n">cmd</span><span class="p">)</span><span class="o">.</span><span class="n">decode</span><span class="p">()</span>
        <span class="n">fields</span> <span class="o">=</span> <span class="n">output</span><span class="o">.</span><span class="n">strip</span><span class="p">()</span><span class="o">.</span><span class="n">split</span><span class="p">()</span>

        <span class="c1"># Get cluster IP</span>
        <span class="n">cluster_ip</span> <span class="o">=</span> <span class="n">fields</span><span class="p">[</span><span class="mi">2</span><span class="p">]</span>
        <span class="n">port</span> <span class="o">=</span> <span class="s2">&quot;5000&quot;</span>  <span class="c1"># Default MLflow port</span>
        <span class="c1"># This needs to be http to be resolved. HTTPS can&#39;t be resolved</span>
        <span class="c1"># This should be fine as it is on a subnet on the cluster regardless</span>
        <span class="k">return</span> <span class="sa">f</span><span class="s2">&quot;http://</span><span class="si">{</span><span class="n">cluster_ip</span><span class="si">}</span><span class="s2">:</span><span class="si">{</span><span class="n">port</span><span class="si">}</span><span class="s2">&quot;</span>
    <span class="k">except</span> <span class="n">subprocess</span><span class="o">.</span><span class="n">CalledProcessError</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Could not grok MLflow: </span><span class="si">{</span><span class="n">e</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>  <span class="c1"># Fixed f-string</span>


<span class="k">def</span><span class="w"> </span><span class="nf">check_clusters_running</span><span class="p">(</span><span class="n">pods</span><span class="p">:</span> <span class="nb">list</span><span class="p">,</span> <span class="n">clusters</span><span class="p">:</span> <span class="nb">set</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">bool</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Check that all of the pods in all provided clusters are running.</span>

<span class="sd">    Args:</span>
<span class="sd">        pods (list): A list of tuples where each tuple contains the pod name and its status.</span>
<span class="sd">        clusters (set): A set of cluster names to check.</span>

<span class="sd">    Returns:</span>
<span class="sd">        bool: True if all pods in any of the clusters are running, False otherwise.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">clusters_running</span> <span class="o">=</span> <span class="kc">False</span>
    <span class="k">for</span> <span class="n">cluster</span> <span class="ow">in</span> <span class="n">clusters</span><span class="p">:</span>
        <span class="n">cluster_pods</span> <span class="o">=</span> <span class="p">[</span><span class="n">p</span> <span class="k">for</span> <span class="n">p</span> <span class="ow">in</span> <span class="n">pods</span> <span class="k">if</span> <span class="n">p</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">startswith</span><span class="p">(</span><span class="n">cluster</span><span class="p">)]</span>
        <span class="n">total_pods</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">cluster_pods</span><span class="p">)</span>
        <span class="n">running_pods</span> <span class="o">=</span> <span class="nb">len</span><span class="p">([</span><span class="n">p</span> <span class="k">for</span> <span class="n">p</span> <span class="ow">in</span> <span class="n">cluster_pods</span> <span class="k">if</span> <span class="n">p</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">==</span> <span class="s2">&quot;Running&quot;</span><span class="p">])</span>
        <span class="k">if</span> <span class="n">running_pods</span> <span class="o">==</span> <span class="n">total_pods</span> <span class="ow">and</span> <span class="n">running_pods</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
            <span class="n">clusters_running</span> <span class="o">=</span> <span class="kc">True</span>
            <span class="k">break</span>
    <span class="k">return</span> <span class="n">clusters_running</span>


<span class="k">def</span><span class="w"> </span><span class="nf">get_ray_address</span><span class="p">(</span><span class="n">head_pod</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span> <span class="n">namespace</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s2">&quot;default&quot;</span><span class="p">,</span> <span class="n">ray_head_name</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s2">&quot;head&quot;</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">str</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Given a cluster head pod, check its logs, which should include the ray address which can accept job requests.</span>

<span class="sd">    Args:</span>
<span class="sd">        head_pod (str): The name of the head pod.</span>
<span class="sd">        namespace (str, optional): The Kubernetes namespace. Defaults to &quot;default&quot;.</span>
<span class="sd">        ray_head_name (str, optional): The name of the ray head container. Defaults to &quot;head&quot;.</span>

<span class="sd">    Returns:</span>
<span class="sd">        str: The ray address if found, None otherwise.</span>

<span class="sd">    Raises:</span>
<span class="sd">        ValueError: If the logs cannot be retrieved or the ray address is not found.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">cmd</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;kubectl&quot;</span><span class="p">,</span> <span class="s2">&quot;logs&quot;</span><span class="p">,</span> <span class="n">head_pod</span><span class="p">,</span> <span class="s2">&quot;-c&quot;</span><span class="p">,</span> <span class="n">ray_head_name</span><span class="p">,</span> <span class="s2">&quot;-n&quot;</span><span class="p">,</span> <span class="n">namespace</span><span class="p">]</span>
    <span class="k">try</span><span class="p">:</span>
        <span class="n">output</span> <span class="o">=</span> <span class="n">subprocess</span><span class="o">.</span><span class="n">check_output</span><span class="p">(</span><span class="n">cmd</span><span class="p">)</span><span class="o">.</span><span class="n">decode</span><span class="p">()</span>
    <span class="k">except</span> <span class="n">subprocess</span><span class="o">.</span><span class="n">CalledProcessError</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
            <span class="sa">f</span><span class="s2">&quot;Could not enter head container with cmd </span><span class="si">{</span><span class="n">cmd</span><span class="si">}</span><span class="s2">: </span><span class="si">{</span><span class="n">e</span><span class="si">}</span><span class="s2">Perhaps try a different namespace or ray head name.&quot;</span>
        <span class="p">)</span>
    <span class="n">match</span> <span class="o">=</span> <span class="n">re</span><span class="o">.</span><span class="n">search</span><span class="p">(</span><span class="sa">r</span><span class="s2">&quot;RAY_ADDRESS=&#39;([^&#39;]+)&#39;&quot;</span><span class="p">,</span> <span class="n">output</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">match</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">match</span><span class="o">.</span><span class="n">group</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="k">return</span> <span class="kc">None</span>


<span class="k">def</span><span class="w"> </span><span class="nf">process_cluster</span><span class="p">(</span><span class="n">cluster_info</span><span class="p">:</span> <span class="nb">dict</span><span class="p">,</span> <span class="n">ray_head_name</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s2">&quot;head&quot;</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">str</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    For each cluster, check that it is running, and get the Ray head address that will accept jobs.</span>

<span class="sd">    Args:</span>
<span class="sd">        cluster_info (dict): A dictionary containing cluster information with keys &#39;cluster&#39;, &#39;pods&#39;, and &#39;namespace&#39;.</span>
<span class="sd">        ray_head_name (str, optional): The name of the ray head container. Defaults to &quot;head&quot;.</span>

<span class="sd">    Returns:</span>
<span class="sd">        str: A string containing the cluster name and its Ray head address, or an error message if the head pod or Ray address is not found.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">cluster</span><span class="p">,</span> <span class="n">pods</span><span class="p">,</span> <span class="n">namespace</span> <span class="o">=</span> <span class="n">cluster_info</span>
    <span class="n">head_pod</span> <span class="o">=</span> <span class="kc">None</span>
    <span class="k">for</span> <span class="n">pod_name</span><span class="p">,</span> <span class="n">status</span> <span class="ow">in</span> <span class="n">pods</span><span class="p">:</span>
        <span class="k">if</span> <span class="n">pod_name</span><span class="o">.</span><span class="n">startswith</span><span class="p">(</span><span class="n">cluster</span> <span class="o">+</span> <span class="s2">&quot;-head&quot;</span><span class="p">):</span>
            <span class="n">head_pod</span> <span class="o">=</span> <span class="n">pod_name</span>
            <span class="k">break</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="n">head_pod</span><span class="p">:</span>
        <span class="k">return</span> <span class="sa">f</span><span class="s2">&quot;Error: Could not find head pod for cluster </span><span class="si">{</span><span class="n">cluster</span><span class="si">}</span><span class="se">\n</span><span class="s2">&quot;</span>

    <span class="c1"># Get RAY_ADDRESS and status</span>
    <span class="n">ray_address</span> <span class="o">=</span> <span class="n">get_ray_address</span><span class="p">(</span><span class="n">head_pod</span><span class="p">,</span> <span class="n">namespace</span><span class="o">=</span><span class="n">namespace</span><span class="p">,</span> <span class="n">ray_head_name</span><span class="o">=</span><span class="n">ray_head_name</span><span class="p">)</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="n">ray_address</span><span class="p">:</span>
        <span class="k">return</span> <span class="sa">f</span><span class="s2">&quot;Error: Could not find RAY_ADDRESS for cluster </span><span class="si">{</span><span class="n">cluster</span><span class="si">}</span><span class="se">\n</span><span class="s2">&quot;</span>

    <span class="c1"># Return only cluster and ray address</span>
    <span class="k">return</span> <span class="sa">f</span><span class="s2">&quot;name: </span><span class="si">{</span><span class="n">cluster</span><span class="si">}</span><span class="s2"> address: </span><span class="si">{</span><span class="n">ray_address</span><span class="si">}</span><span class="se">\n</span><span class="s2">&quot;</span>


<span class="k">def</span><span class="w"> </span><span class="nf">main</span><span class="p">():</span>
    <span class="c1"># Parse command-line arguments</span>
    <span class="n">parser</span> <span class="o">=</span> <span class="n">argparse</span><span class="o">.</span><span class="n">ArgumentParser</span><span class="p">(</span><span class="n">description</span><span class="o">=</span><span class="s2">&quot;Process Ray clusters and save their specifications.&quot;</span><span class="p">)</span>
    <span class="n">parser</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span><span class="s2">&quot;--prefix&quot;</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="s2">&quot;isaacray&quot;</span><span class="p">,</span> <span class="n">help</span><span class="o">=</span><span class="s2">&quot;The prefix for the cluster names.&quot;</span><span class="p">)</span>
    <span class="n">parser</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span><span class="s2">&quot;--output&quot;</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="s2">&quot;~/.cluster_config&quot;</span><span class="p">,</span> <span class="n">help</span><span class="o">=</span><span class="s2">&quot;The file to save cluster specifications.&quot;</span><span class="p">)</span>
    <span class="n">parser</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span><span class="s2">&quot;--ray_head_name&quot;</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="s2">&quot;head&quot;</span><span class="p">,</span> <span class="n">help</span><span class="o">=</span><span class="s2">&quot;The metadata name for the ray head container&quot;</span><span class="p">)</span>
    <span class="n">parser</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span>
        <span class="s2">&quot;--namespace&quot;</span><span class="p">,</span> <span class="n">help</span><span class="o">=</span><span class="s2">&quot;Kubernetes namespace to use. If not provided, will detect from current context.&quot;</span>
    <span class="p">)</span>
    <span class="n">args</span> <span class="o">=</span> <span class="n">parser</span><span class="o">.</span><span class="n">parse_args</span><span class="p">()</span>

    <span class="c1"># Get namespace from args or detect it</span>
    <span class="n">current_namespace</span> <span class="o">=</span> <span class="n">args</span><span class="o">.</span><span class="n">namespace</span> <span class="k">if</span> <span class="n">args</span><span class="o">.</span><span class="n">namespace</span> <span class="k">else</span> <span class="n">get_namespace</span><span class="p">()</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Using namespace: </span><span class="si">{</span><span class="n">current_namespace</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

    <span class="n">cluster_name_prefix</span> <span class="o">=</span> <span class="n">args</span><span class="o">.</span><span class="n">prefix</span>
    <span class="n">cluster_spec_file</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">expanduser</span><span class="p">(</span><span class="n">args</span><span class="o">.</span><span class="n">output</span><span class="p">)</span>

    <span class="c1"># Get all pods</span>
    <span class="n">pods</span> <span class="o">=</span> <span class="n">get_pods</span><span class="p">(</span><span class="n">namespace</span><span class="o">=</span><span class="n">current_namespace</span><span class="p">)</span>

    <span class="c1"># Get clusters</span>
    <span class="n">clusters</span> <span class="o">=</span> <span class="n">get_clusters</span><span class="p">(</span><span class="n">pods</span><span class="p">,</span> <span class="n">cluster_name_prefix</span><span class="p">)</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="n">clusters</span><span class="p">:</span>
        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;No clusters found with prefix </span><span class="si">{</span><span class="n">cluster_name_prefix</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
        <span class="k">return</span>

    <span class="c1"># Wait for clusters to be running</span>
    <span class="k">while</span> <span class="kc">True</span><span class="p">:</span>
        <span class="n">pods</span> <span class="o">=</span> <span class="n">get_pods</span><span class="p">(</span><span class="n">namespace</span><span class="o">=</span><span class="n">current_namespace</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">check_clusters_running</span><span class="p">(</span><span class="n">pods</span><span class="p">,</span> <span class="n">clusters</span><span class="p">):</span>
            <span class="k">break</span>
        <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Waiting for all clusters to spin up...&quot;</span><span class="p">)</span>
        <span class="n">time</span><span class="o">.</span><span class="n">sleep</span><span class="p">(</span><span class="mi">5</span><span class="p">)</span>

    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Checking for MLflow:&quot;</span><span class="p">)</span>
    <span class="c1"># Check MLflow status for each cluster</span>
    <span class="k">for</span> <span class="n">cluster</span> <span class="ow">in</span> <span class="n">clusters</span><span class="p">:</span>
        <span class="k">try</span><span class="p">:</span>
            <span class="n">mlflow_address</span> <span class="o">=</span> <span class="n">get_mlflow_info</span><span class="p">(</span><span class="n">current_namespace</span><span class="p">,</span> <span class="n">cluster</span><span class="p">)</span>
            <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;MLflow address for </span><span class="si">{</span><span class="n">cluster</span><span class="si">}</span><span class="s2">: </span><span class="si">{</span><span class="n">mlflow_address</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
        <span class="k">except</span> <span class="ne">ValueError</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
            <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;ML Flow not located: </span><span class="si">{</span><span class="n">e</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">()</span>

    <span class="c1"># Prepare cluster info for parallel processing</span>
    <span class="n">cluster_infos</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">cluster</span> <span class="ow">in</span> <span class="n">clusters</span><span class="p">:</span>
        <span class="n">cluster_pods</span> <span class="o">=</span> <span class="p">[</span><span class="n">p</span> <span class="k">for</span> <span class="n">p</span> <span class="ow">in</span> <span class="n">pods</span> <span class="k">if</span> <span class="n">p</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">startswith</span><span class="p">(</span><span class="n">cluster</span><span class="p">)]</span>
        <span class="n">cluster_infos</span><span class="o">.</span><span class="n">append</span><span class="p">((</span><span class="n">cluster</span><span class="p">,</span> <span class="n">cluster_pods</span><span class="p">,</span> <span class="n">current_namespace</span><span class="p">))</span>

    <span class="c1"># Use ThreadPoolExecutor to process clusters in parallel</span>
    <span class="n">results</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">results_lock</span> <span class="o">=</span> <span class="n">threading</span><span class="o">.</span><span class="n">Lock</span><span class="p">()</span>

    <span class="k">with</span> <span class="n">ThreadPoolExecutor</span><span class="p">()</span> <span class="k">as</span> <span class="n">executor</span><span class="p">:</span>
        <span class="n">future_to_cluster</span> <span class="o">=</span> <span class="p">{</span>
            <span class="n">executor</span><span class="o">.</span><span class="n">submit</span><span class="p">(</span><span class="n">process_cluster</span><span class="p">,</span> <span class="n">info</span><span class="p">,</span> <span class="n">args</span><span class="o">.</span><span class="n">ray_head_name</span><span class="p">):</span> <span class="n">info</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="k">for</span> <span class="n">info</span> <span class="ow">in</span> <span class="n">cluster_infos</span>
        <span class="p">}</span>
        <span class="k">for</span> <span class="n">future</span> <span class="ow">in</span> <span class="n">as_completed</span><span class="p">(</span><span class="n">future_to_cluster</span><span class="p">):</span>
            <span class="n">cluster_name</span> <span class="o">=</span> <span class="n">future_to_cluster</span><span class="p">[</span><span class="n">future</span><span class="p">]</span>
            <span class="k">try</span><span class="p">:</span>
                <span class="n">result</span> <span class="o">=</span> <span class="n">future</span><span class="o">.</span><span class="n">result</span><span class="p">()</span>
                <span class="k">with</span> <span class="n">results_lock</span><span class="p">:</span>
                    <span class="n">results</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">result</span><span class="p">)</span>
            <span class="k">except</span> <span class="ne">Exception</span> <span class="k">as</span> <span class="n">exc</span><span class="p">:</span>
                <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">cluster_name</span><span class="si">}</span><span class="s2"> generated an exception: </span><span class="si">{</span><span class="n">exc</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

    <span class="c1"># Sort results alphabetically by cluster name</span>
    <span class="n">results</span><span class="o">.</span><span class="n">sort</span><span class="p">()</span>

    <span class="c1"># Write sorted results to the output file (Ray info only)</span>
    <span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">cluster_spec_file</span><span class="p">,</span> <span class="s2">&quot;w&quot;</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
        <span class="k">for</span> <span class="n">result</span> <span class="ow">in</span> <span class="n">results</span><span class="p">:</span>
            <span class="n">f</span><span class="o">.</span><span class="n">write</span><span class="p">(</span><span class="n">result</span><span class="p">)</span>

    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Cluster spec information saved to </span><span class="si">{</span><span class="n">cluster_spec_file</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="c1"># Display the contents of the config file</span>
    <span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">cluster_spec_file</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
        <span class="nb">print</span><span class="p">(</span><span class="n">f</span><span class="o">.</span><span class="n">read</span><span class="p">())</span>


<span class="k">if</span> <span class="vm">__name__</span> <span class="o">==</span> <span class="s2">&quot;__main__&quot;</span><span class="p">:</span>
    <span class="n">main</span><span class="p">()</span>
</pre></div>
</div>
</div>
</details><p>以下脚本可以用来轻松在 Google GKE 上创建集群。</p>
<details class="sd-sphinx-override sd-dropdown sd-card sd-mb-3">
<summary class="sd-summary-title sd-card-header">
<span class="sd-summary-icon"><svg version="1.1" width="1.0em" height="1.0em" class="sd-octicon sd-octicon-code" viewBox="0 0 16 16" aria-hidden="true"><path d="m11.28 3.22 4.25 4.25a.75.75 0 0 1 0 1.06l-4.25 4.25a.749.749 0 0 1-1.275-.326.749.749 0 0 1 .215-.734L13.94 8l-3.72-3.72a.749.749 0 0 1 .326-1.275.749.749 0 0 1 .734.215Zm-6.56 0a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042L2.06 8l3.72 3.72a.749.749 0 0 1-.326 1.275.749.749 0 0 1-.734-.215L.47 8.53a.75.75 0 0 1 0-1.06Z"></path></svg></span><span class="sd-summary-text">scripts/reinforcement_learning/ray/launch.py</span><span class="sd-summary-state-marker sd-summary-chevron-right"><svg version="1.1" width="1.5em" height="1.5em" class="sd-octicon sd-octicon-chevron-right" viewBox="0 0 24 24" aria-hidden="true"><path d="M8.72 18.78a.75.75 0 0 1 0-1.06L14.44 12 8.72 6.28a.751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018l6.25 6.25a.75.75 0 0 1 0 1.06l-6.25 6.25a.75.75 0 0 1-1.06 0Z"></path></svg></span></summary><div class="sd-summary-content sd-card-body docutils">
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># Copyright (c) 2022-2025, The Isaac Lab Project Developers (https://github.com/isaac-sim/IsaacLab/blob/main/CONTRIBUTORS.md).</span>
<span class="c1"># All rights reserved.</span>
<span class="c1">#</span>
<span class="c1"># SPDX-License-Identifier: BSD-3-Clause</span>

<span class="kn">import</span><span class="w"> </span><span class="nn">argparse</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">pathlib</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">subprocess</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">yaml</span>

<span class="kn">import</span><span class="w"> </span><span class="nn">util</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">jinja2</span><span class="w"> </span><span class="kn">import</span> <span class="n">Environment</span><span class="p">,</span> <span class="n">FileSystemLoader</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">kubernetes</span><span class="w"> </span><span class="kn">import</span> <span class="n">config</span>

<span class="hll"><span class="sd">&quot;&quot;&quot;This script helps create one or more KubeRay clusters.</span>
</span><span class="hll">
</span><span class="hll"><span class="sd">Usage:</span>
</span><span class="hll">
</span><span class="hll"><span class="sd">.. code-block:: bash</span>
</span><span class="hll"><span class="sd">    # If the head node is stuck on container creating, make sure to create a secret</span>
</span><span class="hll"><span class="sd">    python3 scripts/reinforcement_learning/ray/launch.py -h</span>
</span><span class="hll">
</span><span class="hll"><span class="sd">    # Examples</span>
</span><span class="hll">
</span><span class="hll"><span class="sd">    # The following creates 8 GPUx1 nvidia l4 workers</span>
</span><span class="hll"><span class="sd">    python3 scripts/reinforcement_learning/ray/launch.py --cluster_host google_cloud \</span>
</span><span class="hll"><span class="sd">    --namespace &lt;NAMESPACE&gt; --image &lt;YOUR_ISAAC_RAY_IMAGE&gt; \</span>
</span><span class="hll"><span class="sd">    --num_workers 8 --num_clusters 1 --worker_accelerator nvidia-l4 --gpu_per_worker 1</span>
</span><span class="hll">
</span><span class="hll"><span class="sd">    # The following creates 1 GPUx1 nvidia l4 worker, 2 GPUx2 nvidia-tesla-t4 workers,</span>
</span><span class="hll"><span class="sd">    # and 2 GPUx4 nvidia-tesla-t4 GPU workers</span>
</span><span class="hll"><span class="sd">    python3 scripts/reinforcement_learning/ray/launch.py --cluster_host google_cloud \</span>
</span><span class="hll"><span class="sd">    --namespace &lt;NAMESPACE&gt; --image &lt;YOUR_ISAAC_RAY_IMAGE&gt; \</span>
</span><span class="hll"><span class="sd">    --num_workers 1 2 --num_clusters 1 \</span>
</span><span class="hll"><span class="sd">    --worker_accelerator nvidia-l4 nvidia-tesla-t4 --gpu_per_worker 1 2 4</span>
</span><span class="hll"><span class="sd">&quot;&quot;&quot;</span>
</span><span class="n">RAY_DIR</span> <span class="o">=</span> <span class="n">pathlib</span><span class="o">.</span><span class="n">Path</span><span class="p">(</span><span class="vm">__file__</span><span class="p">)</span><span class="o">.</span><span class="n">parent</span>


<span class="k">def</span><span class="w"> </span><span class="nf">apply_manifest</span><span class="p">(</span><span class="n">args</span><span class="p">:</span> <span class="n">argparse</span><span class="o">.</span><span class="n">Namespace</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Provided a Jinja templated ray.io/v1alpha1 file,</span>
<span class="sd">    populate the arguments and create the cluster. Additionally, create</span>
<span class="sd">    kubernetes containers for resources separated by &#39;---&#39; from the rest</span>
<span class="sd">    of the file.</span>

<span class="sd">    Args:</span>
<span class="sd">        args: Possible arguments concerning cluster parameters.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="c1"># Load Kubernetes configuration</span>
    <span class="n">config</span><span class="o">.</span><span class="n">load_kube_config</span><span class="p">()</span>

    <span class="c1"># Set up Jinja2 environment for loading templates</span>
    <span class="n">templates_dir</span> <span class="o">=</span> <span class="n">RAY_DIR</span> <span class="o">/</span> <span class="s2">&quot;cluster_configs&quot;</span> <span class="o">/</span> <span class="n">args</span><span class="o">.</span><span class="n">cluster_host</span>
    <span class="n">file_loader</span> <span class="o">=</span> <span class="n">FileSystemLoader</span><span class="p">(</span><span class="nb">str</span><span class="p">(</span><span class="n">templates_dir</span><span class="p">))</span>
    <span class="n">jinja_env</span> <span class="o">=</span> <span class="n">Environment</span><span class="p">(</span><span class="n">loader</span><span class="o">=</span><span class="n">file_loader</span><span class="p">,</span> <span class="n">keep_trailing_newline</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">autoescape</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

    <span class="c1"># Define template filename</span>
    <span class="n">template_file</span> <span class="o">=</span> <span class="s2">&quot;kuberay.yaml.jinja&quot;</span>

    <span class="c1"># Convert args namespace to a dictionary</span>
    <span class="n">template_params</span> <span class="o">=</span> <span class="nb">vars</span><span class="p">(</span><span class="n">args</span><span class="p">)</span>

    <span class="c1"># Load and render the template</span>
    <span class="n">template</span> <span class="o">=</span> <span class="n">jinja_env</span><span class="o">.</span><span class="n">get_template</span><span class="p">(</span><span class="n">template_file</span><span class="p">)</span>
    <span class="n">file_contents</span> <span class="o">=</span> <span class="n">template</span><span class="o">.</span><span class="n">render</span><span class="p">(</span><span class="n">template_params</span><span class="p">)</span>

    <span class="c1"># Parse all YAML documents in the rendered template</span>
    <span class="n">all_yamls</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">doc</span> <span class="ow">in</span> <span class="n">yaml</span><span class="o">.</span><span class="n">safe_load_all</span><span class="p">(</span><span class="n">file_contents</span><span class="p">):</span>
        <span class="n">all_yamls</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">doc</span><span class="p">)</span>

    <span class="c1"># Convert back to YAML string, preserving multiple documents</span>
    <span class="n">cleaned_yaml_string</span> <span class="o">=</span> <span class="s2">&quot;&quot;</span>
    <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">doc</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">all_yamls</span><span class="p">):</span>
        <span class="k">if</span> <span class="n">i</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
            <span class="n">cleaned_yaml_string</span> <span class="o">+=</span> <span class="s2">&quot;</span><span class="se">\n</span><span class="s2">---</span><span class="se">\n</span><span class="s2">&quot;</span>
        <span class="n">cleaned_yaml_string</span> <span class="o">+=</span> <span class="n">yaml</span><span class="o">.</span><span class="n">dump</span><span class="p">(</span><span class="n">doc</span><span class="p">)</span>

    <span class="c1"># Apply the Kubernetes manifest using kubectl</span>
    <span class="k">try</span><span class="p">:</span>
        <span class="nb">print</span><span class="p">(</span><span class="n">cleaned_yaml_string</span><span class="p">)</span>
        <span class="n">subprocess</span><span class="o">.</span><span class="n">run</span><span class="p">([</span><span class="s2">&quot;kubectl&quot;</span><span class="p">,</span> <span class="s2">&quot;apply&quot;</span><span class="p">,</span> <span class="s2">&quot;-f&quot;</span><span class="p">,</span> <span class="s2">&quot;-&quot;</span><span class="p">],</span> <span class="nb">input</span><span class="o">=</span><span class="n">cleaned_yaml_string</span><span class="p">,</span> <span class="n">text</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">check</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
    <span class="k">except</span> <span class="n">subprocess</span><span class="o">.</span><span class="n">CalledProcessError</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
        <span class="n">exit</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;An error occurred while running `kubectl`: </span><span class="si">{</span><span class="n">e</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>


<span class="k">def</span><span class="w"> </span><span class="nf">parse_args</span><span class="p">()</span> <span class="o">-&gt;</span> <span class="n">argparse</span><span class="o">.</span><span class="n">Namespace</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Parse command-line arguments for Kubernetes deployment script.</span>

<span class="sd">    Returns:</span>
<span class="sd">        argparse.Namespace: Parsed command-line arguments.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">arg_parser</span> <span class="o">=</span> <span class="n">argparse</span><span class="o">.</span><span class="n">ArgumentParser</span><span class="p">(</span>
        <span class="n">description</span><span class="o">=</span><span class="s2">&quot;Script to apply manifests to create Kubernetes objects for Ray clusters.&quot;</span><span class="p">,</span>
        <span class="n">formatter_class</span><span class="o">=</span><span class="n">argparse</span><span class="o">.</span><span class="n">ArgumentDefaultsHelpFormatter</span><span class="p">,</span>
    <span class="p">)</span>

    <span class="n">arg_parser</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span>
        <span class="s2">&quot;--cluster_host&quot;</span><span class="p">,</span>
        <span class="nb">type</span><span class="o">=</span><span class="nb">str</span><span class="p">,</span>
        <span class="n">default</span><span class="o">=</span><span class="s2">&quot;google_cloud&quot;</span><span class="p">,</span>
        <span class="n">choices</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;google_cloud&quot;</span><span class="p">],</span>
        <span class="n">help</span><span class="o">=</span><span class="p">(</span>
            <span class="s2">&quot;In the cluster_configs directory, the name of the folder where a tune.yaml.jinja&quot;</span>
            <span class="s2">&quot;file exists defining the KubeRay config. Currently only google_cloud is supported.&quot;</span>
        <span class="p">),</span>
    <span class="p">)</span>

    <span class="n">arg_parser</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span>
        <span class="s2">&quot;--name&quot;</span><span class="p">,</span>
        <span class="nb">type</span><span class="o">=</span><span class="nb">str</span><span class="p">,</span>
        <span class="n">required</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
        <span class="n">default</span><span class="o">=</span><span class="s2">&quot;isaacray&quot;</span><span class="p">,</span>
        <span class="n">help</span><span class="o">=</span><span class="s2">&quot;Name of the Kubernetes deployment.&quot;</span><span class="p">,</span>
    <span class="p">)</span>

    <span class="n">arg_parser</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span>
        <span class="s2">&quot;--namespace&quot;</span><span class="p">,</span>
        <span class="nb">type</span><span class="o">=</span><span class="nb">str</span><span class="p">,</span>
        <span class="n">required</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
        <span class="n">default</span><span class="o">=</span><span class="s2">&quot;default&quot;</span><span class="p">,</span>
        <span class="n">help</span><span class="o">=</span><span class="s2">&quot;Kubernetes namespace to deploy the Ray cluster.&quot;</span><span class="p">,</span>
    <span class="p">)</span>

    <span class="n">arg_parser</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span>
        <span class="s2">&quot;--service_acount_name&quot;</span><span class="p">,</span> <span class="nb">type</span><span class="o">=</span><span class="nb">str</span><span class="p">,</span> <span class="n">required</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="s2">&quot;default&quot;</span><span class="p">,</span> <span class="n">help</span><span class="o">=</span><span class="s2">&quot;The service account name to use.&quot;</span>
    <span class="p">)</span>

    <span class="n">arg_parser</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span>
        <span class="s2">&quot;--image&quot;</span><span class="p">,</span>
        <span class="nb">type</span><span class="o">=</span><span class="nb">str</span><span class="p">,</span>
        <span class="n">required</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
        <span class="n">help</span><span class="o">=</span><span class="s2">&quot;Docker image for the Ray cluster pods.&quot;</span><span class="p">,</span>
    <span class="p">)</span>

    <span class="n">arg_parser</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span>
        <span class="s2">&quot;--worker_accelerator&quot;</span><span class="p">,</span>
        <span class="n">nargs</span><span class="o">=</span><span class="s2">&quot;+&quot;</span><span class="p">,</span>
        <span class="nb">type</span><span class="o">=</span><span class="nb">str</span><span class="p">,</span>
        <span class="n">default</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;nvidia-l4&quot;</span><span class="p">],</span>
        <span class="n">help</span><span class="o">=</span><span class="s2">&quot;GPU accelerator name. Supply more than one for heterogeneous resources.&quot;</span><span class="p">,</span>
    <span class="p">)</span>

    <span class="n">arg_parser</span> <span class="o">=</span> <span class="n">util</span><span class="o">.</span><span class="n">add_resource_arguments</span><span class="p">(</span><span class="n">arg_parser</span><span class="p">,</span> <span class="n">cluster_create_defaults</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

    <span class="n">arg_parser</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span>
        <span class="s2">&quot;--num_clusters&quot;</span><span class="p">,</span>
        <span class="nb">type</span><span class="o">=</span><span class="nb">int</span><span class="p">,</span>
        <span class="n">default</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">help</span><span class="o">=</span><span class="s2">&quot;How many Ray Clusters to create.&quot;</span><span class="p">,</span>
    <span class="p">)</span>
    <span class="n">arg_parser</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span>
        <span class="s2">&quot;--num_head_cpu&quot;</span><span class="p">,</span>
        <span class="nb">type</span><span class="o">=</span><span class="nb">float</span><span class="p">,</span>  <span class="c1"># to be able to schedule partial CPU heads</span>
        <span class="n">default</span><span class="o">=</span><span class="mi">8</span><span class="p">,</span>
        <span class="n">help</span><span class="o">=</span><span class="s2">&quot;The number of CPUs to give the Ray head.&quot;</span><span class="p">,</span>
    <span class="p">)</span>

    <span class="n">arg_parser</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span><span class="s2">&quot;--head_ram_gb&quot;</span><span class="p">,</span> <span class="nb">type</span><span class="o">=</span><span class="nb">int</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="mi">8</span><span class="p">,</span> <span class="n">help</span><span class="o">=</span><span class="s2">&quot;How many gigs of ram to give the Ray head&quot;</span><span class="p">)</span>
    <span class="n">args</span> <span class="o">=</span> <span class="n">arg_parser</span><span class="o">.</span><span class="n">parse_args</span><span class="p">()</span>
    <span class="k">return</span> <span class="n">util</span><span class="o">.</span><span class="n">fill_in_missing_resources</span><span class="p">(</span><span class="n">args</span><span class="p">,</span> <span class="n">cluster_creation_flag</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>


<span class="k">def</span><span class="w"> </span><span class="nf">main</span><span class="p">():</span>
    <span class="n">args</span> <span class="o">=</span> <span class="n">parse_args</span><span class="p">()</span>

    <span class="k">if</span> <span class="s2">&quot;head&quot;</span> <span class="ow">in</span> <span class="n">args</span><span class="o">.</span><span class="n">name</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;For compatibility with other scripts, do not include head in the name&quot;</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">args</span><span class="o">.</span><span class="n">num_clusters</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
        <span class="n">apply_manifest</span><span class="p">(</span><span class="n">args</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">default_name</span> <span class="o">=</span> <span class="n">args</span><span class="o">.</span><span class="n">name</span>
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">args</span><span class="o">.</span><span class="n">num_clusters</span><span class="p">):</span>
            <span class="n">args</span><span class="o">.</span><span class="n">name</span> <span class="o">=</span> <span class="n">default_name</span> <span class="o">+</span> <span class="s2">&quot;-&quot;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">i</span><span class="p">)</span>
            <span class="n">apply_manifest</span><span class="p">(</span><span class="n">args</span><span class="p">)</span>


<span class="k">if</span> <span class="vm">__name__</span> <span class="o">==</span> <span class="s2">&quot;__main__&quot;</span><span class="p">:</span>
    <span class="n">main</span><span class="p">()</span>
</pre></div>
</div>
</div>
</details></section>
<section id="docker-based-local-quickstart">
<h2>基于 Docker 的本地快速启动<a class="headerlink" href="#docker-based-local-quickstart" title="此标题的永久链接">#</a></h2>
<p>首先，按照 <a class="reference external" href="https://isaac-sim.github.io/IsaacLab/main/source/deployment/docker.html">Docker Guide</a> 设置 NVIDIA Container Toolkit 和 Docker Compose。</p>
<p>然后，执行以下步骤以开始调整运行。</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><span class="c1"># Build the base image, but we don&#39;t need to run it</span>
python3<span class="w"> </span>docker/container.py<span class="w"> </span>start<span class="w"> </span><span class="o">&amp;&amp;</span><span class="w"> </span>python3<span class="w"> </span>docker/container.py<span class="w"> </span>stop
<span class="c1"># Build the tuning image with extra deps</span>
docker<span class="w"> </span>build<span class="w"> </span>-t<span class="w"> </span>isaacray<span class="w"> </span>-f<span class="w"> </span>scripts/reinforcement_learning/ray/cluster_configs/Dockerfile<span class="w"> </span>.
<span class="c1"># Start the tuning image - symlink so that changes in the source folder show up in the container</span>
docker<span class="w"> </span>run<span class="w"> </span>-v<span class="w"> </span><span class="k">$(</span><span class="nb">pwd</span><span class="k">)</span>/source:/workspace/isaaclab/source<span class="w"> </span>-it<span class="w"> </span>--gpus<span class="w"> </span>all<span class="w"> </span>--net<span class="o">=</span>host<span class="w"> </span>--entrypoint<span class="w"> </span>/bin/bash<span class="w"> </span>isaacray
<span class="c1"># Start the Ray server within the tuning image</span>
<span class="nb">echo</span><span class="w"> </span><span class="s2">&quot;import ray; ray.init(); import time; [time.sleep(10) for _ in iter(int, 1)]&quot;</span><span class="w"> </span><span class="p">|</span><span class="w"> </span>./isaaclab.sh<span class="w"> </span>-p
</pre></div>
</div>
<p>在另一个终端中，运行以下命令。</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><span class="c1"># In a new terminal (don&#39;t close the above) , enter the image with a new shell.</span>
docker<span class="w"> </span>container<span class="w"> </span>ps
docker<span class="w"> </span><span class="nb">exec</span><span class="w"> </span>-it<span class="w"> </span>&lt;ISAAC_RAY_IMAGE_ID_FROM_CONTAINER_PS&gt;<span class="w"> </span>/bin/bash
<span class="c1"># Start a tuning run, with one parallel worker per GPU</span>
./isaaclab.sh<span class="w"> </span>-p<span class="w"> </span>scripts/reinforcement_learning/ray/tuner.py<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>--cfg_file<span class="w"> </span>scripts/reinforcement_learning/ray/hyperparameter_tuning/vision_cartpole_cfg.py<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>--cfg_class<span class="w"> </span>CartpoleTheiaJobCfg<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>--run_mode<span class="w"> </span><span class="nb">local</span><span class="w"> </span><span class="se">\</span>
<span class="w">  </span>--workflow<span class="w"> </span>scripts/reinforcement_learning/rl_games/train.py<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>--num_workers_per_node<span class="w"> </span>&lt;NUMBER_OF_GPUS_IN_COMPUTER&gt;
</pre></div>
</div>
<p>要查看训练日志，请在另一个终端中运行以下命令，并在浏览器中访问 <code class="docutils literal notranslate"><span class="pre">localhost:6006</span></code> 。</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><span class="c1"># In a new terminal (don&#39;t close the above) , enter the image with a new shell.</span>
docker<span class="w"> </span>container<span class="w"> </span>ps
docker<span class="w"> </span><span class="nb">exec</span><span class="w"> </span>-it<span class="w"> </span>&lt;ISAAC_RAY_IMAGE_ID_FROM_CONTAINER_PS&gt;<span class="w"> </span>/bin/bash
<span class="c1"># Start a tuning run, with one parallel worker per GPU</span>
tensorboard<span class="w"> </span>--logdir<span class="o">=</span>.
</pre></div>
</div>
<p>提交资源包装的单个作业而不是自动调优运行的内容在以下文件中描述。</p>
<details class="sd-sphinx-override sd-dropdown sd-card sd-mb-3">
<summary class="sd-summary-title sd-card-header">
<span class="sd-summary-icon"><svg version="1.1" width="1.0em" height="1.0em" class="sd-octicon sd-octicon-code" viewBox="0 0 16 16" aria-hidden="true"><path d="m11.28 3.22 4.25 4.25a.75.75 0 0 1 0 1.06l-4.25 4.25a.749.749 0 0 1-1.275-.326.749.749 0 0 1 .215-.734L13.94 8l-3.72-3.72a.749.749 0 0 1 .326-1.275.749.749 0 0 1 .734.215Zm-6.56 0a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042L2.06 8l3.72 3.72a.749.749 0 0 1-.326 1.275.749.749 0 0 1-.734-.215L.47 8.53a.75.75 0 0 1 0-1.06Z"></path></svg></span><span class="sd-summary-text">scripts/reinforcement_learning/ray/wrap_resources.py</span><span class="sd-summary-state-marker sd-summary-chevron-right"><svg version="1.1" width="1.5em" height="1.5em" class="sd-octicon sd-octicon-chevron-right" viewBox="0 0 24 24" aria-hidden="true"><path d="M8.72 18.78a.75.75 0 0 1 0-1.06L14.44 12 8.72 6.28a.751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018l6.25 6.25a.75.75 0 0 1 0 1.06l-6.25 6.25a.75.75 0 0 1-1.06 0Z"></path></svg></span></summary><div class="sd-summary-content sd-card-body docutils">
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># Copyright (c) 2022-2025, The Isaac Lab Project Developers (https://github.com/isaac-sim/IsaacLab/blob/main/CONTRIBUTORS.md).</span>
<span class="c1"># All rights reserved.</span>
<span class="c1">#</span>
<span class="c1"># SPDX-License-Identifier: BSD-3-Clause</span>

<span class="sd">&quot;&quot;&quot;</span>
<span class="sd">This script dispatches sub-job(s) (individual jobs, use :file:`tuner.py` for tuning jobs)</span>
<span class="sd">to worker(s) on GPU-enabled node(s) of a specific cluster as part of an resource-wrapped aggregate</span>
<span class="sd">job. If no desired compute resources for each sub-job are specified,</span>
<span class="hll"><span class="sd">this script creates one worker per available node for each node with GPU(s) in the cluster.</span>
</span><span class="hll"><span class="sd">If the desired resources for each sub-job is specified,</span>
</span><span class="hll"><span class="sd">the maximum number of workers possible with the desired resources are created for each node</span>
</span><span class="hll"><span class="sd">with GPU(s) in the cluster. It is also possible to split available node resources for each node</span>
</span><span class="hll"><span class="sd">into the desired number of workers with the ``--num_workers`` flag, to be able to easily</span>
</span><span class="hll"><span class="sd">parallelize sub-jobs on multi-GPU nodes. Due to Isaac Lab requiring a GPU,</span>
</span><span class="hll"><span class="sd">this ignores all CPU only nodes such as loggers.</span>
</span><span class="hll">
</span><span class="hll"><span class="sd">Sub-jobs are matched with node(s) in a cluster via the following relation:</span>
</span><span class="hll"><span class="sd">sorted_nodes = Node sorted by descending GPUs, then descending CPUs, then descending RAM, then node ID</span>
</span><span class="hll"><span class="sd">node_submitted_to = sorted_nodes[job_index % total_node_count]</span>
</span><span class="hll">
</span><span class="hll"><span class="sd">To check the ordering of sorted nodes, supply the ``--test`` argument and run the script.</span>
</span><span class="hll">
</span><span class="hll"><span class="sd">Sub-jobs are separated by the + delimiter. The ``--sub_jobs`` argument must be the last</span>
</span><span class="hll"><span class="sd">argument supplied to the script.</span>
</span><span class="hll">
</span><span class="hll"><span class="sd">If there is more than one available worker, and more than one sub-job,</span>
</span><span class="hll"><span class="sd">sub-jobs will be executed in parallel. If there are more sub-jobs than workers, sub-jobs will</span>
</span><span class="hll"><span class="sd">be dispatched to workers as they become available. There is no limit on the number</span>
</span><span class="hll"><span class="sd">of sub-jobs that can be near-simultaneously submitted.</span>
</span><span class="hll">
</span><span class="hll"><span class="sd">This script is meant to be executed on a Ray cluster head node as an aggregate cluster job.</span>
</span><span class="hll"><span class="sd">To submit aggregate cluster jobs such as this script to one or more remote clusters,</span>
</span><span class="hll"><span class="sd">see :file:`../submit_isaac_ray_job.py`.</span>
</span><span class="hll">
</span><span class="hll"><span class="sd">KubeRay clusters on Google GKE can be created with :file:`../launch.py`</span>
</span><span class="hll">
</span><span class="hll"><span class="sd">Usage:</span>
</span><span class="hll">
</span><span class="hll"><span class="sd">.. code-block:: bash</span>
</span><span class="hll"><span class="sd">    # **Ensure that sub-jobs are separated by the ``+`` delimiter.**</span>
</span><span class="hll"><span class="sd">    # Generic Templates-----------------------------------</span>
</span><span class="hll"><span class="sd">    ./isaaclab.sh -p scripts/reinforcement_learning/ray/wrap_resources.py -h</span>
</span><span class="hll"><span class="sd">    # No resource isolation; no parallelization:</span>
</span><span class="hll"><span class="sd">    ./isaaclab.sh -p scripts/reinforcement_learning/ray/wrap_resources.py</span>
</span><span class="hll"><span class="sd">    --sub_jobs &lt;JOB0&gt;+&lt;JOB1&gt;+&lt;JOB2&gt;</span>
</span><span class="hll"><span class="sd">    # Automatic Resource Isolation; Example A: needed for parallelization</span>
</span><span class="hll"><span class="sd">    ./isaaclab.sh -p scripts/reinforcement_learning/ray/wrap_resources.py \</span>
</span><span class="hll"><span class="sd">    --num_workers &lt;NUM_TO_DIVIDE_TOTAL_RESOURCES_BY&gt; \</span>
</span><span class="hll"><span class="sd">    --sub_jobs &lt;JOB0&gt;+&lt;JOB1&gt;</span>
</span><span class="hll"><span class="sd">    # Manual Resource Isolation; Example B:  needed for parallelization</span>
</span><span class="hll"><span class="sd">    ./isaaclab.sh -p scripts/reinforcement_learning/ray/wrap_resources.py --num_cpu_per_worker &lt;CPU&gt; \</span>
</span><span class="hll"><span class="sd">    --gpu_per_worker &lt;GPU&gt; --ram_gb_per_worker &lt;RAM&gt; --sub_jobs &lt;JOB0&gt;+&lt;JOB1&gt;</span>
</span><span class="hll"><span class="sd">    # Manual Resource Isolation; Example C: Needed for parallelization, for heterogeneous workloads</span>
</span><span class="hll"><span class="sd">    ./isaaclab.sh -p scripts/reinforcement_learning/ray/wrap_resources.py --num_cpu_per_worker &lt;CPU&gt; \</span>
</span><span class="hll"><span class="sd">    --gpu_per_worker &lt;GPU1&gt; &lt;GPU2&gt; --ram_gb_per_worker &lt;RAM&gt; --sub_jobs &lt;JOB0&gt;+&lt;JOB1&gt;</span>
</span><span class="hll"><span class="sd">    # to see all arguments</span>
</span><span class="hll"><span class="sd">    ./isaaclab.sh -p scripts/reinforcement_learning/ray/wrap_resources.py -h</span>
</span><span class="hll"><span class="sd">&quot;&quot;&quot;</span>
</span><span class="hll">
</span><span class="hll"><span class="kn">import</span><span class="w"> </span><span class="nn">argparse</span>
</span><span class="hll">
</span><span class="hll"><span class="kn">import</span><span class="w"> </span><span class="nn">util</span>
</span>

<span class="k">def</span><span class="w"> </span><span class="nf">wrap_resources_to_jobs</span><span class="p">(</span><span class="n">jobs</span><span class="p">:</span> <span class="nb">list</span><span class="p">[</span><span class="nb">str</span><span class="p">],</span> <span class="n">args</span><span class="p">:</span> <span class="n">argparse</span><span class="o">.</span><span class="n">Namespace</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Provided a list of jobs, dispatch jobs to one worker per available node,</span>
<span class="sd">    unless otherwise specified by resource constraints.</span>

<span class="sd">    Args:</span>
<span class="sd">        jobs: bash commands to execute on a Ray cluster</span>
<span class="sd">        args: The arguments for resource allocation</span>

<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">job_objs</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">util</span><span class="o">.</span><span class="n">ray_init</span><span class="p">(</span>
        <span class="n">ray_address</span><span class="o">=</span><span class="n">args</span><span class="o">.</span><span class="n">ray_address</span><span class="p">,</span>
        <span class="n">runtime_env</span><span class="o">=</span><span class="p">{</span>
            <span class="s2">&quot;py_modules&quot;</span><span class="p">:</span> <span class="kc">None</span> <span class="k">if</span> <span class="ow">not</span> <span class="n">args</span><span class="o">.</span><span class="n">py_modules</span> <span class="k">else</span> <span class="n">args</span><span class="o">.</span><span class="n">py_modules</span><span class="p">,</span>
        <span class="p">},</span>
        <span class="n">log_to_driver</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
    <span class="p">)</span>
    <span class="n">gpu_node_resources</span> <span class="o">=</span> <span class="n">util</span><span class="o">.</span><span class="n">get_gpu_node_resources</span><span class="p">(</span><span class="n">include_id</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">include_gb_ram</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

    <span class="k">if</span> <span class="nb">any</span><span class="p">([</span><span class="n">args</span><span class="o">.</span><span class="n">gpu_per_worker</span><span class="p">,</span> <span class="n">args</span><span class="o">.</span><span class="n">cpu_per_worker</span><span class="p">,</span> <span class="n">args</span><span class="o">.</span><span class="n">ram_gb_per_worker</span><span class="p">])</span> <span class="ow">and</span> <span class="n">args</span><span class="o">.</span><span class="n">num_workers</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;Either specify only num_workers or only granular resources(GPU,CPU,RAM_GB).&quot;</span><span class="p">)</span>

    <span class="n">num_nodes</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">gpu_node_resources</span><span class="p">)</span>
    <span class="c1"># Populate arguments</span>
    <span class="n">formatted_node_resources</span> <span class="o">=</span> <span class="p">{</span>
        <span class="s2">&quot;gpu_per_worker&quot;</span><span class="p">:</span> <span class="p">[</span><span class="n">gpu_node_resources</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="s2">&quot;GPU&quot;</span><span class="p">]</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">num_nodes</span><span class="p">)],</span>
        <span class="s2">&quot;cpu_per_worker&quot;</span><span class="p">:</span> <span class="p">[</span><span class="n">gpu_node_resources</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="s2">&quot;CPU&quot;</span><span class="p">]</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">num_nodes</span><span class="p">)],</span>
        <span class="s2">&quot;ram_gb_per_worker&quot;</span><span class="p">:</span> <span class="p">[</span><span class="n">gpu_node_resources</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="s2">&quot;ram_gb&quot;</span><span class="p">]</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">num_nodes</span><span class="p">)],</span>
        <span class="s2">&quot;num_workers&quot;</span><span class="p">:</span> <span class="n">args</span><span class="o">.</span><span class="n">num_workers</span><span class="p">,</span>  <span class="c1"># By default, 1 worker por node</span>
    <span class="p">}</span>
    <span class="n">args</span> <span class="o">=</span> <span class="n">util</span><span class="o">.</span><span class="n">fill_in_missing_resources</span><span class="p">(</span><span class="n">args</span><span class="p">,</span> <span class="n">resources</span><span class="o">=</span><span class="n">formatted_node_resources</span><span class="p">,</span> <span class="n">policy</span><span class="o">=</span><span class="nb">min</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;[INFO]: Number of GPU nodes found: </span><span class="si">{</span><span class="n">num_nodes</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">args</span><span class="o">.</span><span class="n">test</span><span class="p">:</span>
        <span class="n">jobs</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;nvidia-smi&quot;</span><span class="p">]</span> <span class="o">*</span> <span class="n">num_nodes</span>
    <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">job</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">jobs</span><span class="p">):</span>
        <span class="n">gpu_node</span> <span class="o">=</span> <span class="n">gpu_node_resources</span><span class="p">[</span><span class="n">i</span> <span class="o">%</span> <span class="n">num_nodes</span><span class="p">]</span>
        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;[INFO]: Creating job </span><span class="si">{</span><span class="n">i</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="mi">1</span><span class="si">}</span><span class="s2"> of </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">jobs</span><span class="p">)</span><span class="si">}</span><span class="s2"> with job &#39;</span><span class="si">{</span><span class="n">job</span><span class="si">}</span><span class="s2">&#39; to node </span><span class="si">{</span><span class="n">gpu_node</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
        <span class="nb">print</span><span class="p">(</span>
            <span class="sa">f</span><span class="s2">&quot;[INFO]: Resource parameters: GPU: </span><span class="si">{</span><span class="n">args</span><span class="o">.</span><span class="n">gpu_per_worker</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="si">}</span><span class="s2">&quot;</span>
            <span class="sa">f</span><span class="s2">&quot; CPU: </span><span class="si">{</span><span class="n">args</span><span class="o">.</span><span class="n">cpu_per_worker</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="si">}</span><span class="s2"> RAM </span><span class="si">{</span><span class="n">args</span><span class="o">.</span><span class="n">ram_gb_per_worker</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="si">}</span><span class="s2">&quot;</span>
        <span class="p">)</span>
        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;[INFO] For the node parameters, creating </span><span class="si">{</span><span class="n">args</span><span class="o">.</span><span class="n">num_workers</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="si">}</span><span class="s2"> workers&quot;</span><span class="p">)</span>
        <span class="n">num_gpus</span> <span class="o">=</span> <span class="n">args</span><span class="o">.</span><span class="n">gpu_per_worker</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">/</span> <span class="n">args</span><span class="o">.</span><span class="n">num_workers</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>
        <span class="n">num_cpus</span> <span class="o">=</span> <span class="n">args</span><span class="o">.</span><span class="n">cpu_per_worker</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">/</span> <span class="n">args</span><span class="o">.</span><span class="n">num_workers</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>
        <span class="n">memory</span> <span class="o">=</span> <span class="p">(</span><span class="n">args</span><span class="o">.</span><span class="n">ram_gb_per_worker</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">*</span> <span class="mi">1024</span><span class="o">**</span><span class="mi">3</span><span class="p">)</span> <span class="o">/</span> <span class="n">args</span><span class="o">.</span><span class="n">num_workers</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>
        <span class="n">job_objs</span><span class="o">.</span><span class="n">append</span><span class="p">(</span>
            <span class="n">util</span><span class="o">.</span><span class="n">Job</span><span class="p">(</span>
                <span class="n">cmd</span><span class="o">=</span><span class="n">job</span><span class="p">,</span>
                <span class="n">name</span><span class="o">=</span><span class="sa">f</span><span class="s2">&quot;Job-</span><span class="si">{</span><span class="n">i</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="mi">1</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">,</span>
                <span class="n">resources</span><span class="o">=</span><span class="n">util</span><span class="o">.</span><span class="n">JobResource</span><span class="p">(</span><span class="n">num_gpus</span><span class="o">=</span><span class="n">num_gpus</span><span class="p">,</span> <span class="n">num_cpus</span><span class="o">=</span><span class="n">num_cpus</span><span class="p">,</span> <span class="n">memory</span><span class="o">=</span><span class="n">memory</span><span class="p">),</span>
                <span class="n">node</span><span class="o">=</span><span class="n">util</span><span class="o">.</span><span class="n">JobNode</span><span class="p">(</span>
                    <span class="n">specific</span><span class="o">=</span><span class="s2">&quot;node_id&quot;</span><span class="p">,</span>
                    <span class="n">node_id</span><span class="o">=</span><span class="n">gpu_node</span><span class="p">[</span><span class="s2">&quot;id&quot;</span><span class="p">],</span>
                <span class="p">),</span>
            <span class="p">)</span>
        <span class="p">)</span>
    <span class="c1"># submit jobs</span>
    <span class="n">util</span><span class="o">.</span><span class="n">submit_wrapped_jobs</span><span class="p">(</span><span class="n">jobs</span><span class="o">=</span><span class="n">job_objs</span><span class="p">,</span> <span class="n">test_mode</span><span class="o">=</span><span class="n">args</span><span class="o">.</span><span class="n">test</span><span class="p">,</span> <span class="n">concurrent</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>


<span class="k">if</span> <span class="vm">__name__</span> <span class="o">==</span> <span class="s2">&quot;__main__&quot;</span><span class="p">:</span>
    <span class="n">parser</span> <span class="o">=</span> <span class="n">argparse</span><span class="o">.</span><span class="n">ArgumentParser</span><span class="p">(</span><span class="n">description</span><span class="o">=</span><span class="s2">&quot;Submit multiple jobs with optional GPU testing.&quot;</span><span class="p">)</span>
    <span class="n">parser</span> <span class="o">=</span> <span class="n">util</span><span class="o">.</span><span class="n">add_resource_arguments</span><span class="p">(</span><span class="n">arg_parser</span><span class="o">=</span><span class="n">parser</span><span class="p">)</span>
    <span class="n">parser</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span><span class="s2">&quot;--ray_address&quot;</span><span class="p">,</span> <span class="nb">type</span><span class="o">=</span><span class="nb">str</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="s2">&quot;auto&quot;</span><span class="p">,</span> <span class="n">help</span><span class="o">=</span><span class="s2">&quot;the Ray address.&quot;</span><span class="p">)</span>
    <span class="n">parser</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span>
        <span class="s2">&quot;--test&quot;</span><span class="p">,</span>
        <span class="n">action</span><span class="o">=</span><span class="s2">&quot;store_true&quot;</span><span class="p">,</span>
        <span class="n">help</span><span class="o">=</span><span class="p">(</span>
            <span class="s2">&quot;Run nvidia-smi test instead of the arbitrary job,&quot;</span>
            <span class="s2">&quot;can use as a sanity check prior to any jobs to check &quot;</span>
            <span class="s2">&quot;that GPU resources are correctly isolated.&quot;</span>
        <span class="p">),</span>
    <span class="p">)</span>
    <span class="n">parser</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span>
        <span class="s2">&quot;--py_modules&quot;</span><span class="p">,</span>
        <span class="nb">type</span><span class="o">=</span><span class="nb">str</span><span class="p">,</span>
        <span class="n">nargs</span><span class="o">=</span><span class="s2">&quot;*&quot;</span><span class="p">,</span>
        <span class="n">default</span><span class="o">=</span><span class="p">[],</span>
        <span class="n">help</span><span class="o">=</span><span class="p">(</span>
            <span class="s2">&quot;List of python modules or paths to add before running the job. Example: --py_modules my_package/my_package&quot;</span>
        <span class="p">),</span>
    <span class="p">)</span>
    <span class="n">parser</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span>
        <span class="s2">&quot;--sub_jobs&quot;</span><span class="p">,</span>
        <span class="nb">type</span><span class="o">=</span><span class="nb">str</span><span class="p">,</span>
        <span class="n">nargs</span><span class="o">=</span><span class="n">argparse</span><span class="o">.</span><span class="n">REMAINDER</span><span class="p">,</span>
        <span class="n">help</span><span class="o">=</span><span class="s2">&quot;This should be last wrapper argument. Jobs separated by the + delimiter to run on a cluster.&quot;</span><span class="p">,</span>
    <span class="p">)</span>
    <span class="n">args</span> <span class="o">=</span> <span class="n">parser</span><span class="o">.</span><span class="n">parse_args</span><span class="p">()</span>
    <span class="k">if</span> <span class="n">args</span><span class="o">.</span><span class="n">sub_jobs</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">jobs</span> <span class="o">=</span> <span class="s2">&quot; &quot;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">args</span><span class="o">.</span><span class="n">sub_jobs</span><span class="p">)</span>
        <span class="n">formatted_jobs</span> <span class="o">=</span> <span class="n">jobs</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s2">&quot;+&quot;</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">formatted_jobs</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;[INFO]: Isaac Ray Wrapper received jobs </span><span class="si">{</span><span class="n">formatted_jobs</span><span class="si">=}</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="n">wrap_resources_to_jobs</span><span class="p">(</span><span class="n">jobs</span><span class="o">=</span><span class="n">formatted_jobs</span><span class="p">,</span> <span class="n">args</span><span class="o">=</span><span class="n">args</span><span class="p">)</span>
</pre></div>
</div>
</div>
</details><p><code class="docutils literal notranslate"><span class="pre">task_runner.py</span></code> 通过单个声明性的 YAML 文件将 Python 任务分发到 Ray 集群。这种方法允许用户为每次运行指定额外的 pip packages 和 Python 模块。支持细粒度的资源分配，可以明确控制分配给每个任务的 CPU、GPU 和内存数量。该运行程序还提供高级调度功能：任务可以被限制在特定节点上按主机名或节点 ID 运行，并支持两种启动模式：任务可以在资源可用时独立执行，或者被分组成一个同时执行的批处理————这对于多节点训练工作非常理想，它确保所有任务仅在整个集群中有足够的资源可用时一起启动。</p>
<details class="sd-sphinx-override sd-dropdown sd-card sd-mb-3">
<summary class="sd-summary-title sd-card-header">
<span class="sd-summary-icon"><svg version="1.1" width="1.0em" height="1.0em" class="sd-octicon sd-octicon-code" viewBox="0 0 16 16" aria-hidden="true"><path d="m11.28 3.22 4.25 4.25a.75.75 0 0 1 0 1.06l-4.25 4.25a.749.749 0 0 1-1.275-.326.749.749 0 0 1 .215-.734L13.94 8l-3.72-3.72a.749.749 0 0 1 .326-1.275.749.749 0 0 1 .734.215Zm-6.56 0a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042L2.06 8l3.72 3.72a.749.749 0 0 1-.326 1.275.749.749 0 0 1-.734-.215L.47 8.53a.75.75 0 0 1 0-1.06Z"></path></svg></span><span class="sd-summary-text">scripts/reinforcement_learning/ray/task_runner.py</span><span class="sd-summary-state-marker sd-summary-chevron-right"><svg version="1.1" width="1.5em" height="1.5em" class="sd-octicon sd-octicon-chevron-right" viewBox="0 0 24 24" aria-hidden="true"><path d="M8.72 18.78a.75.75 0 0 1 0-1.06L14.44 12 8.72 6.28a.751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018l6.25 6.25a.75.75 0 0 1 0 1.06l-6.25 6.25a.75.75 0 0 1-1.06 0Z"></path></svg></span></summary><div class="sd-summary-content sd-card-body docutils">
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># Copyright (c) 2022-2025, The Isaac Lab Project Developers (https://github.com/isaac-sim/IsaacLab/blob/main/CONTRIBUTORS.md).</span>
<span class="c1"># All rights reserved.</span>
<span class="c1">#</span>
<span class="c1"># SPDX-License-Identifier: BSD-3-Clause</span>

<span class="sd">&quot;&quot;&quot;</span>
<span class="sd">This script dispatches one or more user-defined Python tasks to workers in a Ray cluster.</span>
<span class="sd">Each task, along with its resource requirements and execution parameters, is specified in a YAML configuration file.</span>
<span class="sd">Users may define the number of CPUs, GPUs, and the amount of memory to allocate per task via the config file.</span>

<span class="sd">Key features:</span>
<span class="sd">-------------</span>
<span class="hll"><span class="sd">- Fine-grained, per-task resource management via config fields (`num_gpus`, `num_cpus`, `memory`).</span>
</span><span class="hll"><span class="sd">- Parallel execution of multiple tasks using available resources across the Ray cluster.</span>
</span><span class="hll"><span class="sd">- Option to specify node affinity for tasks, e.g., by hostname, node ID, or any node.</span>
</span><span class="hll"><span class="sd">- Optional batch (simultaneous) or independent scheduling of tasks.</span>
</span><span class="hll">
</span><span class="hll"><span class="sd">Task scheduling and distribution are handled via Ray’s built-in resource manager.</span>
</span><span class="hll">
</span><span class="hll"><span class="sd">YAML configuration fields:</span>
</span><span class="hll"><span class="sd">--------------------------</span>
</span><span class="hll"><span class="sd">- `pip`: List of extra pip packages to install before running any tasks.</span>
</span><span class="hll"><span class="sd">- `py_modules`: List of additional Python module paths (directories or files) to include in the runtime environment.</span>
</span><span class="hll"><span class="sd">- `concurrent`: (bool) It determines task dispatch semantics:</span>
</span><span class="hll"><span class="sd">    - If `concurrent: true`, **all tasks are scheduled as a batch**. The script waits until sufficient resources are available for every task in the batch, then launches all tasks together. If resources are insufficient, all tasks remain blocked until the cluster can support the full batch.</span>
</span><span class="hll"><span class="sd">    - If `concurrent: false`, tasks are launched as soon as resources are available for each individual task, and Ray independently schedules them. This may result in non-simultaneous task start times.</span>
</span><span class="hll"><span class="sd">- `tasks`: List of task specifications, each with:</span>
</span><span class="hll"><span class="sd">    - `name`: String identifier for the task.</span>
</span><span class="hll"><span class="sd">    - `py_args`: Arguments to the Python interpreter (e.g., script/module, flags, user arguments).</span>
</span><span class="hll"><span class="sd">    - `num_gpus`: Number of GPUs to allocate (float or string arithmetic, e.g., &quot;2*2&quot;).</span>
</span><span class="hll"><span class="sd">    - `num_cpus`: Number of CPUs to allocate (float or string).</span>
</span><span class="hll"><span class="sd">    - `memory`: Amount of RAM in bytes (int or string).</span>
</span><span class="hll"><span class="sd">    - `node` (optional): Node placement constraints.</span>
</span><span class="hll"><span class="sd">        - `specific` (str): Type of node placement, support `hostname`, `node_id`, or `any`.</span>
</span><span class="hll"><span class="sd">            - `any`: Place the task on any available node.</span>
</span><span class="hll"><span class="sd">            - `hostname`: Place the task on a specific hostname. `hostname` must be specified in the node field.</span>
</span><span class="hll"><span class="sd">            - `node_id`: Place the task on a specific node ID. `node_id` must be specified in the node field.</span>
</span><span class="hll"><span class="sd">        - `hostname` (str): Specific hostname to place the task on.</span>
</span><span class="hll"><span class="sd">        - `node_id` (str): Specific node ID to place the task on.</span>
</span><span class="hll">
</span><span class="hll">
</span><span class="hll"><span class="sd">Typical usage:</span>
</span><span class="hll"><span class="sd">---------------</span>
</span><span class="hll">
</span><span class="hll"><span class="sd">.. code-block:: bash</span>
</span><span class="hll">
</span><span class="hll"><span class="sd">    # Print help and argument details:</span>
</span><span class="hll"><span class="sd">    python task_runner.py -h</span>
</span><span class="hll">
</span><span class="hll"><span class="sd">    # Submit tasks defined in a YAML file to the Ray cluster (auto-detects Ray head address):</span>
</span><span class="hll"><span class="sd">    python task_runner.py --task_cfg /path/to/tasks.yaml</span>
</span><span class="hll">
</span><span class="hll"><span class="sd">YAML configuration example-1:</span>
</span><span class="hll"><span class="sd">---------------------------</span>
</span><span class="hll"><span class="sd">.. code-block:: yaml</span>
</span><span class="hll">
</span><span class="hll"><span class="sd">    pip: [&quot;xxx&quot;]</span>
</span><span class="hll"><span class="sd">    py_modules: [&quot;my_package/my_package&quot;]</span>
</span><span class="hll"><span class="sd">    concurrent: false</span>
</span><span class="hll"><span class="sd">    tasks:</span>
</span><span class="hll"><span class="sd">      - name: &quot;Isaac-Cartpole-v0&quot;</span>
</span><span class="hll"><span class="sd">        py_args: &quot;-m torch.distributed.run --nnodes=1 --nproc_per_node=2  --rdzv_endpoint=localhost:29501 /workspace/isaaclab/scripts/reinforcement_learning/rsl_rl/train.py --task=Isaac-Cartpole-v0 --max_iterations 200 --headless --distributed&quot;</span>
</span><span class="hll"><span class="sd">        num_gpus: 2</span>
</span><span class="hll"><span class="sd">        num_cpus: 10</span>
</span><span class="hll"><span class="sd">        memory: 10737418240</span>
</span><span class="hll"><span class="sd">      - name: &quot;script need some dependencies&quot;</span>
</span><span class="hll"><span class="sd">        py_args: &quot;script.py --option arg&quot;</span>
</span><span class="hll"><span class="sd">        num_gpus: 0</span>
</span><span class="hll"><span class="sd">        num_cpus: 1</span>
</span><span class="hll"><span class="sd">        memory: 10*1024*1024*1024</span>
</span><span class="hll">
</span><span class="hll"><span class="sd">YAML configuration example-2:</span>
</span><span class="hll"><span class="sd">---------------------------</span>
</span><span class="hll"><span class="sd">.. code-block:: yaml</span>
</span><span class="hll">
</span><span class="hll"><span class="sd">    pip: [&quot;xxx&quot;]</span>
</span><span class="hll"><span class="sd">    py_modules: [&quot;my_package/my_package&quot;]</span>
</span><span class="hll"><span class="sd">    concurrent: true</span>
</span><span class="hll"><span class="sd">    tasks:</span>
</span><span class="hll"><span class="sd">    - name: &quot;Isaac-Cartpole-v0-multi-node-train-1&quot;</span>
</span><span class="hll"><span class="sd">        py_args: &quot;-m torch.distributed.run --nproc_per_node=1 --nnodes=2 --node_rank=0 --rdzv_id=123 --rdzv_backend=c10d --rdzv_endpoint=localhost:5555 /workspace/isaaclab/scripts/reinforcement_learning/rsl_rl/train.py --task=Isaac-Cartpole-v0 --headless --distributed --max_iterations 1000&quot;</span>
</span><span class="hll"><span class="sd">        num_gpus: 1</span>
</span><span class="hll"><span class="sd">        num_cpus: 10</span>
</span><span class="hll"><span class="sd">        memory: 10*1024*1024*1024</span>
</span><span class="hll"><span class="sd">        node:</span>
</span><span class="hll"><span class="sd">          specific: &quot;hostname&quot;</span>
</span><span class="hll"><span class="sd">          hostname: &quot;xxx&quot;</span>
</span><span class="hll"><span class="sd">    - name: &quot;Isaac-Cartpole-v0-multi-node-train-2&quot;</span>
</span><span class="hll"><span class="sd">        py_args: &quot;-m torch.distributed.run --nproc_per_node=1 --nnodes=2 --node_rank=1 --rdzv_id=123 --rdzv_backend=c10d --rdzv_endpoint=x.x.x.x:5555 /workspace/isaaclab/scripts/reinforcement_learning/rsl_rl/train.py --task=Isaac-Cartpole-v0 --headless --distributed --max_iterations 1000&quot;</span>
</span><span class="hll"><span class="sd">        num_gpus: 1</span>
</span><span class="hll"><span class="sd">        num_cpus: 10</span>
</span><span class="hll"><span class="sd">        memory: 10*1024*1024*1024</span>
</span><span class="hll"><span class="sd">        node:</span>
</span><span class="hll"><span class="sd">          specific: &quot;hostname&quot;</span>
</span><span class="hll"><span class="sd">          hostname: &quot;xxx&quot;</span>
</span><span class="hll">
</span><span class="hll"><span class="sd">To stop all tasks early, press Ctrl+C; the script will cancel all running Ray tasks.</span>
</span><span class="hll"><span class="sd">&quot;&quot;&quot;</span>
</span><span class="hll">
</span><span class="hll"><span class="kn">import</span><span class="w"> </span><span class="nn">argparse</span>
</span><span class="hll"><span class="kn">import</span><span class="w"> </span><span class="nn">yaml</span>
</span><span class="hll"><span class="kn">from</span><span class="w"> </span><span class="nn">datetime</span><span class="w"> </span><span class="kn">import</span> <span class="n">datetime</span>
</span><span class="hll">
</span><span class="hll"><span class="kn">import</span><span class="w"> </span><span class="nn">util</span>
</span><span class="hll">
</span>
<span class="k">def</span><span class="w"> </span><span class="nf">parse_args</span><span class="p">()</span> <span class="o">-&gt;</span> <span class="n">argparse</span><span class="o">.</span><span class="n">Namespace</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Parse command-line arguments for the Ray task runner.</span>

<span class="sd">    Returns:</span>
<span class="sd">        argparse.Namespace: The namespace containing parsed CLI arguments:</span>
<span class="sd">            - task_cfg (str): Path to the YAML task file.</span>
<span class="sd">            - ray_address (str): Ray cluster address.</span>
<span class="sd">            - test (bool): Whether to run a GPU resource isolation sanity check.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">parser</span> <span class="o">=</span> <span class="n">argparse</span><span class="o">.</span><span class="n">ArgumentParser</span><span class="p">(</span><span class="n">description</span><span class="o">=</span><span class="s2">&quot;Run tasks from a YAML config file.&quot;</span><span class="p">)</span>
    <span class="n">parser</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span><span class="s2">&quot;--task_cfg&quot;</span><span class="p">,</span> <span class="nb">type</span><span class="o">=</span><span class="nb">str</span><span class="p">,</span> <span class="n">required</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">help</span><span class="o">=</span><span class="s2">&quot;Path to the YAML task file.&quot;</span><span class="p">)</span>
    <span class="n">parser</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span><span class="s2">&quot;--ray_address&quot;</span><span class="p">,</span> <span class="nb">type</span><span class="o">=</span><span class="nb">str</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="s2">&quot;auto&quot;</span><span class="p">,</span> <span class="n">help</span><span class="o">=</span><span class="s2">&quot;the Ray address.&quot;</span><span class="p">)</span>
    <span class="n">parser</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span>
        <span class="s2">&quot;--test&quot;</span><span class="p">,</span>
        <span class="n">action</span><span class="o">=</span><span class="s2">&quot;store_true&quot;</span><span class="p">,</span>
        <span class="n">help</span><span class="o">=</span><span class="p">(</span>
            <span class="s2">&quot;Run nvidia-smi test instead of the arbitrary job,&quot;</span>
            <span class="s2">&quot;can use as a sanity check prior to any jobs to check &quot;</span>
            <span class="s2">&quot;that GPU resources are correctly isolated.&quot;</span>
        <span class="p">),</span>
    <span class="p">)</span>
    <span class="k">return</span> <span class="n">parser</span><span class="o">.</span><span class="n">parse_args</span><span class="p">()</span>


<span class="k">def</span><span class="w"> </span><span class="nf">parse_task_resource</span><span class="p">(</span><span class="n">task</span><span class="p">:</span> <span class="nb">dict</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">util</span><span class="o">.</span><span class="n">JobResource</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Parse task resource requirements from the YAML configuration.</span>

<span class="sd">    Args:</span>
<span class="sd">        task (dict): Dictionary representing a single task&#39;s configuration.</span>
<span class="sd">            Keys may include `num_gpus`, `num_cpus`, and `memory`, each either</span>
<span class="sd">            as a number or evaluatable string expression.</span>

<span class="sd">    Returns:</span>
<span class="sd">        util.JobResource: Resource object with the parsed values.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">resource</span> <span class="o">=</span> <span class="n">util</span><span class="o">.</span><span class="n">JobResource</span><span class="p">()</span>
    <span class="k">if</span> <span class="s2">&quot;num_gpus&quot;</span> <span class="ow">in</span> <span class="n">task</span><span class="p">:</span>
        <span class="n">resource</span><span class="o">.</span><span class="n">num_gpus</span> <span class="o">=</span> <span class="nb">eval</span><span class="p">(</span><span class="n">task</span><span class="p">[</span><span class="s2">&quot;num_gpus&quot;</span><span class="p">])</span> <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">task</span><span class="p">[</span><span class="s2">&quot;num_gpus&quot;</span><span class="p">],</span> <span class="nb">str</span><span class="p">)</span> <span class="k">else</span> <span class="n">task</span><span class="p">[</span><span class="s2">&quot;num_gpus&quot;</span><span class="p">]</span>
    <span class="k">if</span> <span class="s2">&quot;num_cpus&quot;</span> <span class="ow">in</span> <span class="n">task</span><span class="p">:</span>
        <span class="n">resource</span><span class="o">.</span><span class="n">num_cpus</span> <span class="o">=</span> <span class="nb">eval</span><span class="p">(</span><span class="n">task</span><span class="p">[</span><span class="s2">&quot;num_cpus&quot;</span><span class="p">])</span> <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">task</span><span class="p">[</span><span class="s2">&quot;num_cpus&quot;</span><span class="p">],</span> <span class="nb">str</span><span class="p">)</span> <span class="k">else</span> <span class="n">task</span><span class="p">[</span><span class="s2">&quot;num_cpus&quot;</span><span class="p">]</span>
    <span class="k">if</span> <span class="s2">&quot;memory&quot;</span> <span class="ow">in</span> <span class="n">task</span><span class="p">:</span>
        <span class="n">resource</span><span class="o">.</span><span class="n">memory</span> <span class="o">=</span> <span class="nb">eval</span><span class="p">(</span><span class="n">task</span><span class="p">[</span><span class="s2">&quot;memory&quot;</span><span class="p">])</span> <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">task</span><span class="p">[</span><span class="s2">&quot;memory&quot;</span><span class="p">],</span> <span class="nb">str</span><span class="p">)</span> <span class="k">else</span> <span class="n">task</span><span class="p">[</span><span class="s2">&quot;memory&quot;</span><span class="p">]</span>
    <span class="k">return</span> <span class="n">resource</span>


<span class="k">def</span><span class="w"> </span><span class="nf">run_tasks</span><span class="p">(</span>
    <span class="n">tasks</span><span class="p">:</span> <span class="nb">list</span><span class="p">[</span><span class="nb">dict</span><span class="p">],</span> <span class="n">args</span><span class="p">:</span> <span class="n">argparse</span><span class="o">.</span><span class="n">Namespace</span><span class="p">,</span> <span class="n">runtime_env</span><span class="p">:</span> <span class="nb">dict</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span> <span class="n">concurrent</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Submit tasks to the Ray cluster for execution.</span>

<span class="sd">    Args:</span>
<span class="sd">        tasks (list[dict]): A list of task configuration dictionaries.</span>
<span class="sd">        args (argparse.Namespace): Parsed command-line arguments.</span>
<span class="sd">        runtime_env (dict | None): Ray runtime environment configuration containing:</span>
<span class="sd">            - pip (list[str] | None): Additional pip packages to install.</span>
<span class="sd">            - py_modules (list[str] | None): Python modules to include in the environment.</span>
<span class="sd">        concurrent (bool): Whether to launch tasks simultaneously as a batch,</span>
<span class="sd">                           or independently as resources become available.</span>

<span class="sd">    Returns:</span>
<span class="sd">        None</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">job_objs</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">util</span><span class="o">.</span><span class="n">ray_init</span><span class="p">(</span><span class="n">ray_address</span><span class="o">=</span><span class="n">args</span><span class="o">.</span><span class="n">ray_address</span><span class="p">,</span> <span class="n">runtime_env</span><span class="o">=</span><span class="n">runtime_env</span><span class="p">,</span> <span class="n">log_to_driver</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">task</span> <span class="ow">in</span> <span class="n">tasks</span><span class="p">:</span>
        <span class="n">resource</span> <span class="o">=</span> <span class="n">parse_task_resource</span><span class="p">(</span><span class="n">task</span><span class="p">)</span>
        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;[INFO] Creating job </span><span class="si">{</span><span class="n">task</span><span class="p">[</span><span class="s1">&#39;name&#39;</span><span class="p">]</span><span class="si">}</span><span class="s2"> with resource=</span><span class="si">{</span><span class="n">resource</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
        <span class="n">job</span> <span class="o">=</span> <span class="n">util</span><span class="o">.</span><span class="n">Job</span><span class="p">(</span>
            <span class="n">name</span><span class="o">=</span><span class="n">task</span><span class="p">[</span><span class="s2">&quot;name&quot;</span><span class="p">],</span>
            <span class="n">py_args</span><span class="o">=</span><span class="n">task</span><span class="p">[</span><span class="s2">&quot;py_args&quot;</span><span class="p">],</span>
            <span class="n">resources</span><span class="o">=</span><span class="n">resource</span><span class="p">,</span>
            <span class="n">node</span><span class="o">=</span><span class="n">util</span><span class="o">.</span><span class="n">JobNode</span><span class="p">(</span>
                <span class="n">specific</span><span class="o">=</span><span class="n">task</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;node&quot;</span><span class="p">,</span> <span class="p">{})</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;specific&quot;</span><span class="p">),</span>
                <span class="n">hostname</span><span class="o">=</span><span class="n">task</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;node&quot;</span><span class="p">,</span> <span class="p">{})</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;hostname&quot;</span><span class="p">),</span>
                <span class="n">node_id</span><span class="o">=</span><span class="n">task</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;node&quot;</span><span class="p">,</span> <span class="p">{})</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;node_id&quot;</span><span class="p">),</span>
            <span class="p">),</span>
        <span class="p">)</span>
        <span class="n">job_objs</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">job</span><span class="p">)</span>
    <span class="n">start</span> <span class="o">=</span> <span class="n">datetime</span><span class="o">.</span><span class="n">now</span><span class="p">()</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;[INFO] Creating </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">job_objs</span><span class="p">)</span><span class="si">}</span><span class="s2"> jobs at </span><span class="si">{</span><span class="n">start</span><span class="o">.</span><span class="n">strftime</span><span class="p">(</span><span class="s1">&#39;%H:%M:%S.</span><span class="si">%f</span><span class="s1">&#39;</span><span class="p">)</span><span class="si">}</span><span class="s2"> with runtime env=</span><span class="si">{</span><span class="n">runtime_env</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="c1"># submit jobs</span>
    <span class="n">util</span><span class="o">.</span><span class="n">submit_wrapped_jobs</span><span class="p">(</span>
        <span class="n">jobs</span><span class="o">=</span><span class="n">job_objs</span><span class="p">,</span>
        <span class="n">test_mode</span><span class="o">=</span><span class="n">args</span><span class="o">.</span><span class="n">test</span><span class="p">,</span>
        <span class="n">concurrent</span><span class="o">=</span><span class="n">concurrent</span><span class="p">,</span>
    <span class="p">)</span>
    <span class="n">end</span> <span class="o">=</span> <span class="n">datetime</span><span class="o">.</span><span class="n">now</span><span class="p">()</span>
    <span class="nb">print</span><span class="p">(</span>
        <span class="sa">f</span><span class="s2">&quot;[INFO] All jobs completed at </span><span class="si">{</span><span class="n">end</span><span class="o">.</span><span class="n">strftime</span><span class="p">(</span><span class="s1">&#39;%H:%M:%S.</span><span class="si">%f</span><span class="s1">&#39;</span><span class="p">)</span><span class="si">}</span><span class="s2">, took </span><span class="si">{</span><span class="p">(</span><span class="n">end</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="n">start</span><span class="p">)</span><span class="o">.</span><span class="n">total_seconds</span><span class="p">()</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2"> seconds.&quot;</span>
    <span class="p">)</span>


<span class="k">def</span><span class="w"> </span><span class="nf">main</span><span class="p">()</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Main entry point for the Ray task runner script.</span>

<span class="sd">    Reads the YAML task configuration file, parses CLI arguments,</span>
<span class="sd">    and dispatches tasks to the Ray cluster.</span>

<span class="sd">    Returns:</span>
<span class="sd">        None</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">args</span> <span class="o">=</span> <span class="n">parse_args</span><span class="p">()</span>
    <span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">args</span><span class="o">.</span><span class="n">task_cfg</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
        <span class="n">config</span> <span class="o">=</span> <span class="n">yaml</span><span class="o">.</span><span class="n">safe_load</span><span class="p">(</span><span class="n">f</span><span class="p">)</span>
    <span class="n">tasks</span> <span class="o">=</span> <span class="n">config</span><span class="p">[</span><span class="s2">&quot;tasks&quot;</span><span class="p">]</span>
    <span class="n">runtime_env</span> <span class="o">=</span> <span class="p">{</span>
        <span class="s2">&quot;pip&quot;</span><span class="p">:</span> <span class="kc">None</span> <span class="k">if</span> <span class="ow">not</span> <span class="n">config</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;pip&quot;</span><span class="p">)</span> <span class="k">else</span> <span class="n">config</span><span class="p">[</span><span class="s2">&quot;pip&quot;</span><span class="p">],</span>
        <span class="s2">&quot;py_modules&quot;</span><span class="p">:</span> <span class="kc">None</span> <span class="k">if</span> <span class="ow">not</span> <span class="n">config</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;py_modules&quot;</span><span class="p">)</span> <span class="k">else</span> <span class="n">config</span><span class="p">[</span><span class="s2">&quot;py_modules&quot;</span><span class="p">],</span>
    <span class="p">}</span>
    <span class="n">concurrent</span> <span class="o">=</span> <span class="n">config</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;concurrent&quot;</span><span class="p">,</span> <span class="kc">False</span><span class="p">)</span>
    <span class="n">run_tasks</span><span class="p">(</span>
        <span class="n">tasks</span><span class="o">=</span><span class="n">tasks</span><span class="p">,</span>
        <span class="n">args</span><span class="o">=</span><span class="n">args</span><span class="p">,</span>
        <span class="n">runtime_env</span><span class="o">=</span><span class="n">runtime_env</span><span class="p">,</span>
        <span class="n">concurrent</span><span class="o">=</span><span class="n">concurrent</span><span class="p">,</span>
    <span class="p">)</span>


<span class="k">if</span> <span class="vm">__name__</span> <span class="o">==</span> <span class="s2">&quot;__main__&quot;</span><span class="p">:</span>
    <span class="n">main</span><span class="p">()</span>
</pre></div>
</div>
</div>
</details><p>使用此脚本，运行类似以下命令(用你的实际配置文件替换 <code class="docutils literal notranslate"><span class="pre">tasks.yaml</span></code>):</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>python3<span class="w"> </span>scripts/reinforcement_learning/ray/submit_job.py<span class="w"> </span>--aggregate_jobs<span class="w"> </span>task_runner.py<span class="w"> </span>--task_cfg<span class="w"> </span>tasks.yaml
</pre></div>
</div>
<p>有关如何编写您的 <code class="docutils literal notranslate"><span class="pre">tasks.yaml</span></code> 文件的详细说明，请参考 <code class="docutils literal notranslate"><span class="pre">task_runner.py</span></code> 中的注释。</p>
<p><strong>提示:</strong> 将 <code class="docutils literal notranslate"><span class="pre">tasks.yaml</span></code> 文件放在 <code class="docutils literal notranslate"><span class="pre">scripts/reinforcement_learning/ray</span></code> 目录中，这样当上传 <code class="docutils literal notranslate"><span class="pre">working_dir</span></code> 时它就会被包括进去。然后可以在命令中使用相对路径引用它。</p>
<p>从正在运行的容器中转移文件可以按照以下步骤进行。</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>docker<span class="w"> </span>container<span class="w"> </span>ps
docker<span class="w"> </span>cp<span class="w"> </span>&lt;ISAAC_RAY_IMAGE_ID_FROM_CONTAINER_PS&gt;:&lt;/path/in/container/file&gt;<span class="w">  </span>&lt;/path/on/host/&gt;
</pre></div>
</div>
<p>对于调优任务，指定调优任务 / 超参数搜索为 <code class="xref py py-class docutils literal notranslate"><span class="pre">JobCfg</span></code> 的子类。由于环境入口点和 hydra 参数的差异，所包含的 <code class="xref py py-class docutils literal notranslate"><span class="pre">JobCfg</span></code> 仅支持 <code class="docutils literal notranslate"><span class="pre">rl_games</span></code> 工作流，尽管如果提供兼容的 <code class="xref py py-class docutils literal notranslate"><span class="pre">JobCfg</span></code> ，其他工作流也能正常工作。</p>
<details class="sd-sphinx-override sd-dropdown sd-card sd-mb-3">
<summary class="sd-summary-title sd-card-header">
<span class="sd-summary-icon"><svg version="1.1" width="1.0em" height="1.0em" class="sd-octicon sd-octicon-code" viewBox="0 0 16 16" aria-hidden="true"><path d="m11.28 3.22 4.25 4.25a.75.75 0 0 1 0 1.06l-4.25 4.25a.749.749 0 0 1-1.275-.326.749.749 0 0 1 .215-.734L13.94 8l-3.72-3.72a.749.749 0 0 1 .326-1.275.749.749 0 0 1 .734.215Zm-6.56 0a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042L2.06 8l3.72 3.72a.749.749 0 0 1-.326 1.275.749.749 0 0 1-.734-.215L.47 8.53a.75.75 0 0 1 0-1.06Z"></path></svg></span><span class="sd-summary-text">scripts/reinforcement_learning/ray/tuner.py (JobCfg 定义)</span><span class="sd-summary-state-marker sd-summary-chevron-right"><svg version="1.1" width="1.5em" height="1.5em" class="sd-octicon sd-octicon-chevron-right" viewBox="0 0 24 24" aria-hidden="true"><path d="M8.72 18.78a.75.75 0 0 1 0-1.06L14.44 12 8.72 6.28a.751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018l6.25 6.25a.75.75 0 0 1 0 1.06l-6.25 6.25a.75.75 0 0 1-1.06 0Z"></path></svg></span></summary><div class="sd-summary-content sd-card-body docutils">
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">class</span><span class="w"> </span><span class="nc">JobCfg</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;To be compatible with :meth: invoke_tuning_run and :class:IsaacLabTuneTrainable,</span>
<span class="sd">    at a minimum, the tune job should inherit from this class.&quot;&quot;&quot;</span>

    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">cfg</span><span class="p">:</span> <span class="nb">dict</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Runner args include command line arguments passed to the task.</span>
<span class="sd">        For example:</span>
<span class="sd">        cfg[&quot;runner_args&quot;][&quot;headless_singleton&quot;] = &quot;--headless&quot;</span>
<span class="sd">        cfg[&quot;runner_args&quot;][&quot;enable_cameras_singleton&quot;] = &quot;--enable_cameras&quot;</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">assert</span> <span class="s2">&quot;runner_args&quot;</span> <span class="ow">in</span> <span class="n">cfg</span><span class="p">,</span> <span class="s2">&quot;No runner arguments specified.&quot;</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Task is the desired task to train on. For example:</span>
<span class="sd">        cfg[&quot;runner_args&quot;][&quot;--task&quot;] = tune.choice([&quot;Isaac-Cartpole-RGB-TheiaTiny-v0&quot;])</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">assert</span> <span class="s2">&quot;--task&quot;</span> <span class="ow">in</span> <span class="n">cfg</span><span class="p">[</span><span class="s2">&quot;runner_args&quot;</span><span class="p">],</span> <span class="s2">&quot;No task specified.&quot;</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Hydra args define the hyperparameters varied within the sweep. For example:</span>
<span class="sd">        cfg[&quot;hydra_args&quot;][&quot;agent.params.network.cnn.activation&quot;] = tune.choice([&quot;relu&quot;, &quot;elu&quot;])</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">assert</span> <span class="s2">&quot;hydra_args&quot;</span> <span class="ow">in</span> <span class="n">cfg</span><span class="p">,</span> <span class="s2">&quot;No hyperparameters specified.&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">cfg</span> <span class="o">=</span> <span class="n">cfg</span>
</pre></div>
</div>
</div>
</details><p>例如，请参阅 Cartpole 示例配置。</p>
<details class="sd-sphinx-override sd-dropdown sd-card sd-mb-3">
<summary class="sd-summary-title sd-card-header">
<span class="sd-summary-icon"><svg version="1.1" width="1.0em" height="1.0em" class="sd-octicon sd-octicon-code" viewBox="0 0 16 16" aria-hidden="true"><path d="m11.28 3.22 4.25 4.25a.75.75 0 0 1 0 1.06l-4.25 4.25a.749.749 0 0 1-1.275-.326.749.749 0 0 1 .215-.734L13.94 8l-3.72-3.72a.749.749 0 0 1 .326-1.275.749.749 0 0 1 .734.215Zm-6.56 0a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042L2.06 8l3.72 3.72a.749.749 0 0 1-.326 1.275.749.749 0 0 1-.734-.215L.47 8.53a.75.75 0 0 1 0-1.06Z"></path></svg></span><span class="sd-summary-text">scripts/reinforcement_learning/ray/hyperparameter_tuning/vision_cartpole_cfg.py</span><span class="sd-summary-state-marker sd-summary-chevron-right"><svg version="1.1" width="1.5em" height="1.5em" class="sd-octicon sd-octicon-chevron-right" viewBox="0 0 24 24" aria-hidden="true"><path d="M8.72 18.78a.75.75 0 0 1 0-1.06L14.44 12 8.72 6.28a.751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018l6.25 6.25a.75.75 0 0 1 0 1.06l-6.25 6.25a.75.75 0 0 1-1.06 0Z"></path></svg></span></summary><div class="sd-summary-content sd-card-body docutils">
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># Copyright (c) 2022-2025, The Isaac Lab Project Developers (https://github.com/isaac-sim/IsaacLab/blob/main/CONTRIBUTORS.md).</span>
<span class="c1"># All rights reserved.</span>
<span class="c1">#</span>
<span class="c1"># SPDX-License-Identifier: BSD-3-Clause</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">pathlib</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">sys</span>

<span class="c1"># Allow for import of items from the ray workflow.</span>
<span class="n">CUR_DIR</span> <span class="o">=</span> <span class="n">pathlib</span><span class="o">.</span><span class="n">Path</span><span class="p">(</span><span class="vm">__file__</span><span class="p">)</span><span class="o">.</span><span class="n">parent</span>
<span class="n">UTIL_DIR</span> <span class="o">=</span> <span class="n">CUR_DIR</span><span class="o">.</span><span class="n">parent</span>
<span class="n">sys</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">extend</span><span class="p">([</span><span class="nb">str</span><span class="p">(</span><span class="n">UTIL_DIR</span><span class="p">),</span> <span class="nb">str</span><span class="p">(</span><span class="n">CUR_DIR</span><span class="p">)])</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">util</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">vision_cfg</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">ray</span><span class="w"> </span><span class="kn">import</span> <span class="n">tune</span>


<span class="k">class</span><span class="w"> </span><span class="nc">CartpoleRGBNoTuneJobCfg</span><span class="p">(</span><span class="n">vision_cfg</span><span class="o">.</span><span class="n">CameraJobCfg</span><span class="p">):</span>
    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">cfg</span><span class="p">:</span> <span class="nb">dict</span> <span class="o">=</span> <span class="p">{}):</span>
        <span class="n">cfg</span> <span class="o">=</span> <span class="n">util</span><span class="o">.</span><span class="n">populate_isaac_ray_cfg_args</span><span class="p">(</span><span class="n">cfg</span><span class="p">)</span>
        <span class="n">cfg</span><span class="p">[</span><span class="s2">&quot;runner_args&quot;</span><span class="p">][</span><span class="s2">&quot;--task&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">tune</span><span class="o">.</span><span class="n">choice</span><span class="p">([</span><span class="s2">&quot;Isaac-Cartpole-RGB-v0&quot;</span><span class="p">])</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">cfg</span><span class="p">,</span> <span class="n">vary_env_count</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">vary_cnn</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">vary_mlp</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>


<span class="k">class</span><span class="w"> </span><span class="nc">CartpoleRGBCNNOnlyJobCfg</span><span class="p">(</span><span class="n">vision_cfg</span><span class="o">.</span><span class="n">CameraJobCfg</span><span class="p">):</span>
    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">cfg</span><span class="p">:</span> <span class="nb">dict</span> <span class="o">=</span> <span class="p">{}):</span>
        <span class="n">cfg</span> <span class="o">=</span> <span class="n">util</span><span class="o">.</span><span class="n">populate_isaac_ray_cfg_args</span><span class="p">(</span><span class="n">cfg</span><span class="p">)</span>
        <span class="n">cfg</span><span class="p">[</span><span class="s2">&quot;runner_args&quot;</span><span class="p">][</span><span class="s2">&quot;--task&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">tune</span><span class="o">.</span><span class="n">choice</span><span class="p">([</span><span class="s2">&quot;Isaac-Cartpole-RGB-v0&quot;</span><span class="p">])</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">cfg</span><span class="p">,</span> <span class="n">vary_env_count</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">vary_cnn</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">vary_mlp</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>


<span class="k">class</span><span class="w"> </span><span class="nc">CartpoleRGBJobCfg</span><span class="p">(</span><span class="n">vision_cfg</span><span class="o">.</span><span class="n">CameraJobCfg</span><span class="p">):</span>
    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">cfg</span><span class="p">:</span> <span class="nb">dict</span> <span class="o">=</span> <span class="p">{}):</span>
        <span class="n">cfg</span> <span class="o">=</span> <span class="n">util</span><span class="o">.</span><span class="n">populate_isaac_ray_cfg_args</span><span class="p">(</span><span class="n">cfg</span><span class="p">)</span>
        <span class="n">cfg</span><span class="p">[</span><span class="s2">&quot;runner_args&quot;</span><span class="p">][</span><span class="s2">&quot;--task&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">tune</span><span class="o">.</span><span class="n">choice</span><span class="p">([</span><span class="s2">&quot;Isaac-Cartpole-RGB-v0&quot;</span><span class="p">])</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">cfg</span><span class="p">,</span> <span class="n">vary_env_count</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">vary_cnn</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">vary_mlp</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>


<span class="k">class</span><span class="w"> </span><span class="nc">CartpoleResNetJobCfg</span><span class="p">(</span><span class="n">vision_cfg</span><span class="o">.</span><span class="n">ResNetCameraJob</span><span class="p">):</span>
    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">cfg</span><span class="p">:</span> <span class="nb">dict</span> <span class="o">=</span> <span class="p">{}):</span>
        <span class="n">cfg</span> <span class="o">=</span> <span class="n">util</span><span class="o">.</span><span class="n">populate_isaac_ray_cfg_args</span><span class="p">(</span><span class="n">cfg</span><span class="p">)</span>
        <span class="n">cfg</span><span class="p">[</span><span class="s2">&quot;runner_args&quot;</span><span class="p">][</span><span class="s2">&quot;--task&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">tune</span><span class="o">.</span><span class="n">choice</span><span class="p">([</span><span class="s2">&quot;Isaac-Cartpole-RGB-ResNet18-v0&quot;</span><span class="p">])</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">cfg</span><span class="p">)</span>


<span class="k">class</span><span class="w"> </span><span class="nc">CartpoleTheiaJobCfg</span><span class="p">(</span><span class="n">vision_cfg</span><span class="o">.</span><span class="n">TheiaCameraJob</span><span class="p">):</span>
    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">cfg</span><span class="p">:</span> <span class="nb">dict</span> <span class="o">=</span> <span class="p">{}):</span>
        <span class="n">cfg</span> <span class="o">=</span> <span class="n">util</span><span class="o">.</span><span class="n">populate_isaac_ray_cfg_args</span><span class="p">(</span><span class="n">cfg</span><span class="p">)</span>
        <span class="n">cfg</span><span class="p">[</span><span class="s2">&quot;runner_args&quot;</span><span class="p">][</span><span class="s2">&quot;--task&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">tune</span><span class="o">.</span><span class="n">choice</span><span class="p">([</span><span class="s2">&quot;Isaac-Cartpole-RGB-TheiaTiny-v0&quot;</span><span class="p">])</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">cfg</span><span class="p">)</span>
</pre></div>
</div>
</div>
</details></section>
<section id="remote-clusters">
<h2>远程集群<a class="headerlink" href="#remote-clusters" title="此标题的永久链接">#</a></h2>
<p>选择以下方法之一来创建 Ray 集群，以接收和执行调度的任务。</p>
<section id="kuberay-setup">
<h3>KubeRay 安装<a class="headerlink" href="#kuberay-setup" title="此标题的永久链接">#</a></h3>
<p>如果在 Google GKE 上使用 KubeRay 集群，并且使用自带集群启动文件，则还需要以下依赖项。</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>python3<span class="w"> </span>-p<span class="w"> </span>-m<span class="w"> </span>pip<span class="w"> </span>install<span class="w"> </span>kubernetes<span class="w"> </span>Jinja2
</pre></div>
</div>
<p>用于具有 KubeRay 的 Kubernetes 集群，如 Google Kubernetes Engine 或 Amazon Elastic Kubernetes Service， <code class="docutils literal notranslate"><span class="pre">kubectl</span></code> 是必需的，可以通过 <a class="reference external" href="https://kubernetes.io/docs/tasks/tools/">Kubernetes website</a> 安装。</p>
<p>Google Cloud 目前是唯一经过测试的平台，尽管任何云服务提供商只要配置以下内容也应当可以使用。</p>
<div class="admonition attention">
<p class="admonition-title">注意</p>
<p><code class="docutils literal notranslate"><span class="pre">ray</span></code> 命令应该修改为使用 Isaac python，这可以通过类似于 <code class="docutils literal notranslate"><span class="pre">sed</span> <span class="pre">-i</span> <span class="pre">&quot;1i</span> <span class="pre">$(echo</span> <span class="pre">&quot;#!/workspace/isaaclab/_isaac_sim/python.sh&quot;)&quot;</span> <span class="pre">\</span> <span class="pre">/isaac-sim/kit/python/bin/ray</span> <span class="pre">&amp;&amp;</span> <span class="pre">ln</span> <span class="pre">-s</span> <span class="pre">/isaac-sim/kit/python/bin/ray</span> <span class="pre">/usr/local/bin/ray</span></code> 的方式来实现。</p>
</div>
<ul class="simple">
<li><p>一个配置了支持 Ray 的 Isaac Lab 镜像的容器注册表（NGC、GCS artifact registry、AWS ECR 等）。查看 <code class="docutils literal notranslate"><span class="pre">cluster_configs/Dockerfile</span></code> 了解如何修改 <code class="docutils literal notranslate"><span class="pre">isaac-lab-base</span></code> 容器以兼容 Ray。Ray 应该使用 isaac sim 的 python shebang，并且 <code class="docutils literal notranslate"><span class="pre">nvidia-smi</span></code> 应该在容器内正常工作。这里的设置需要小心，因为路径必须正确配置才能正常工作。例子的 dockerfile 很可能开箱即用，并可以推送到注册表，只要基础镜像已经按照容器指南中的方式构建完成。</p></li>
<li><p>一个包含可用 NVIDIA RTX（可能是 <code class="docutils literal notranslate"><span class="pre">l4</span></code>、<code class="docutils literal notranslate"><span class="pre">l40</span></code>、<code class="docutils literal notranslate"><span class="pre">tesla-t4</span></code> 或 <code class="docutils literal notranslate"><span class="pre">a10</span></code> ）GPU直通节点池资源的 Kubernetes 设置，能够访问您的容器注册表/存储桶，并启用了 Ray 操作符且具有正确的 IAM 权限。通过像 Google GKE 或 AWS EKS 等服务可以轻松实现，前提是您的账户或组织已被授予 GPU 预算。建议使用手动 Kubernetes 服务，而非“自动驾驶”服务进行成本效益高的实验，因为这种方式可以在不使用时完全关闭集群，尽管这可能需要安装 <a class="reference external" href="https://docs.nvidia.com/datacenter/cloud-native/gpu-operator/latest/google-gke.html">Nvidia GPU Operator</a> 。</p></li>
<li><p>一个 <a class="reference external" href="https://mlflow.org/docs/latest/getting-started/logging-first-model/step1-tracking-server.html">MLFlow server</a> ，您的集群可以访问（已为 Google Cloud 包含，可以参考其格式和 MLFlow 集成）。</p></li>
<li><p>一个 <code class="docutils literal notranslate"><span class="pre">kuberay.yaml.ninja</span></code> 文件，描述了如何分配资源（已经为 Google Cloud 包含，可以参考该格式和 MLFlow 集成）。</p></li>
</ul>
</section>
<section id="ray-clusters-without-kubernetes-setup">
<h3>Ray 集群（不使用 Kubernetes）安装<a class="headerlink" href="#ray-clusters-without-kubernetes-setup" title="此标题的永久链接">#</a></h3>
<div class="admonition attention">
<p class="admonition-title">注意</p>
<p>修改 Ray 命令以像在 KubeRay 集群中一样使用 Isaac Python，并按照相同的步骤创建镜像/集群权限。</p>
</div>
<p>请参阅 <a class="reference external" href="https://docs.ray.io/en/latest/cluster/getting-started.html">Ray Clusters Overview</a> 或 <a class="reference external" href="https://www.anyscale.com/product">Anyscale</a> 以获取更多信息。</p>
<p>当然，创建一个 <a class="reference external" href="https://mlflow.org/docs/latest/getting-started/logging-first-model/step1-tracking-server.html">MLFlow server</a> ，让你的本地主机和集群可以访问。</p>
</section>
<section id="shared-steps-between-kuberay-and-pure-ray-part-i">
<h3>KubeRay 和纯 Ray 之间的共享步骤 第 I 部分<a class="headerlink" href="#shared-steps-between-kuberay-and-pure-ray-part-i" title="此标题的永久链接">#</a></h3>
<p>1.) 在本地机器上安装 Ray。</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>python3<span class="w"> </span>-p<span class="w"> </span>-m<span class="w"> </span>pip<span class="w"> </span>install<span class="w"> </span>ray<span class="o">[</span>default<span class="o">]==</span><span class="m">2</span>.31.0
</pre></div>
</div>
<p>2.) 构建 Isaac Ray 镜像，并将其上传到你选择的容器注册表。</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><span class="c1"># Login with NGC (nvcr.io) registry first, see docker steps in repo.</span>
python3<span class="w"> </span>docker/container.py<span class="w"> </span>start
<span class="c1"># Build the special Isaac Lab Ray Image</span>
docker<span class="w"> </span>build<span class="w"> </span>-t<span class="w"> </span>&lt;REGISTRY/IMAGE_NAME&gt;<span class="w"> </span>-f<span class="w"> </span>scripts/reinforcement_learning/ray/cluster_configs/Dockerfile<span class="w"> </span>.
<span class="c1"># Push the image to your registry of choice.</span>
docker<span class="w"> </span>push<span class="w"> </span>&lt;REGISTRY/IMAGE_NAME&gt;
</pre></div>
</div>
</section>
<section id="kuberay-clusters-only">
<h3>仅限KubeRay集群<a class="headerlink" href="#kuberay-clusters-only" title="此标题的永久链接">#</a></h3>
<p><a class="reference external" href="https://github.com/derailed/k9s">k9s</a> 是一个很好的工具，用于监控您的集群，可以通过 <code class="docutils literal notranslate"><span class="pre">snap</span> <span class="pre">install</span> <span class="pre">k9s</span> <span class="pre">--devmode</span></code> 简单安装。</p>
<p>1.) 验证集群访问权限，并确保正确的操作符已安装。</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><span class="c1"># Verify cluster access</span>
kubectl<span class="w"> </span>cluster-info
<span class="c1"># If using a manually managed cluster (not Autopilot or the like)</span>
<span class="c1"># verify that there are node pools</span>
kubectl<span class="w"> </span>get<span class="w"> </span>nodes
<span class="c1"># Check that the ray operator is installed on the cluster</span>
<span class="c1"># should list rayclusters.ray.io , rayjobs.ray.io , and rayservices.ray.io</span>
kubectl<span class="w"> </span>get<span class="w"> </span>crds<span class="w"> </span><span class="p">|</span><span class="w"> </span>grep<span class="w"> </span>ray
<span class="c1"># Check that the NVIDIA Driver Operator is installed on the cluster</span>
<span class="c1"># should list clusterpolicies.nvidia.com</span>
kubectl<span class="w"> </span>get<span class="w"> </span>crds<span class="w"> </span><span class="p">|</span><span class="w"> </span>grep<span class="w"> </span>nvidia
</pre></div>
</div>
<p>2.) 创建 KubeRay 集群和一个 MLFlow 服务器，用于接收您的集群可以访问的日志。这可以通过 Google GKE 自动完成，相关说明已包含在以下创建文件中。</p>
<details class="sd-sphinx-override sd-dropdown sd-card sd-mb-3">
<summary class="sd-summary-title sd-card-header">
<span class="sd-summary-icon"><svg version="1.1" width="1.0em" height="1.0em" class="sd-octicon sd-octicon-code" viewBox="0 0 16 16" aria-hidden="true"><path d="m11.28 3.22 4.25 4.25a.75.75 0 0 1 0 1.06l-4.25 4.25a.749.749 0 0 1-1.275-.326.749.749 0 0 1 .215-.734L13.94 8l-3.72-3.72a.749.749 0 0 1 .326-1.275.749.749 0 0 1 .734.215Zm-6.56 0a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042L2.06 8l3.72 3.72a.749.749 0 0 1-.326 1.275.749.749 0 0 1-.734-.215L.47 8.53a.75.75 0 0 1 0-1.06Z"></path></svg></span><span class="sd-summary-text">scripts/reinforcement_learning/ray/launch.py</span><span class="sd-summary-state-marker sd-summary-chevron-right"><svg version="1.1" width="1.5em" height="1.5em" class="sd-octicon sd-octicon-chevron-right" viewBox="0 0 24 24" aria-hidden="true"><path d="M8.72 18.78a.75.75 0 0 1 0-1.06L14.44 12 8.72 6.28a.751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018l6.25 6.25a.75.75 0 0 1 0 1.06l-6.25 6.25a.75.75 0 0 1-1.06 0Z"></path></svg></span></summary><div class="sd-summary-content sd-card-body docutils">
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># Copyright (c) 2022-2025, The Isaac Lab Project Developers (https://github.com/isaac-sim/IsaacLab/blob/main/CONTRIBUTORS.md).</span>
<span class="c1"># All rights reserved.</span>
<span class="c1">#</span>
<span class="c1"># SPDX-License-Identifier: BSD-3-Clause</span>

<span class="kn">import</span><span class="w"> </span><span class="nn">argparse</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">pathlib</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">subprocess</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">yaml</span>

<span class="kn">import</span><span class="w"> </span><span class="nn">util</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">jinja2</span><span class="w"> </span><span class="kn">import</span> <span class="n">Environment</span><span class="p">,</span> <span class="n">FileSystemLoader</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">kubernetes</span><span class="w"> </span><span class="kn">import</span> <span class="n">config</span>

<span class="hll"><span class="sd">&quot;&quot;&quot;This script helps create one or more KubeRay clusters.</span>
</span><span class="hll">
</span><span class="hll"><span class="sd">Usage:</span>
</span><span class="hll">
</span><span class="hll"><span class="sd">.. code-block:: bash</span>
</span><span class="hll"><span class="sd">    # If the head node is stuck on container creating, make sure to create a secret</span>
</span><span class="hll"><span class="sd">    python3 scripts/reinforcement_learning/ray/launch.py -h</span>
</span><span class="hll">
</span><span class="hll"><span class="sd">    # Examples</span>
</span><span class="hll">
</span><span class="hll"><span class="sd">    # The following creates 8 GPUx1 nvidia l4 workers</span>
</span><span class="hll"><span class="sd">    python3 scripts/reinforcement_learning/ray/launch.py --cluster_host google_cloud \</span>
</span><span class="hll"><span class="sd">    --namespace &lt;NAMESPACE&gt; --image &lt;YOUR_ISAAC_RAY_IMAGE&gt; \</span>
</span><span class="hll"><span class="sd">    --num_workers 8 --num_clusters 1 --worker_accelerator nvidia-l4 --gpu_per_worker 1</span>
</span><span class="hll">
</span><span class="hll"><span class="sd">    # The following creates 1 GPUx1 nvidia l4 worker, 2 GPUx2 nvidia-tesla-t4 workers,</span>
</span><span class="hll"><span class="sd">    # and 2 GPUx4 nvidia-tesla-t4 GPU workers</span>
</span><span class="hll"><span class="sd">    python3 scripts/reinforcement_learning/ray/launch.py --cluster_host google_cloud \</span>
</span><span class="hll"><span class="sd">    --namespace &lt;NAMESPACE&gt; --image &lt;YOUR_ISAAC_RAY_IMAGE&gt; \</span>
</span><span class="hll"><span class="sd">    --num_workers 1 2 --num_clusters 1 \</span>
</span><span class="hll"><span class="sd">    --worker_accelerator nvidia-l4 nvidia-tesla-t4 --gpu_per_worker 1 2 4</span>
</span><span class="hll"><span class="sd">&quot;&quot;&quot;</span>
</span><span class="n">RAY_DIR</span> <span class="o">=</span> <span class="n">pathlib</span><span class="o">.</span><span class="n">Path</span><span class="p">(</span><span class="vm">__file__</span><span class="p">)</span><span class="o">.</span><span class="n">parent</span>


<span class="k">def</span><span class="w"> </span><span class="nf">apply_manifest</span><span class="p">(</span><span class="n">args</span><span class="p">:</span> <span class="n">argparse</span><span class="o">.</span><span class="n">Namespace</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Provided a Jinja templated ray.io/v1alpha1 file,</span>
<span class="sd">    populate the arguments and create the cluster. Additionally, create</span>
<span class="sd">    kubernetes containers for resources separated by &#39;---&#39; from the rest</span>
<span class="sd">    of the file.</span>

<span class="sd">    Args:</span>
<span class="sd">        args: Possible arguments concerning cluster parameters.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="c1"># Load Kubernetes configuration</span>
    <span class="n">config</span><span class="o">.</span><span class="n">load_kube_config</span><span class="p">()</span>

    <span class="c1"># Set up Jinja2 environment for loading templates</span>
    <span class="n">templates_dir</span> <span class="o">=</span> <span class="n">RAY_DIR</span> <span class="o">/</span> <span class="s2">&quot;cluster_configs&quot;</span> <span class="o">/</span> <span class="n">args</span><span class="o">.</span><span class="n">cluster_host</span>
    <span class="n">file_loader</span> <span class="o">=</span> <span class="n">FileSystemLoader</span><span class="p">(</span><span class="nb">str</span><span class="p">(</span><span class="n">templates_dir</span><span class="p">))</span>
    <span class="n">jinja_env</span> <span class="o">=</span> <span class="n">Environment</span><span class="p">(</span><span class="n">loader</span><span class="o">=</span><span class="n">file_loader</span><span class="p">,</span> <span class="n">keep_trailing_newline</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">autoescape</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

    <span class="c1"># Define template filename</span>
    <span class="n">template_file</span> <span class="o">=</span> <span class="s2">&quot;kuberay.yaml.jinja&quot;</span>

    <span class="c1"># Convert args namespace to a dictionary</span>
    <span class="n">template_params</span> <span class="o">=</span> <span class="nb">vars</span><span class="p">(</span><span class="n">args</span><span class="p">)</span>

    <span class="c1"># Load and render the template</span>
    <span class="n">template</span> <span class="o">=</span> <span class="n">jinja_env</span><span class="o">.</span><span class="n">get_template</span><span class="p">(</span><span class="n">template_file</span><span class="p">)</span>
    <span class="n">file_contents</span> <span class="o">=</span> <span class="n">template</span><span class="o">.</span><span class="n">render</span><span class="p">(</span><span class="n">template_params</span><span class="p">)</span>

    <span class="c1"># Parse all YAML documents in the rendered template</span>
    <span class="n">all_yamls</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">doc</span> <span class="ow">in</span> <span class="n">yaml</span><span class="o">.</span><span class="n">safe_load_all</span><span class="p">(</span><span class="n">file_contents</span><span class="p">):</span>
        <span class="n">all_yamls</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">doc</span><span class="p">)</span>

    <span class="c1"># Convert back to YAML string, preserving multiple documents</span>
    <span class="n">cleaned_yaml_string</span> <span class="o">=</span> <span class="s2">&quot;&quot;</span>
    <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">doc</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">all_yamls</span><span class="p">):</span>
        <span class="k">if</span> <span class="n">i</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
            <span class="n">cleaned_yaml_string</span> <span class="o">+=</span> <span class="s2">&quot;</span><span class="se">\n</span><span class="s2">---</span><span class="se">\n</span><span class="s2">&quot;</span>
        <span class="n">cleaned_yaml_string</span> <span class="o">+=</span> <span class="n">yaml</span><span class="o">.</span><span class="n">dump</span><span class="p">(</span><span class="n">doc</span><span class="p">)</span>

    <span class="c1"># Apply the Kubernetes manifest using kubectl</span>
    <span class="k">try</span><span class="p">:</span>
        <span class="nb">print</span><span class="p">(</span><span class="n">cleaned_yaml_string</span><span class="p">)</span>
        <span class="n">subprocess</span><span class="o">.</span><span class="n">run</span><span class="p">([</span><span class="s2">&quot;kubectl&quot;</span><span class="p">,</span> <span class="s2">&quot;apply&quot;</span><span class="p">,</span> <span class="s2">&quot;-f&quot;</span><span class="p">,</span> <span class="s2">&quot;-&quot;</span><span class="p">],</span> <span class="nb">input</span><span class="o">=</span><span class="n">cleaned_yaml_string</span><span class="p">,</span> <span class="n">text</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">check</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
    <span class="k">except</span> <span class="n">subprocess</span><span class="o">.</span><span class="n">CalledProcessError</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
        <span class="n">exit</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;An error occurred while running `kubectl`: </span><span class="si">{</span><span class="n">e</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>


<span class="k">def</span><span class="w"> </span><span class="nf">parse_args</span><span class="p">()</span> <span class="o">-&gt;</span> <span class="n">argparse</span><span class="o">.</span><span class="n">Namespace</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Parse command-line arguments for Kubernetes deployment script.</span>

<span class="sd">    Returns:</span>
<span class="sd">        argparse.Namespace: Parsed command-line arguments.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">arg_parser</span> <span class="o">=</span> <span class="n">argparse</span><span class="o">.</span><span class="n">ArgumentParser</span><span class="p">(</span>
        <span class="n">description</span><span class="o">=</span><span class="s2">&quot;Script to apply manifests to create Kubernetes objects for Ray clusters.&quot;</span><span class="p">,</span>
        <span class="n">formatter_class</span><span class="o">=</span><span class="n">argparse</span><span class="o">.</span><span class="n">ArgumentDefaultsHelpFormatter</span><span class="p">,</span>
    <span class="p">)</span>

    <span class="n">arg_parser</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span>
        <span class="s2">&quot;--cluster_host&quot;</span><span class="p">,</span>
        <span class="nb">type</span><span class="o">=</span><span class="nb">str</span><span class="p">,</span>
        <span class="n">default</span><span class="o">=</span><span class="s2">&quot;google_cloud&quot;</span><span class="p">,</span>
        <span class="n">choices</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;google_cloud&quot;</span><span class="p">],</span>
        <span class="n">help</span><span class="o">=</span><span class="p">(</span>
            <span class="s2">&quot;In the cluster_configs directory, the name of the folder where a tune.yaml.jinja&quot;</span>
            <span class="s2">&quot;file exists defining the KubeRay config. Currently only google_cloud is supported.&quot;</span>
        <span class="p">),</span>
    <span class="p">)</span>

    <span class="n">arg_parser</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span>
        <span class="s2">&quot;--name&quot;</span><span class="p">,</span>
        <span class="nb">type</span><span class="o">=</span><span class="nb">str</span><span class="p">,</span>
        <span class="n">required</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
        <span class="n">default</span><span class="o">=</span><span class="s2">&quot;isaacray&quot;</span><span class="p">,</span>
        <span class="n">help</span><span class="o">=</span><span class="s2">&quot;Name of the Kubernetes deployment.&quot;</span><span class="p">,</span>
    <span class="p">)</span>

    <span class="n">arg_parser</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span>
        <span class="s2">&quot;--namespace&quot;</span><span class="p">,</span>
        <span class="nb">type</span><span class="o">=</span><span class="nb">str</span><span class="p">,</span>
        <span class="n">required</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
        <span class="n">default</span><span class="o">=</span><span class="s2">&quot;default&quot;</span><span class="p">,</span>
        <span class="n">help</span><span class="o">=</span><span class="s2">&quot;Kubernetes namespace to deploy the Ray cluster.&quot;</span><span class="p">,</span>
    <span class="p">)</span>

    <span class="n">arg_parser</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span>
        <span class="s2">&quot;--service_acount_name&quot;</span><span class="p">,</span> <span class="nb">type</span><span class="o">=</span><span class="nb">str</span><span class="p">,</span> <span class="n">required</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="s2">&quot;default&quot;</span><span class="p">,</span> <span class="n">help</span><span class="o">=</span><span class="s2">&quot;The service account name to use.&quot;</span>
    <span class="p">)</span>

    <span class="n">arg_parser</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span>
        <span class="s2">&quot;--image&quot;</span><span class="p">,</span>
        <span class="nb">type</span><span class="o">=</span><span class="nb">str</span><span class="p">,</span>
        <span class="n">required</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
        <span class="n">help</span><span class="o">=</span><span class="s2">&quot;Docker image for the Ray cluster pods.&quot;</span><span class="p">,</span>
    <span class="p">)</span>

    <span class="n">arg_parser</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span>
        <span class="s2">&quot;--worker_accelerator&quot;</span><span class="p">,</span>
        <span class="n">nargs</span><span class="o">=</span><span class="s2">&quot;+&quot;</span><span class="p">,</span>
        <span class="nb">type</span><span class="o">=</span><span class="nb">str</span><span class="p">,</span>
        <span class="n">default</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;nvidia-l4&quot;</span><span class="p">],</span>
        <span class="n">help</span><span class="o">=</span><span class="s2">&quot;GPU accelerator name. Supply more than one for heterogeneous resources.&quot;</span><span class="p">,</span>
    <span class="p">)</span>

    <span class="n">arg_parser</span> <span class="o">=</span> <span class="n">util</span><span class="o">.</span><span class="n">add_resource_arguments</span><span class="p">(</span><span class="n">arg_parser</span><span class="p">,</span> <span class="n">cluster_create_defaults</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

    <span class="n">arg_parser</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span>
        <span class="s2">&quot;--num_clusters&quot;</span><span class="p">,</span>
        <span class="nb">type</span><span class="o">=</span><span class="nb">int</span><span class="p">,</span>
        <span class="n">default</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">help</span><span class="o">=</span><span class="s2">&quot;How many Ray Clusters to create.&quot;</span><span class="p">,</span>
    <span class="p">)</span>
    <span class="n">arg_parser</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span>
        <span class="s2">&quot;--num_head_cpu&quot;</span><span class="p">,</span>
        <span class="nb">type</span><span class="o">=</span><span class="nb">float</span><span class="p">,</span>  <span class="c1"># to be able to schedule partial CPU heads</span>
        <span class="n">default</span><span class="o">=</span><span class="mi">8</span><span class="p">,</span>
        <span class="n">help</span><span class="o">=</span><span class="s2">&quot;The number of CPUs to give the Ray head.&quot;</span><span class="p">,</span>
    <span class="p">)</span>

    <span class="n">arg_parser</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span><span class="s2">&quot;--head_ram_gb&quot;</span><span class="p">,</span> <span class="nb">type</span><span class="o">=</span><span class="nb">int</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="mi">8</span><span class="p">,</span> <span class="n">help</span><span class="o">=</span><span class="s2">&quot;How many gigs of ram to give the Ray head&quot;</span><span class="p">)</span>
    <span class="n">args</span> <span class="o">=</span> <span class="n">arg_parser</span><span class="o">.</span><span class="n">parse_args</span><span class="p">()</span>
    <span class="k">return</span> <span class="n">util</span><span class="o">.</span><span class="n">fill_in_missing_resources</span><span class="p">(</span><span class="n">args</span><span class="p">,</span> <span class="n">cluster_creation_flag</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>


<span class="k">def</span><span class="w"> </span><span class="nf">main</span><span class="p">():</span>
    <span class="n">args</span> <span class="o">=</span> <span class="n">parse_args</span><span class="p">()</span>

    <span class="k">if</span> <span class="s2">&quot;head&quot;</span> <span class="ow">in</span> <span class="n">args</span><span class="o">.</span><span class="n">name</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;For compatibility with other scripts, do not include head in the name&quot;</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">args</span><span class="o">.</span><span class="n">num_clusters</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
        <span class="n">apply_manifest</span><span class="p">(</span><span class="n">args</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">default_name</span> <span class="o">=</span> <span class="n">args</span><span class="o">.</span><span class="n">name</span>
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">args</span><span class="o">.</span><span class="n">num_clusters</span><span class="p">):</span>
            <span class="n">args</span><span class="o">.</span><span class="n">name</span> <span class="o">=</span> <span class="n">default_name</span> <span class="o">+</span> <span class="s2">&quot;-&quot;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">i</span><span class="p">)</span>
            <span class="n">apply_manifest</span><span class="p">(</span><span class="n">args</span><span class="p">)</span>


<span class="k">if</span> <span class="vm">__name__</span> <span class="o">==</span> <span class="s2">&quot;__main__&quot;</span><span class="p">:</span>
    <span class="n">main</span><span class="p">()</span>
</pre></div>
</div>
</div>
</details><p>对于其他云服务， <code class="docutils literal notranslate"><span class="pre">kuberay.yaml.ninja</span></code> 将类似于 Google 的。</p>
<details class="sd-sphinx-override sd-dropdown sd-card sd-mb-3">
<summary class="sd-summary-title sd-card-header">
<span class="sd-summary-icon"><svg version="1.1" width="1.0em" height="1.0em" class="sd-octicon sd-octicon-code" viewBox="0 0 16 16" aria-hidden="true"><path d="m11.28 3.22 4.25 4.25a.75.75 0 0 1 0 1.06l-4.25 4.25a.749.749 0 0 1-1.275-.326.749.749 0 0 1 .215-.734L13.94 8l-3.72-3.72a.749.749 0 0 1 .326-1.275.749.749 0 0 1 .734.215Zm-6.56 0a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042L2.06 8l3.72 3.72a.749.749 0 0 1-.326 1.275.749.749 0 0 1-.734-.215L.47 8.53a.75.75 0 0 1 0-1.06Z"></path></svg></span><span class="sd-summary-text">scripts/reinforcement_learning/ray/cluster_configs/google_cloud/kuberay.yaml.ninja</span><span class="sd-summary-state-marker sd-summary-chevron-right"><svg version="1.1" width="1.5em" height="1.5em" class="sd-octicon sd-octicon-chevron-right" viewBox="0 0 24 24" aria-hidden="true"><path d="M8.72 18.78a.75.75 0 0 1 0-1.06L14.44 12 8.72 6.28a.751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018l6.25 6.25a.75.75 0 0 1 0 1.06l-6.25 6.25a.75.75 0 0 1-1.06 0Z"></path></svg></span></summary><div class="sd-summary-content sd-card-body docutils">
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># Jinja is used for templating here as full helm setup is excessive for application</span>
<span class="n">apiVersion</span><span class="p">:</span> <span class="n">ray</span><span class="o">.</span><span class="n">io</span><span class="o">/</span><span class="n">v1alpha1</span>
<span class="n">kind</span><span class="p">:</span> <span class="n">RayCluster</span>
<span class="n">metadata</span><span class="p">:</span>
  <span class="n">name</span><span class="p">:</span> <span class="p">{{</span> <span class="n">name</span> <span class="p">}}</span>
  <span class="n">namespace</span><span class="p">:</span> <span class="p">{{</span> <span class="n">namespace</span> <span class="p">}}</span>
<span class="n">spec</span><span class="p">:</span>
  <span class="n">rayVersion</span><span class="p">:</span> <span class="s2">&quot;2.8.0&quot;</span>
  <span class="n">enableInTreeAutoscaling</span><span class="p">:</span> <span class="n">true</span>
  <span class="n">autoscalerOptions</span><span class="p">:</span>
    <span class="n">upscalingMode</span><span class="p">:</span> <span class="n">Default</span>
    <span class="n">idleTimeoutSeconds</span><span class="p">:</span> <span class="mi">120</span>
    <span class="n">imagePullPolicy</span><span class="p">:</span> <span class="n">Always</span>
    <span class="n">securityContext</span><span class="p">:</span> <span class="p">{}</span>
    <span class="n">envFrom</span><span class="p">:</span> <span class="p">[]</span>

  <span class="n">headGroupSpec</span><span class="p">:</span>
    <span class="n">rayStartParams</span><span class="p">:</span>
      <span class="n">block</span><span class="p">:</span> <span class="s2">&quot;true&quot;</span>
      <span class="n">dashboard</span><span class="o">-</span><span class="n">host</span><span class="p">:</span> <span class="mf">0.0.0.0</span>
      <span class="n">dashboard</span><span class="o">-</span><span class="n">port</span><span class="p">:</span> <span class="s2">&quot;8265&quot;</span>
      <span class="n">port</span><span class="p">:</span> <span class="s2">&quot;6379&quot;</span>
      <span class="n">include</span><span class="o">-</span><span class="n">dashboard</span><span class="p">:</span> <span class="s2">&quot;true&quot;</span>
      <span class="n">ray</span><span class="o">-</span><span class="n">debugger</span><span class="o">-</span><span class="n">external</span><span class="p">:</span> <span class="s2">&quot;true&quot;</span>
      <span class="nb">object</span><span class="o">-</span><span class="n">manager</span><span class="o">-</span><span class="n">port</span><span class="p">:</span> <span class="s2">&quot;8076&quot;</span>
      <span class="n">num</span><span class="o">-</span><span class="n">gpus</span><span class="p">:</span> <span class="s2">&quot;0&quot;</span>
      <span class="n">num</span><span class="o">-</span><span class="n">cpus</span><span class="p">:</span> <span class="s2">&quot;0&quot;</span> <span class="c1"># prevent scheduling jobs to the head node - workers only</span>
    <span class="n">headService</span><span class="p">:</span>
      <span class="n">apiVersion</span><span class="p">:</span> <span class="n">v1</span>
      <span class="n">kind</span><span class="p">:</span> <span class="n">Service</span>
      <span class="n">metadata</span><span class="p">:</span>
        <span class="n">name</span><span class="p">:</span> <span class="p">{{</span> <span class="n">name</span> <span class="p">}}</span><span class="o">-</span><span class="n">head</span>
      <span class="n">spec</span><span class="p">:</span>
        <span class="nb">type</span><span class="p">:</span> <span class="n">LoadBalancer</span>
    <span class="n">template</span><span class="p">:</span>
      <span class="n">metadata</span><span class="p">:</span>
        <span class="n">labels</span><span class="p">:</span>
          <span class="n">app</span><span class="o">.</span><span class="n">kubernetes</span><span class="o">.</span><span class="n">io</span><span class="o">/</span><span class="n">instance</span><span class="p">:</span> <span class="n">tuner</span>
          <span class="n">app</span><span class="o">.</span><span class="n">kubernetes</span><span class="o">.</span><span class="n">io</span><span class="o">/</span><span class="n">name</span><span class="p">:</span> <span class="n">kuberay</span>
          <span class="n">cloud</span><span class="o">.</span><span class="n">google</span><span class="o">.</span><span class="n">com</span><span class="o">/</span><span class="n">gke</span><span class="o">-</span><span class="n">ray</span><span class="o">-</span><span class="n">node</span><span class="o">-</span><span class="nb">type</span><span class="p">:</span> <span class="n">head</span>
      <span class="n">spec</span><span class="p">:</span>
        <span class="n">serviceAccountName</span><span class="p">:</span> <span class="p">{{</span> <span class="n">service_account_name</span> <span class="p">}}</span>
        <span class="n">affinity</span><span class="p">:</span> <span class="p">{}</span>
        <span class="n">securityContext</span><span class="p">:</span>
          <span class="n">fsGroup</span><span class="p">:</span> <span class="mi">100</span>
        <span class="n">containers</span><span class="p">:</span>
          <span class="o">-</span> <span class="n">env</span><span class="p">:</span>
            <span class="n">image</span><span class="p">:</span> <span class="p">{{</span> <span class="n">image</span> <span class="p">}}</span>
            <span class="n">imagePullPolicy</span><span class="p">:</span> <span class="n">Always</span>
            <span class="n">name</span><span class="p">:</span> <span class="n">head</span>
            <span class="n">resources</span><span class="p">:</span>
              <span class="n">limits</span><span class="p">:</span>
                <span class="n">cpu</span><span class="p">:</span> <span class="s2">&quot;{{ num_head_cpu }}&quot;</span>
                <span class="n">memory</span><span class="p">:</span> <span class="p">{{</span> <span class="n">head_ram_gb</span> <span class="p">}}</span><span class="n">G</span>
                <span class="n">nvidia</span><span class="o">.</span><span class="n">com</span><span class="o">/</span><span class="n">gpu</span><span class="p">:</span> <span class="s2">&quot;0&quot;</span>
              <span class="n">requests</span><span class="p">:</span>
                <span class="n">cpu</span><span class="p">:</span> <span class="s2">&quot;{{ num_head_cpu }}&quot;</span>
                <span class="n">memory</span><span class="p">:</span> <span class="p">{{</span> <span class="n">head_ram_gb</span> <span class="p">}}</span><span class="n">G</span>
                <span class="n">nvidia</span><span class="o">.</span><span class="n">com</span><span class="o">/</span><span class="n">gpu</span><span class="p">:</span> <span class="s2">&quot;0&quot;</span>
            <span class="n">securityContext</span><span class="p">:</span> <span class="p">{}</span>
            <span class="n">volumeMounts</span><span class="p">:</span>
              <span class="o">-</span> <span class="n">mountPath</span><span class="p">:</span> <span class="o">/</span><span class="n">tmp</span><span class="o">/</span><span class="n">ray</span>
                <span class="n">name</span><span class="p">:</span> <span class="n">ray</span><span class="o">-</span><span class="n">logs</span>
            <span class="n">command</span><span class="p">:</span> <span class="p">[</span><span class="s2">&quot;/bin/bash&quot;</span><span class="p">,</span> <span class="s2">&quot;-c&quot;</span><span class="p">,</span> <span class="s2">&quot;ray start --head --port=6379 --object-manager-port=8076 --dashboard-host=0.0.0.0 --dashboard-port=8265 --include-dashboard=true &amp;&amp; tail -f /dev/null&quot;</span><span class="p">]</span>
          <span class="o">-</span> <span class="n">image</span><span class="p">:</span> <span class="n">fluent</span><span class="o">/</span><span class="n">fluent</span><span class="o">-</span><span class="n">bit</span><span class="p">:</span><span class="mf">1.9.6</span>
            <span class="n">name</span><span class="p">:</span> <span class="n">fluentbit</span>
            <span class="n">resources</span><span class="p">:</span>
              <span class="n">limits</span><span class="p">:</span>
                <span class="n">cpu</span><span class="p">:</span> <span class="mi">100</span><span class="n">m</span>
                <span class="n">memory</span><span class="p">:</span> <span class="mi">128</span><span class="n">Mi</span>
              <span class="n">requests</span><span class="p">:</span>
                <span class="n">cpu</span><span class="p">:</span> <span class="mi">100</span><span class="n">m</span>
                <span class="n">memory</span><span class="p">:</span> <span class="mi">128</span><span class="n">Mi</span>
            <span class="n">volumeMounts</span><span class="p">:</span>
              <span class="o">-</span> <span class="n">mountPath</span><span class="p">:</span> <span class="o">/</span><span class="n">tmp</span><span class="o">/</span><span class="n">ray</span>
                <span class="n">name</span><span class="p">:</span> <span class="n">ray</span><span class="o">-</span><span class="n">logs</span>
        <span class="n">imagePullSecrets</span><span class="p">:</span> <span class="p">[]</span>
        <span class="n">nodeSelector</span><span class="p">:</span>
          <span class="n">iam</span><span class="o">.</span><span class="n">gke</span><span class="o">.</span><span class="n">io</span><span class="o">/</span><span class="n">gke</span><span class="o">-</span><span class="n">metadata</span><span class="o">-</span><span class="n">server</span><span class="o">-</span><span class="n">enabled</span><span class="p">:</span> <span class="s2">&quot;true&quot;</span>
        <span class="n">volumes</span><span class="p">:</span>
          <span class="o">-</span> <span class="n">configMap</span><span class="p">:</span>
              <span class="n">name</span><span class="p">:</span> <span class="n">fluentbit</span><span class="o">-</span><span class="n">config</span>
            <span class="n">name</span><span class="p">:</span> <span class="n">fluentbit</span><span class="o">-</span><span class="n">config</span>
          <span class="o">-</span> <span class="n">name</span><span class="p">:</span> <span class="n">ray</span><span class="o">-</span><span class="n">logs</span>
            <span class="n">emptyDir</span><span class="p">:</span> <span class="p">{}</span>

  <span class="n">workerGroupSpecs</span><span class="p">:</span>
    <span class="p">{</span><span class="o">%</span> <span class="k">for</span> <span class="n">it</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">gpu_per_worker</span><span class="o">|</span><span class="n">length</span><span class="p">)</span> <span class="o">%</span><span class="p">}</span>
    <span class="o">-</span> <span class="n">groupName</span><span class="p">:</span> <span class="s2">&quot;{{ worker_accelerator[it] }}x{{ gpu_per_worker[it] }}-cpu-{{ cpu_per_worker[it] }}-ram-gb-{{ ram_gb_per_worker[it] }}&quot;</span>
      <span class="n">replicas</span><span class="p">:</span> <span class="p">{{</span> <span class="n">num_workers</span><span class="p">[</span><span class="n">it</span><span class="p">]</span> <span class="p">}}</span>
      <span class="n">maxReplicas</span><span class="p">:</span> <span class="p">{{</span> <span class="n">num_workers</span><span class="p">[</span><span class="n">it</span><span class="p">]</span> <span class="p">}}</span>
      <span class="n">minReplicas</span><span class="p">:</span> <span class="p">{{</span> <span class="n">num_workers</span><span class="p">[</span><span class="n">it</span><span class="p">]</span> <span class="p">}}</span>
      <span class="n">rayStartParams</span><span class="p">:</span>
        <span class="n">block</span><span class="p">:</span> <span class="s2">&quot;true&quot;</span>
        <span class="n">ray</span><span class="o">-</span><span class="n">debugger</span><span class="o">-</span><span class="n">external</span><span class="p">:</span> <span class="s2">&quot;true&quot;</span>
        <span class="n">replicas</span><span class="p">:</span> <span class="s2">&quot;{{num_workers[it]}}&quot;</span>
      <span class="n">template</span><span class="p">:</span>
        <span class="n">metadata</span><span class="p">:</span>
          <span class="n">annotations</span><span class="p">:</span> <span class="p">{}</span>
          <span class="n">labels</span><span class="p">:</span>
            <span class="n">app</span><span class="o">.</span><span class="n">kubernetes</span><span class="o">.</span><span class="n">io</span><span class="o">/</span><span class="n">instance</span><span class="p">:</span> <span class="n">tuner</span>
            <span class="n">app</span><span class="o">.</span><span class="n">kubernetes</span><span class="o">.</span><span class="n">io</span><span class="o">/</span><span class="n">name</span><span class="p">:</span> <span class="n">kuberay</span>
            <span class="n">cloud</span><span class="o">.</span><span class="n">google</span><span class="o">.</span><span class="n">com</span><span class="o">/</span><span class="n">gke</span><span class="o">-</span><span class="n">ray</span><span class="o">-</span><span class="n">node</span><span class="o">-</span><span class="nb">type</span><span class="p">:</span> <span class="n">worker</span>
        <span class="n">spec</span><span class="p">:</span>
          <span class="n">serviceAccountName</span><span class="p">:</span> <span class="p">{{</span> <span class="n">service_account_name</span> <span class="p">}}</span>
          <span class="n">affinity</span><span class="p">:</span> <span class="p">{}</span>
          <span class="n">securityContext</span><span class="p">:</span>
            <span class="n">fsGroup</span><span class="p">:</span> <span class="mi">100</span>
          <span class="n">containers</span><span class="p">:</span>
            <span class="o">-</span> <span class="n">env</span><span class="p">:</span>
              <span class="o">-</span> <span class="n">name</span><span class="p">:</span> <span class="n">NVIDIA_VISIBLE_DEVICES</span>
                <span class="n">value</span><span class="p">:</span> <span class="s2">&quot;all&quot;</span>
              <span class="o">-</span> <span class="n">name</span><span class="p">:</span> <span class="n">NVIDIA_DRIVER_CAPABILITIES</span>
                <span class="n">value</span><span class="p">:</span> <span class="s2">&quot;compute,utility&quot;</span>

              <span class="n">image</span><span class="p">:</span> <span class="p">{{</span> <span class="n">image</span> <span class="p">}}</span>
              <span class="n">imagePullPolicy</span><span class="p">:</span> <span class="n">Always</span>
              <span class="n">name</span><span class="p">:</span> <span class="n">ray</span><span class="o">-</span><span class="n">worker</span>
              <span class="n">resources</span><span class="p">:</span>
                <span class="n">limits</span><span class="p">:</span>
                  <span class="n">cpu</span><span class="p">:</span> <span class="s2">&quot;{{ cpu_per_worker[it] }}&quot;</span>
                  <span class="n">memory</span><span class="p">:</span> <span class="p">{{</span> <span class="n">ram_gb_per_worker</span><span class="p">[</span><span class="n">it</span><span class="p">]</span> <span class="p">}}</span><span class="n">G</span>
                  <span class="n">nvidia</span><span class="o">.</span><span class="n">com</span><span class="o">/</span><span class="n">gpu</span><span class="p">:</span> <span class="s2">&quot;{{ gpu_per_worker[it] }}&quot;</span>
                <span class="n">requests</span><span class="p">:</span>
                  <span class="n">cpu</span><span class="p">:</span> <span class="s2">&quot;{{ cpu_per_worker[it] }}&quot;</span>
                  <span class="n">memory</span><span class="p">:</span> <span class="p">{{</span> <span class="n">ram_gb_per_worker</span><span class="p">[</span><span class="n">it</span><span class="p">]</span> <span class="p">}}</span><span class="n">G</span>
                  <span class="n">nvidia</span><span class="o">.</span><span class="n">com</span><span class="o">/</span><span class="n">gpu</span><span class="p">:</span> <span class="s2">&quot;{{ gpu_per_worker[it] }}&quot;</span>
              <span class="n">securityContext</span><span class="p">:</span> <span class="p">{}</span>
              <span class="n">volumeMounts</span><span class="p">:</span>
                <span class="o">-</span> <span class="n">mountPath</span><span class="p">:</span> <span class="o">/</span><span class="n">tmp</span><span class="o">/</span><span class="n">ray</span>
                  <span class="n">name</span><span class="p">:</span> <span class="n">ray</span><span class="o">-</span><span class="n">logs</span>
              <span class="n">command</span><span class="p">:</span> <span class="p">[</span><span class="s2">&quot;/bin/bash&quot;</span><span class="p">,</span> <span class="s2">&quot;-c&quot;</span><span class="p">,</span> <span class="s2">&quot;ray start --address={{name}}-head.{{ namespace }}.svc.cluster.local:6379 &amp;&amp; tail -f /dev/null&quot;</span><span class="p">]</span>
            <span class="o">-</span> <span class="n">image</span><span class="p">:</span> <span class="n">fluent</span><span class="o">/</span><span class="n">fluent</span><span class="o">-</span><span class="n">bit</span><span class="p">:</span><span class="mf">1.9.6</span>
              <span class="n">name</span><span class="p">:</span> <span class="n">fluentbit</span>
              <span class="n">resources</span><span class="p">:</span>
                <span class="n">limits</span><span class="p">:</span>
                  <span class="n">cpu</span><span class="p">:</span> <span class="mi">100</span><span class="n">m</span>
                  <span class="n">memory</span><span class="p">:</span> <span class="mi">128</span><span class="n">Mi</span>
                <span class="n">requests</span><span class="p">:</span>
                  <span class="n">cpu</span><span class="p">:</span> <span class="mi">100</span><span class="n">m</span>
                  <span class="n">memory</span><span class="p">:</span> <span class="mi">128</span><span class="n">Mi</span>
              <span class="n">volumeMounts</span><span class="p">:</span>
                <span class="o">-</span> <span class="n">mountPath</span><span class="p">:</span> <span class="o">/</span><span class="n">tmp</span><span class="o">/</span><span class="n">ray</span>
                  <span class="n">name</span><span class="p">:</span> <span class="n">ray</span><span class="o">-</span><span class="n">logs</span>

          <span class="n">imagePullSecrets</span><span class="p">:</span> <span class="p">[]</span>
          <span class="n">nodeSelector</span><span class="p">:</span>
            <span class="n">cloud</span><span class="o">.</span><span class="n">google</span><span class="o">.</span><span class="n">com</span><span class="o">/</span><span class="n">gke</span><span class="o">-</span><span class="n">accelerator</span><span class="p">:</span> <span class="p">{{</span> <span class="n">worker_accelerator</span><span class="p">[</span><span class="n">it</span><span class="p">]</span> <span class="p">}}</span>
            <span class="n">iam</span><span class="o">.</span><span class="n">gke</span><span class="o">.</span><span class="n">io</span><span class="o">/</span><span class="n">gke</span><span class="o">-</span><span class="n">metadata</span><span class="o">-</span><span class="n">server</span><span class="o">-</span><span class="n">enabled</span><span class="p">:</span> <span class="s2">&quot;true&quot;</span>
          <span class="n">tolerations</span><span class="p">:</span>
            <span class="o">-</span> <span class="n">key</span><span class="p">:</span> <span class="s2">&quot;nvidia.com/gpu&quot;</span>
              <span class="n">operator</span><span class="p">:</span> <span class="s2">&quot;Exists&quot;</span>
              <span class="n">effect</span><span class="p">:</span> <span class="s2">&quot;NoSchedule&quot;</span>
          <span class="n">volumes</span><span class="p">:</span>
            <span class="o">-</span> <span class="n">configMap</span><span class="p">:</span>
                <span class="n">name</span><span class="p">:</span> <span class="n">fluentbit</span><span class="o">-</span><span class="n">config</span>
              <span class="n">name</span><span class="p">:</span> <span class="n">fluentbit</span><span class="o">-</span><span class="n">config</span>
            <span class="o">-</span> <span class="n">name</span><span class="p">:</span> <span class="n">ray</span><span class="o">-</span><span class="n">logs</span>
              <span class="n">emptyDir</span><span class="p">:</span> <span class="p">{}</span>
    <span class="p">{</span><span class="o">%</span> <span class="n">endfor</span> <span class="o">%</span><span class="p">}</span>

<span class="o">---</span>
<span class="c1"># ML Flow Server - for fetching logs</span>
<span class="n">apiVersion</span><span class="p">:</span> <span class="n">apps</span><span class="o">/</span><span class="n">v1</span>
<span class="n">kind</span><span class="p">:</span> <span class="n">Deployment</span>
<span class="n">metadata</span><span class="p">:</span>
  <span class="n">name</span><span class="p">:</span> <span class="p">{{</span><span class="n">name</span><span class="p">}}</span><span class="o">-</span><span class="n">mlflow</span>
  <span class="n">namespace</span><span class="p">:</span> <span class="p">{{</span> <span class="n">namespace</span> <span class="p">}}</span>
<span class="n">spec</span><span class="p">:</span>
  <span class="n">replicas</span><span class="p">:</span> <span class="mi">1</span>
  <span class="n">selector</span><span class="p">:</span>
    <span class="n">matchLabels</span><span class="p">:</span>
      <span class="n">app</span><span class="p">:</span> <span class="n">mlflow</span>
  <span class="n">template</span><span class="p">:</span>
    <span class="n">metadata</span><span class="p">:</span>
      <span class="n">labels</span><span class="p">:</span>
        <span class="n">app</span><span class="p">:</span> <span class="n">mlflow</span>
    <span class="n">spec</span><span class="p">:</span>
      <span class="n">containers</span><span class="p">:</span>
      <span class="o">-</span> <span class="n">name</span><span class="p">:</span> <span class="n">mlflow</span>
        <span class="n">image</span><span class="p">:</span> <span class="n">ghcr</span><span class="o">.</span><span class="n">io</span><span class="o">/</span><span class="n">mlflow</span><span class="o">/</span><span class="n">mlflow</span><span class="p">:</span><span class="n">v2</span><span class="mf">.9.2</span>
        <span class="n">ports</span><span class="p">:</span>
        <span class="o">-</span> <span class="n">containerPort</span><span class="p">:</span> <span class="mi">5000</span>
        <span class="n">command</span><span class="p">:</span> <span class="p">[</span><span class="s2">&quot;mlflow&quot;</span><span class="p">]</span>
        <span class="n">args</span><span class="p">:</span>
        <span class="o">-</span> <span class="n">server</span>
        <span class="o">-</span> <span class="o">--</span><span class="n">host</span><span class="o">=</span><span class="mf">0.0.0.0</span>
        <span class="o">-</span> <span class="o">--</span><span class="n">port</span><span class="o">=</span><span class="mi">5000</span>
        <span class="o">-</span> <span class="o">--</span><span class="n">backend</span><span class="o">-</span><span class="n">store</span><span class="o">-</span><span class="n">uri</span><span class="o">=</span><span class="n">sqlite</span><span class="p">:</span><span class="o">///</span><span class="n">mlflow</span><span class="o">.</span><span class="n">db</span>
<span class="o">---</span>
<span class="c1"># ML Flow Service (for port forwarding, kubectl port-forward service/{name}-mlflow 5000:5000)</span>
<span class="n">apiVersion</span><span class="p">:</span> <span class="n">v1</span>
<span class="n">kind</span><span class="p">:</span> <span class="n">Service</span>
<span class="n">metadata</span><span class="p">:</span>
  <span class="n">name</span><span class="p">:</span> <span class="p">{{</span><span class="n">name</span><span class="p">}}</span><span class="o">-</span><span class="n">mlflow</span>
  <span class="n">namespace</span><span class="p">:</span> <span class="p">{{</span> <span class="n">namespace</span> <span class="p">}}</span>
<span class="n">spec</span><span class="p">:</span>
  <span class="n">selector</span><span class="p">:</span>
    <span class="n">app</span><span class="p">:</span> <span class="n">mlflow</span>
  <span class="n">ports</span><span class="p">:</span>
  <span class="o">-</span> <span class="n">port</span><span class="p">:</span> <span class="mi">5000</span>
    <span class="n">targetPort</span><span class="p">:</span> <span class="mi">5000</span>
  <span class="nb">type</span><span class="p">:</span> <span class="n">ClusterIP</span>
</pre></div>
</div>
</div>
</details><p>3.) 获取 KubeRay 集群的 IP 地址以及 MLFlow 服务器的 IP。对于 KubeRay 集群，可以自动执行此操作，相关说明已包含在以下获取文件中。KubeRay 集群会被保存到文件中，但 MLFlow 服务器 IP 会被打印出来。</p>
<details class="sd-sphinx-override sd-dropdown sd-card sd-mb-3">
<summary class="sd-summary-title sd-card-header">
<span class="sd-summary-icon"><svg version="1.1" width="1.0em" height="1.0em" class="sd-octicon sd-octicon-code" viewBox="0 0 16 16" aria-hidden="true"><path d="m11.28 3.22 4.25 4.25a.75.75 0 0 1 0 1.06l-4.25 4.25a.749.749 0 0 1-1.275-.326.749.749 0 0 1 .215-.734L13.94 8l-3.72-3.72a.749.749 0 0 1 .326-1.275.749.749 0 0 1 .734.215Zm-6.56 0a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042L2.06 8l3.72 3.72a.749.749 0 0 1-.326 1.275.749.749 0 0 1-.734-.215L.47 8.53a.75.75 0 0 1 0-1.06Z"></path></svg></span><span class="sd-summary-text">scripts/reinforcement_learning/ray/grok_cluster_with_kubectl.py</span><span class="sd-summary-state-marker sd-summary-chevron-right"><svg version="1.1" width="1.5em" height="1.5em" class="sd-octicon sd-octicon-chevron-right" viewBox="0 0 24 24" aria-hidden="true"><path d="M8.72 18.78a.75.75 0 0 1 0-1.06L14.44 12 8.72 6.28a.751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018l6.25 6.25a.75.75 0 0 1 0 1.06l-6.25 6.25a.75.75 0 0 1-1.06 0Z"></path></svg></span></summary><div class="sd-summary-content sd-card-body docutils">
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># Copyright (c) 2022-2025, The Isaac Lab Project Developers (https://github.com/isaac-sim/IsaacLab/blob/main/CONTRIBUTORS.md).</span>
<span class="c1"># All rights reserved.</span>
<span class="c1">#</span>
<span class="c1"># SPDX-License-Identifier: BSD-3-Clause</span>

<span class="kn">import</span><span class="w"> </span><span class="nn">argparse</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">os</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">re</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">subprocess</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">threading</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">time</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">concurrent.futures</span><span class="w"> </span><span class="kn">import</span> <span class="n">ThreadPoolExecutor</span><span class="p">,</span> <span class="n">as_completed</span>

<span class="hll"><span class="sd">&quot;&quot;&quot;</span>
</span><span class="hll"><span class="sd">This script requires that kubectl is installed and KubeRay was used to create the cluster.</span>
</span><span class="hll">
</span><span class="hll"><span class="sd">Creates a config file containing ``name: &lt;NAME&gt; address: http://&lt;IP&gt;:&lt;PORT&gt;`` on</span>
</span><span class="hll"><span class="sd">a new line for each cluster, and also fetches the MLFlow URI.</span>
</span><span class="hll">
</span><span class="hll"><span class="sd">Usage:</span>
</span><span class="hll">
</span><span class="hll"><span class="sd">.. code-block:: bash</span>
</span><span class="hll">
</span><span class="hll"><span class="sd">    python3 scripts/reinforcement_learning/ray/grok_cluster_with_kubectl.py</span>
</span><span class="hll"><span class="sd">    # For options, supply -h arg</span>
</span><span class="hll"><span class="sd">&quot;&quot;&quot;</span>
</span>

<span class="k">def</span><span class="w"> </span><span class="nf">get_namespace</span><span class="p">()</span> <span class="o">-&gt;</span> <span class="nb">str</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Get the current Kubernetes namespace from the context, fallback to default if not set&quot;&quot;&quot;</span>
    <span class="k">try</span><span class="p">:</span>
        <span class="n">namespace</span> <span class="o">=</span> <span class="p">(</span>
            <span class="n">subprocess</span><span class="o">.</span><span class="n">check_output</span><span class="p">([</span><span class="s2">&quot;kubectl&quot;</span><span class="p">,</span> <span class="s2">&quot;config&quot;</span><span class="p">,</span> <span class="s2">&quot;view&quot;</span><span class="p">,</span> <span class="s2">&quot;--minify&quot;</span><span class="p">,</span> <span class="s2">&quot;--output&quot;</span><span class="p">,</span> <span class="s2">&quot;jsonpath={..namespace}&quot;</span><span class="p">])</span>
            <span class="o">.</span><span class="n">decode</span><span class="p">()</span>
            <span class="o">.</span><span class="n">strip</span><span class="p">()</span>
        <span class="p">)</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="n">namespace</span><span class="p">:</span>
            <span class="n">namespace</span> <span class="o">=</span> <span class="s2">&quot;default&quot;</span>
    <span class="k">except</span> <span class="n">subprocess</span><span class="o">.</span><span class="n">CalledProcessError</span><span class="p">:</span>
        <span class="n">namespace</span> <span class="o">=</span> <span class="s2">&quot;default&quot;</span>
    <span class="k">return</span> <span class="n">namespace</span>


<span class="k">def</span><span class="w"> </span><span class="nf">get_pods</span><span class="p">(</span><span class="n">namespace</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s2">&quot;default&quot;</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">list</span><span class="p">[</span><span class="nb">tuple</span><span class="p">]:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Get a list of all of the pods in the namespace&quot;&quot;&quot;</span>
    <span class="n">cmd</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;kubectl&quot;</span><span class="p">,</span> <span class="s2">&quot;get&quot;</span><span class="p">,</span> <span class="s2">&quot;pods&quot;</span><span class="p">,</span> <span class="s2">&quot;-n&quot;</span><span class="p">,</span> <span class="n">namespace</span><span class="p">,</span> <span class="s2">&quot;--no-headers&quot;</span><span class="p">]</span>
    <span class="n">output</span> <span class="o">=</span> <span class="n">subprocess</span><span class="o">.</span><span class="n">check_output</span><span class="p">(</span><span class="n">cmd</span><span class="p">)</span><span class="o">.</span><span class="n">decode</span><span class="p">()</span>
    <span class="n">pods</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">line</span> <span class="ow">in</span> <span class="n">output</span><span class="o">.</span><span class="n">strip</span><span class="p">()</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">):</span>
        <span class="n">fields</span> <span class="o">=</span> <span class="n">line</span><span class="o">.</span><span class="n">split</span><span class="p">()</span>
        <span class="n">pod_name</span> <span class="o">=</span> <span class="n">fields</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
        <span class="n">status</span> <span class="o">=</span> <span class="n">fields</span><span class="p">[</span><span class="mi">2</span><span class="p">]</span>
        <span class="n">pods</span><span class="o">.</span><span class="n">append</span><span class="p">((</span><span class="n">pod_name</span><span class="p">,</span> <span class="n">status</span><span class="p">))</span>
    <span class="k">return</span> <span class="n">pods</span>


<span class="k">def</span><span class="w"> </span><span class="nf">get_clusters</span><span class="p">(</span><span class="n">pods</span><span class="p">:</span> <span class="nb">list</span><span class="p">,</span> <span class="n">cluster_name_prefix</span><span class="p">:</span> <span class="nb">str</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">set</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Get unique cluster name(s). Works for one or more clusters, based off of the number of head nodes.</span>
<span class="sd">    Excludes MLflow deployments.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">clusters</span> <span class="o">=</span> <span class="nb">set</span><span class="p">()</span>
    <span class="k">for</span> <span class="n">pod_name</span><span class="p">,</span> <span class="n">_</span> <span class="ow">in</span> <span class="n">pods</span><span class="p">:</span>
        <span class="c1"># Skip MLflow pods</span>
        <span class="k">if</span> <span class="s2">&quot;-mlflow&quot;</span> <span class="ow">in</span> <span class="n">pod_name</span><span class="p">:</span>
            <span class="k">continue</span>

        <span class="n">match</span> <span class="o">=</span> <span class="n">re</span><span class="o">.</span><span class="n">match</span><span class="p">(</span><span class="sa">r</span><span class="s2">&quot;(&quot;</span> <span class="o">+</span> <span class="n">re</span><span class="o">.</span><span class="n">escape</span><span class="p">(</span><span class="n">cluster_name_prefix</span><span class="p">)</span> <span class="o">+</span> <span class="sa">r</span><span class="s2">&quot;[-\w]+)&quot;</span><span class="p">,</span> <span class="n">pod_name</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">match</span><span class="p">:</span>
            <span class="c1"># Get base name without head/worker suffix (skip workers)</span>
            <span class="k">if</span> <span class="s2">&quot;head&quot;</span> <span class="ow">in</span> <span class="n">pod_name</span><span class="p">:</span>
                <span class="n">base_name</span> <span class="o">=</span> <span class="n">match</span><span class="o">.</span><span class="n">group</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s2">&quot;-head&quot;</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span>
                <span class="n">clusters</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">base_name</span><span class="p">)</span>
    <span class="k">return</span> <span class="nb">sorted</span><span class="p">(</span><span class="n">clusters</span><span class="p">)</span>


<span class="k">def</span><span class="w"> </span><span class="nf">get_mlflow_info</span><span class="p">(</span><span class="n">namespace</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span> <span class="n">cluster_prefix</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s2">&quot;isaacray&quot;</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">str</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Get MLflow service information if it exists in the namespace with the given prefix.</span>
<span class="sd">    Only works for a single cluster instance.</span>
<span class="sd">    Args:</span>
<span class="sd">        namespace: Kubernetes namespace</span>
<span class="sd">        cluster_prefix: Base cluster name (without -head/-worker suffixes)</span>
<span class="sd">    Returns:</span>
<span class="sd">        MLflow service URL</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="c1"># Strip any -head or -worker suffixes to get base name</span>
    <span class="k">if</span> <span class="n">namespace</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">namespace</span> <span class="o">=</span> <span class="n">get_namespace</span><span class="p">()</span>
    <span class="n">pods</span> <span class="o">=</span> <span class="n">get_pods</span><span class="p">(</span><span class="n">namespace</span><span class="o">=</span><span class="n">namespace</span><span class="p">)</span>
    <span class="n">clusters</span> <span class="o">=</span> <span class="n">get_clusters</span><span class="p">(</span><span class="n">pods</span><span class="o">=</span><span class="n">pods</span><span class="p">,</span> <span class="n">cluster_name_prefix</span><span class="o">=</span><span class="n">cluster_prefix</span><span class="p">)</span>
    <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">clusters</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;More than one cluster matches prefix, could not automatically determine mlflow info.&quot;</span><span class="p">)</span>
    <span class="n">mlflow_name</span> <span class="o">=</span> <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">cluster_prefix</span><span class="si">}</span><span class="s2">-mlflow&quot;</span>

    <span class="n">cmd</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;kubectl&quot;</span><span class="p">,</span> <span class="s2">&quot;get&quot;</span><span class="p">,</span> <span class="s2">&quot;svc&quot;</span><span class="p">,</span> <span class="n">mlflow_name</span><span class="p">,</span> <span class="s2">&quot;-n&quot;</span><span class="p">,</span> <span class="n">namespace</span><span class="p">,</span> <span class="s2">&quot;--no-headers&quot;</span><span class="p">]</span>
    <span class="k">try</span><span class="p">:</span>
        <span class="n">output</span> <span class="o">=</span> <span class="n">subprocess</span><span class="o">.</span><span class="n">check_output</span><span class="p">(</span><span class="n">cmd</span><span class="p">)</span><span class="o">.</span><span class="n">decode</span><span class="p">()</span>
        <span class="n">fields</span> <span class="o">=</span> <span class="n">output</span><span class="o">.</span><span class="n">strip</span><span class="p">()</span><span class="o">.</span><span class="n">split</span><span class="p">()</span>

        <span class="c1"># Get cluster IP</span>
        <span class="n">cluster_ip</span> <span class="o">=</span> <span class="n">fields</span><span class="p">[</span><span class="mi">2</span><span class="p">]</span>
        <span class="n">port</span> <span class="o">=</span> <span class="s2">&quot;5000&quot;</span>  <span class="c1"># Default MLflow port</span>
        <span class="c1"># This needs to be http to be resolved. HTTPS can&#39;t be resolved</span>
        <span class="c1"># This should be fine as it is on a subnet on the cluster regardless</span>
        <span class="k">return</span> <span class="sa">f</span><span class="s2">&quot;http://</span><span class="si">{</span><span class="n">cluster_ip</span><span class="si">}</span><span class="s2">:</span><span class="si">{</span><span class="n">port</span><span class="si">}</span><span class="s2">&quot;</span>
    <span class="k">except</span> <span class="n">subprocess</span><span class="o">.</span><span class="n">CalledProcessError</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Could not grok MLflow: </span><span class="si">{</span><span class="n">e</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>  <span class="c1"># Fixed f-string</span>


<span class="k">def</span><span class="w"> </span><span class="nf">check_clusters_running</span><span class="p">(</span><span class="n">pods</span><span class="p">:</span> <span class="nb">list</span><span class="p">,</span> <span class="n">clusters</span><span class="p">:</span> <span class="nb">set</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">bool</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Check that all of the pods in all provided clusters are running.</span>

<span class="sd">    Args:</span>
<span class="sd">        pods (list): A list of tuples where each tuple contains the pod name and its status.</span>
<span class="sd">        clusters (set): A set of cluster names to check.</span>

<span class="sd">    Returns:</span>
<span class="sd">        bool: True if all pods in any of the clusters are running, False otherwise.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">clusters_running</span> <span class="o">=</span> <span class="kc">False</span>
    <span class="k">for</span> <span class="n">cluster</span> <span class="ow">in</span> <span class="n">clusters</span><span class="p">:</span>
        <span class="n">cluster_pods</span> <span class="o">=</span> <span class="p">[</span><span class="n">p</span> <span class="k">for</span> <span class="n">p</span> <span class="ow">in</span> <span class="n">pods</span> <span class="k">if</span> <span class="n">p</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">startswith</span><span class="p">(</span><span class="n">cluster</span><span class="p">)]</span>
        <span class="n">total_pods</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">cluster_pods</span><span class="p">)</span>
        <span class="n">running_pods</span> <span class="o">=</span> <span class="nb">len</span><span class="p">([</span><span class="n">p</span> <span class="k">for</span> <span class="n">p</span> <span class="ow">in</span> <span class="n">cluster_pods</span> <span class="k">if</span> <span class="n">p</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">==</span> <span class="s2">&quot;Running&quot;</span><span class="p">])</span>
        <span class="k">if</span> <span class="n">running_pods</span> <span class="o">==</span> <span class="n">total_pods</span> <span class="ow">and</span> <span class="n">running_pods</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
            <span class="n">clusters_running</span> <span class="o">=</span> <span class="kc">True</span>
            <span class="k">break</span>
    <span class="k">return</span> <span class="n">clusters_running</span>


<span class="k">def</span><span class="w"> </span><span class="nf">get_ray_address</span><span class="p">(</span><span class="n">head_pod</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span> <span class="n">namespace</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s2">&quot;default&quot;</span><span class="p">,</span> <span class="n">ray_head_name</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s2">&quot;head&quot;</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">str</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Given a cluster head pod, check its logs, which should include the ray address which can accept job requests.</span>

<span class="sd">    Args:</span>
<span class="sd">        head_pod (str): The name of the head pod.</span>
<span class="sd">        namespace (str, optional): The Kubernetes namespace. Defaults to &quot;default&quot;.</span>
<span class="sd">        ray_head_name (str, optional): The name of the ray head container. Defaults to &quot;head&quot;.</span>

<span class="sd">    Returns:</span>
<span class="sd">        str: The ray address if found, None otherwise.</span>

<span class="sd">    Raises:</span>
<span class="sd">        ValueError: If the logs cannot be retrieved or the ray address is not found.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">cmd</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;kubectl&quot;</span><span class="p">,</span> <span class="s2">&quot;logs&quot;</span><span class="p">,</span> <span class="n">head_pod</span><span class="p">,</span> <span class="s2">&quot;-c&quot;</span><span class="p">,</span> <span class="n">ray_head_name</span><span class="p">,</span> <span class="s2">&quot;-n&quot;</span><span class="p">,</span> <span class="n">namespace</span><span class="p">]</span>
    <span class="k">try</span><span class="p">:</span>
        <span class="n">output</span> <span class="o">=</span> <span class="n">subprocess</span><span class="o">.</span><span class="n">check_output</span><span class="p">(</span><span class="n">cmd</span><span class="p">)</span><span class="o">.</span><span class="n">decode</span><span class="p">()</span>
    <span class="k">except</span> <span class="n">subprocess</span><span class="o">.</span><span class="n">CalledProcessError</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
            <span class="sa">f</span><span class="s2">&quot;Could not enter head container with cmd </span><span class="si">{</span><span class="n">cmd</span><span class="si">}</span><span class="s2">: </span><span class="si">{</span><span class="n">e</span><span class="si">}</span><span class="s2">Perhaps try a different namespace or ray head name.&quot;</span>
        <span class="p">)</span>
    <span class="n">match</span> <span class="o">=</span> <span class="n">re</span><span class="o">.</span><span class="n">search</span><span class="p">(</span><span class="sa">r</span><span class="s2">&quot;RAY_ADDRESS=&#39;([^&#39;]+)&#39;&quot;</span><span class="p">,</span> <span class="n">output</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">match</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">match</span><span class="o">.</span><span class="n">group</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="k">return</span> <span class="kc">None</span>


<span class="k">def</span><span class="w"> </span><span class="nf">process_cluster</span><span class="p">(</span><span class="n">cluster_info</span><span class="p">:</span> <span class="nb">dict</span><span class="p">,</span> <span class="n">ray_head_name</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s2">&quot;head&quot;</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">str</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    For each cluster, check that it is running, and get the Ray head address that will accept jobs.</span>

<span class="sd">    Args:</span>
<span class="sd">        cluster_info (dict): A dictionary containing cluster information with keys &#39;cluster&#39;, &#39;pods&#39;, and &#39;namespace&#39;.</span>
<span class="sd">        ray_head_name (str, optional): The name of the ray head container. Defaults to &quot;head&quot;.</span>

<span class="sd">    Returns:</span>
<span class="sd">        str: A string containing the cluster name and its Ray head address, or an error message if the head pod or Ray address is not found.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">cluster</span><span class="p">,</span> <span class="n">pods</span><span class="p">,</span> <span class="n">namespace</span> <span class="o">=</span> <span class="n">cluster_info</span>
    <span class="n">head_pod</span> <span class="o">=</span> <span class="kc">None</span>
    <span class="k">for</span> <span class="n">pod_name</span><span class="p">,</span> <span class="n">status</span> <span class="ow">in</span> <span class="n">pods</span><span class="p">:</span>
        <span class="k">if</span> <span class="n">pod_name</span><span class="o">.</span><span class="n">startswith</span><span class="p">(</span><span class="n">cluster</span> <span class="o">+</span> <span class="s2">&quot;-head&quot;</span><span class="p">):</span>
            <span class="n">head_pod</span> <span class="o">=</span> <span class="n">pod_name</span>
            <span class="k">break</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="n">head_pod</span><span class="p">:</span>
        <span class="k">return</span> <span class="sa">f</span><span class="s2">&quot;Error: Could not find head pod for cluster </span><span class="si">{</span><span class="n">cluster</span><span class="si">}</span><span class="se">\n</span><span class="s2">&quot;</span>

    <span class="c1"># Get RAY_ADDRESS and status</span>
    <span class="n">ray_address</span> <span class="o">=</span> <span class="n">get_ray_address</span><span class="p">(</span><span class="n">head_pod</span><span class="p">,</span> <span class="n">namespace</span><span class="o">=</span><span class="n">namespace</span><span class="p">,</span> <span class="n">ray_head_name</span><span class="o">=</span><span class="n">ray_head_name</span><span class="p">)</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="n">ray_address</span><span class="p">:</span>
        <span class="k">return</span> <span class="sa">f</span><span class="s2">&quot;Error: Could not find RAY_ADDRESS for cluster </span><span class="si">{</span><span class="n">cluster</span><span class="si">}</span><span class="se">\n</span><span class="s2">&quot;</span>

    <span class="c1"># Return only cluster and ray address</span>
    <span class="k">return</span> <span class="sa">f</span><span class="s2">&quot;name: </span><span class="si">{</span><span class="n">cluster</span><span class="si">}</span><span class="s2"> address: </span><span class="si">{</span><span class="n">ray_address</span><span class="si">}</span><span class="se">\n</span><span class="s2">&quot;</span>


<span class="k">def</span><span class="w"> </span><span class="nf">main</span><span class="p">():</span>
    <span class="c1"># Parse command-line arguments</span>
    <span class="n">parser</span> <span class="o">=</span> <span class="n">argparse</span><span class="o">.</span><span class="n">ArgumentParser</span><span class="p">(</span><span class="n">description</span><span class="o">=</span><span class="s2">&quot;Process Ray clusters and save their specifications.&quot;</span><span class="p">)</span>
    <span class="n">parser</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span><span class="s2">&quot;--prefix&quot;</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="s2">&quot;isaacray&quot;</span><span class="p">,</span> <span class="n">help</span><span class="o">=</span><span class="s2">&quot;The prefix for the cluster names.&quot;</span><span class="p">)</span>
    <span class="n">parser</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span><span class="s2">&quot;--output&quot;</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="s2">&quot;~/.cluster_config&quot;</span><span class="p">,</span> <span class="n">help</span><span class="o">=</span><span class="s2">&quot;The file to save cluster specifications.&quot;</span><span class="p">)</span>
    <span class="n">parser</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span><span class="s2">&quot;--ray_head_name&quot;</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="s2">&quot;head&quot;</span><span class="p">,</span> <span class="n">help</span><span class="o">=</span><span class="s2">&quot;The metadata name for the ray head container&quot;</span><span class="p">)</span>
    <span class="n">parser</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span>
        <span class="s2">&quot;--namespace&quot;</span><span class="p">,</span> <span class="n">help</span><span class="o">=</span><span class="s2">&quot;Kubernetes namespace to use. If not provided, will detect from current context.&quot;</span>
    <span class="p">)</span>
    <span class="n">args</span> <span class="o">=</span> <span class="n">parser</span><span class="o">.</span><span class="n">parse_args</span><span class="p">()</span>

    <span class="c1"># Get namespace from args or detect it</span>
    <span class="n">current_namespace</span> <span class="o">=</span> <span class="n">args</span><span class="o">.</span><span class="n">namespace</span> <span class="k">if</span> <span class="n">args</span><span class="o">.</span><span class="n">namespace</span> <span class="k">else</span> <span class="n">get_namespace</span><span class="p">()</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Using namespace: </span><span class="si">{</span><span class="n">current_namespace</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

    <span class="n">cluster_name_prefix</span> <span class="o">=</span> <span class="n">args</span><span class="o">.</span><span class="n">prefix</span>
    <span class="n">cluster_spec_file</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">expanduser</span><span class="p">(</span><span class="n">args</span><span class="o">.</span><span class="n">output</span><span class="p">)</span>

    <span class="c1"># Get all pods</span>
    <span class="n">pods</span> <span class="o">=</span> <span class="n">get_pods</span><span class="p">(</span><span class="n">namespace</span><span class="o">=</span><span class="n">current_namespace</span><span class="p">)</span>

    <span class="c1"># Get clusters</span>
    <span class="n">clusters</span> <span class="o">=</span> <span class="n">get_clusters</span><span class="p">(</span><span class="n">pods</span><span class="p">,</span> <span class="n">cluster_name_prefix</span><span class="p">)</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="n">clusters</span><span class="p">:</span>
        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;No clusters found with prefix </span><span class="si">{</span><span class="n">cluster_name_prefix</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
        <span class="k">return</span>

    <span class="c1"># Wait for clusters to be running</span>
    <span class="k">while</span> <span class="kc">True</span><span class="p">:</span>
        <span class="n">pods</span> <span class="o">=</span> <span class="n">get_pods</span><span class="p">(</span><span class="n">namespace</span><span class="o">=</span><span class="n">current_namespace</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">check_clusters_running</span><span class="p">(</span><span class="n">pods</span><span class="p">,</span> <span class="n">clusters</span><span class="p">):</span>
            <span class="k">break</span>
        <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Waiting for all clusters to spin up...&quot;</span><span class="p">)</span>
        <span class="n">time</span><span class="o">.</span><span class="n">sleep</span><span class="p">(</span><span class="mi">5</span><span class="p">)</span>

    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Checking for MLflow:&quot;</span><span class="p">)</span>
    <span class="c1"># Check MLflow status for each cluster</span>
    <span class="k">for</span> <span class="n">cluster</span> <span class="ow">in</span> <span class="n">clusters</span><span class="p">:</span>
        <span class="k">try</span><span class="p">:</span>
            <span class="n">mlflow_address</span> <span class="o">=</span> <span class="n">get_mlflow_info</span><span class="p">(</span><span class="n">current_namespace</span><span class="p">,</span> <span class="n">cluster</span><span class="p">)</span>
            <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;MLflow address for </span><span class="si">{</span><span class="n">cluster</span><span class="si">}</span><span class="s2">: </span><span class="si">{</span><span class="n">mlflow_address</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
        <span class="k">except</span> <span class="ne">ValueError</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
            <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;ML Flow not located: </span><span class="si">{</span><span class="n">e</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">()</span>

    <span class="c1"># Prepare cluster info for parallel processing</span>
    <span class="n">cluster_infos</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">cluster</span> <span class="ow">in</span> <span class="n">clusters</span><span class="p">:</span>
        <span class="n">cluster_pods</span> <span class="o">=</span> <span class="p">[</span><span class="n">p</span> <span class="k">for</span> <span class="n">p</span> <span class="ow">in</span> <span class="n">pods</span> <span class="k">if</span> <span class="n">p</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">startswith</span><span class="p">(</span><span class="n">cluster</span><span class="p">)]</span>
        <span class="n">cluster_infos</span><span class="o">.</span><span class="n">append</span><span class="p">((</span><span class="n">cluster</span><span class="p">,</span> <span class="n">cluster_pods</span><span class="p">,</span> <span class="n">current_namespace</span><span class="p">))</span>

    <span class="c1"># Use ThreadPoolExecutor to process clusters in parallel</span>
    <span class="n">results</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">results_lock</span> <span class="o">=</span> <span class="n">threading</span><span class="o">.</span><span class="n">Lock</span><span class="p">()</span>

    <span class="k">with</span> <span class="n">ThreadPoolExecutor</span><span class="p">()</span> <span class="k">as</span> <span class="n">executor</span><span class="p">:</span>
        <span class="n">future_to_cluster</span> <span class="o">=</span> <span class="p">{</span>
            <span class="n">executor</span><span class="o">.</span><span class="n">submit</span><span class="p">(</span><span class="n">process_cluster</span><span class="p">,</span> <span class="n">info</span><span class="p">,</span> <span class="n">args</span><span class="o">.</span><span class="n">ray_head_name</span><span class="p">):</span> <span class="n">info</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="k">for</span> <span class="n">info</span> <span class="ow">in</span> <span class="n">cluster_infos</span>
        <span class="p">}</span>
        <span class="k">for</span> <span class="n">future</span> <span class="ow">in</span> <span class="n">as_completed</span><span class="p">(</span><span class="n">future_to_cluster</span><span class="p">):</span>
            <span class="n">cluster_name</span> <span class="o">=</span> <span class="n">future_to_cluster</span><span class="p">[</span><span class="n">future</span><span class="p">]</span>
            <span class="k">try</span><span class="p">:</span>
                <span class="n">result</span> <span class="o">=</span> <span class="n">future</span><span class="o">.</span><span class="n">result</span><span class="p">()</span>
                <span class="k">with</span> <span class="n">results_lock</span><span class="p">:</span>
                    <span class="n">results</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">result</span><span class="p">)</span>
            <span class="k">except</span> <span class="ne">Exception</span> <span class="k">as</span> <span class="n">exc</span><span class="p">:</span>
                <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">cluster_name</span><span class="si">}</span><span class="s2"> generated an exception: </span><span class="si">{</span><span class="n">exc</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

    <span class="c1"># Sort results alphabetically by cluster name</span>
    <span class="n">results</span><span class="o">.</span><span class="n">sort</span><span class="p">()</span>

    <span class="c1"># Write sorted results to the output file (Ray info only)</span>
    <span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">cluster_spec_file</span><span class="p">,</span> <span class="s2">&quot;w&quot;</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
        <span class="k">for</span> <span class="n">result</span> <span class="ow">in</span> <span class="n">results</span><span class="p">:</span>
            <span class="n">f</span><span class="o">.</span><span class="n">write</span><span class="p">(</span><span class="n">result</span><span class="p">)</span>

    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Cluster spec information saved to </span><span class="si">{</span><span class="n">cluster_spec_file</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="c1"># Display the contents of the config file</span>
    <span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">cluster_spec_file</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
        <span class="nb">print</span><span class="p">(</span><span class="n">f</span><span class="o">.</span><span class="n">read</span><span class="p">())</span>


<span class="k">if</span> <span class="vm">__name__</span> <span class="o">==</span> <span class="s2">&quot;__main__&quot;</span><span class="p">:</span>
    <span class="n">main</span><span class="p">()</span>
</pre></div>
</div>
</div>
</details></section>
<section id="ray-clusters-only-without-kubernetes">
<h3>仅限Ray Clusters（不含Kubernetes）<a class="headerlink" href="#ray-clusters-only-without-kubernetes" title="此标题的永久链接">#</a></h3>
<p>1.) 验证集群访问权限。</p>
<p>2.) 创建 <code class="docutils literal notranslate"><span class="pre">~/.cluster_config</span></code> 文件，其中 <code class="docutils literal notranslate"><span class="pre">name:</span> <span class="pre">&lt;NAME&gt;</span> <span class="pre">address:</span> <span class="pre">http://&lt;IP&gt;:&lt;PORT&gt;</span></code> 每个唯一集群在新的一行中。对于一个集群，文件中应该只有一行。</p>
<p>3.) 启动 MLFlow 服务器来接收 Ray 集群访问的日志，并确定服务器 URI。</p>
</section>
<section id="dispatching-steps-shared-between-kuberay-and-pure-ray-part-ii">
<h3>KubeRay与Pure Ray共享调度步骤 第 II 部分<a class="headerlink" href="#dispatching-steps-shared-between-kuberay-and-pure-ray-part-ii" title="此标题的永久链接">#</a></h3>
<p>1.) 测试您的集群是否正常运行，方法如下。</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><span class="c1"># Test that NVIDIA GPUs are visible and that Ray is operation with the following command:</span>
python3<span class="w"> </span>scripts/reinforcement_learning/ray/submit_job.py<span class="w"> </span>--aggregate_jobs<span class="w"> </span>wrap_resources.py<span class="w"> </span>--test
</pre></div>
</div>
<p>2.) 提交调优和/或资源包装作业在 <code class="file docutils literal notranslate"><span class="pre">submit_job.py</span></code> 文件中有描述。</p>
<details class="sd-sphinx-override sd-dropdown sd-card sd-mb-3">
<summary class="sd-summary-title sd-card-header">
<span class="sd-summary-icon"><svg version="1.1" width="1.0em" height="1.0em" class="sd-octicon sd-octicon-code" viewBox="0 0 16 16" aria-hidden="true"><path d="m11.28 3.22 4.25 4.25a.75.75 0 0 1 0 1.06l-4.25 4.25a.749.749 0 0 1-1.275-.326.749.749 0 0 1 .215-.734L13.94 8l-3.72-3.72a.749.749 0 0 1 .326-1.275.749.749 0 0 1 .734.215Zm-6.56 0a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042L2.06 8l3.72 3.72a.749.749 0 0 1-.326 1.275.749.749 0 0 1-.734-.215L.47 8.53a.75.75 0 0 1 0-1.06Z"></path></svg></span><span class="sd-summary-text">脚本 <cite>reinforcement_learning</cite>/<cite>ray</cite>/<cite>submit_job.py</cite></span><span class="sd-summary-state-marker sd-summary-chevron-right"><svg version="1.1" width="1.5em" height="1.5em" class="sd-octicon sd-octicon-chevron-right" viewBox="0 0 24 24" aria-hidden="true"><path d="M8.72 18.78a.75.75 0 0 1 0-1.06L14.44 12 8.72 6.28a.751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018l6.25 6.25a.75.75 0 0 1 0 1.06l-6.25 6.25a.75.75 0 0 1-1.06 0Z"></path></svg></span></summary><div class="sd-summary-content sd-card-body docutils">
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># Copyright (c) 2022-2025, The Isaac Lab Project Developers (https://github.com/isaac-sim/IsaacLab/blob/main/CONTRIBUTORS.md).</span>
<span class="c1"># All rights reserved.</span>
<span class="c1">#</span>
<span class="c1"># SPDX-License-Identifier: BSD-3-Clause</span>

<span class="sd">&quot;&quot;&quot;</span>
<span class="sd">This script submits aggregate job(s) to cluster(s) described in a</span>
<span class="sd">config file containing ``name: &lt;NAME&gt; address: http://&lt;IP&gt;:&lt;PORT&gt;`` on</span>
<span class="sd">a new line for each cluster. For KubeRay clusters, this file</span>
<span class="sd">can be automatically created with :file:`grok_cluster_with_kubectl.py`</span>

<span class="sd">Aggregate job(s) are matched with cluster(s) via the following relation:</span>
<span class="hll"><span class="sd">cluster_line_index_submitted_to = job_index % total_cluster_count</span>
</span><span class="hll">
</span><span class="hll"><span class="sd">Aggregate jobs are separated by the * delimiter. The ``--aggregate_jobs`` argument must be</span>
</span><span class="hll"><span class="sd">the last argument supplied to the script.</span>
</span><span class="hll">
</span><span class="hll"><span class="sd">An aggregate job could be a :file:`../tuner.py` tuning job, which automatically</span>
</span><span class="hll"><span class="sd">creates several individual jobs when started on a cluster. Alternatively, an aggregate job</span>
</span><span class="hll"><span class="sd">could be a :file:&#39;../wrap_resources.py` resource-wrapped job,</span>
</span><span class="hll"><span class="sd">which may contain several individual sub-jobs separated by</span>
</span><span class="hll"><span class="sd">the + delimiter. An aggregate job could also be a :file:`../task_runner.py` multi-task submission job,</span>
</span><span class="hll"><span class="sd">where each sub-job and its resource requirements are defined in a YAML configuration file.</span>
</span><span class="hll"><span class="sd">In this mode, :file:`../task_runner.py` will read the YAML file (via --task_cfg), and</span>
</span><span class="hll"><span class="sd">submit all defined sub-tasks to the Ray cluster, supporting per-job resource specification and</span>
</span><span class="hll"><span class="sd">real-time streaming of sub-job outputs.</span>
</span><span class="hll">
</span><span class="hll"><span class="sd">If there are more aggregate jobs than cluster(s), aggregate jobs will be submitted</span>
</span><span class="hll"><span class="sd">as clusters become available via the defined relation above. If there are less aggregate job(s)</span>
</span><span class="hll"><span class="sd">than clusters, some clusters will not receive aggregate job(s). The maximum number of</span>
</span><span class="hll"><span class="sd">aggregate jobs that can be run simultaneously is equal to the number of workers created by</span>
</span><span class="hll"><span class="sd">default by a ThreadPoolExecutor on the machine submitting jobs due to fetching the log output after</span>
</span><span class="hll"><span class="sd">jobs finish, which is unlikely to constrain overall-job submission.</span>
</span><span class="hll">
</span><span class="hll"><span class="sd">Usage:</span>
</span><span class="hll">
</span><span class="hll"><span class="sd">.. code-block:: bash</span>
</span><span class="hll">
</span><span class="hll"><span class="sd">    # Example; submitting a tuning job</span>
</span><span class="hll"><span class="sd">    python3 scripts/reinforcement_learning/ray/submit_job.py \</span>
</span><span class="hll"><span class="sd">    --aggregate_jobs /workspace/isaaclab/scripts/reinforcement_learning/ray/tuner.py \</span>
</span><span class="hll"><span class="sd">        --cfg_file hyperparameter_tuning/vision_cartpole_cfg.py \</span>
</span><span class="hll"><span class="sd">        --cfg_class CartpoleTheiaJobCfg --mlflow_uri &lt;ML_FLOW_URI&gt;</span>
</span><span class="hll">
</span><span class="hll"><span class="sd">    # Example: Submitting resource wrapped job</span>
</span><span class="hll"><span class="sd">    python3 scripts/reinforcement_learning/ray/submit_job.py --aggregate_jobs wrap_resources.py --test</span>
</span><span class="hll">
</span><span class="hll"><span class="sd">    # Example: submitting tasks with specific resources, and supporting pip packages and py_modules</span>
</span><span class="hll"><span class="sd">    # You may use relative paths for task_cfg and py_modules, placing them in the scripts/reinforcement_learning/ray directory, which will be uploaded to the cluster.</span>
</span><span class="hll"><span class="sd">    python3 scripts/reinforcement_learning/ray/submit_job.py --aggregate_jobs task_runner.py --task_cfg tasks.yaml</span>
</span><span class="hll">
</span><span class="hll"><span class="sd">    # For all command line arguments</span>
</span><span class="hll"><span class="sd">    python3 scripts/reinforcement_learning/ray/submit_job.py -h</span>
</span><span class="hll"><span class="sd">&quot;&quot;&quot;</span>
</span><span class="hll">
</span><span class="hll"><span class="kn">import</span><span class="w"> </span><span class="nn">argparse</span>
</span><span class="hll"><span class="kn">import</span><span class="w"> </span><span class="nn">os</span>
</span><span class="hll"><span class="kn">import</span><span class="w"> </span><span class="nn">time</span>
</span><span class="hll"><span class="kn">from</span><span class="w"> </span><span class="nn">concurrent.futures</span><span class="w"> </span><span class="kn">import</span> <span class="n">ThreadPoolExecutor</span>
</span><span class="hll">
</span><span class="hll"><span class="kn">from</span><span class="w"> </span><span class="nn">ray</span><span class="w"> </span><span class="kn">import</span> <span class="n">job_submission</span>
</span>
<span class="n">script_directory</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">dirname</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">abspath</span><span class="p">(</span><span class="vm">__file__</span><span class="p">))</span>
<span class="n">CONFIG</span> <span class="o">=</span> <span class="p">{</span><span class="s2">&quot;working_dir&quot;</span><span class="p">:</span> <span class="n">script_directory</span><span class="p">,</span> <span class="s2">&quot;executable&quot;</span><span class="p">:</span> <span class="s2">&quot;/workspace/isaaclab/isaaclab.sh -p&quot;</span><span class="p">}</span>


<span class="k">def</span><span class="w"> </span><span class="nf">read_cluster_spec</span><span class="p">(</span><span class="n">fn</span><span class="p">:</span> <span class="nb">str</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">list</span><span class="p">[</span><span class="nb">dict</span><span class="p">]:</span>
    <span class="k">if</span> <span class="n">fn</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">cluster_spec_path</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">expanduser</span><span class="p">(</span><span class="s2">&quot;~/.cluster_config&quot;</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">cluster_spec_path</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">expanduser</span><span class="p">(</span><span class="n">fn</span><span class="p">)</span>

    <span class="k">if</span> <span class="ow">not</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">exists</span><span class="p">(</span><span class="n">cluster_spec_path</span><span class="p">):</span>
        <span class="k">raise</span> <span class="ne">FileNotFoundError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Cluster spec file not found at </span><span class="si">{</span><span class="n">cluster_spec_path</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

    <span class="n">clusters</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">cluster_spec_path</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
        <span class="k">for</span> <span class="n">line</span> <span class="ow">in</span> <span class="n">f</span><span class="p">:</span>
            <span class="n">parts</span> <span class="o">=</span> <span class="n">line</span><span class="o">.</span><span class="n">strip</span><span class="p">()</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s2">&quot; &quot;</span><span class="p">)</span>
            <span class="n">http_address</span> <span class="o">=</span> <span class="n">parts</span><span class="p">[</span><span class="mi">3</span><span class="p">]</span>
            <span class="n">cluster_info</span> <span class="o">=</span> <span class="p">{</span><span class="s2">&quot;name&quot;</span><span class="p">:</span> <span class="n">parts</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="s2">&quot;address&quot;</span><span class="p">:</span> <span class="n">http_address</span><span class="p">}</span>
            <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;[INFO] Setting </span><span class="si">{</span><span class="n">cluster_info</span><span class="p">[</span><span class="s1">&#39;name&#39;</span><span class="p">]</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>  <span class="c1"># with {cluster_info[&#39;num_gpu&#39;]} GPUs.&quot;)</span>
            <span class="n">clusters</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">cluster_info</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">clusters</span>


<span class="k">def</span><span class="w"> </span><span class="nf">submit_job</span><span class="p">(</span><span class="n">cluster</span><span class="p">:</span> <span class="nb">dict</span><span class="p">,</span> <span class="n">job_command</span><span class="p">:</span> <span class="nb">str</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Submits a job to a single cluster, prints the final result and Ray dashboard URL at the end.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">address</span> <span class="o">=</span> <span class="n">cluster</span><span class="p">[</span><span class="s2">&quot;address&quot;</span><span class="p">]</span>
    <span class="n">cluster_name</span> <span class="o">=</span> <span class="n">cluster</span><span class="p">[</span><span class="s2">&quot;name&quot;</span><span class="p">]</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;[INFO]: Submitting job to cluster &#39;</span><span class="si">{</span><span class="n">cluster_name</span><span class="si">}</span><span class="s2">&#39; at </span><span class="si">{</span><span class="n">address</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>  <span class="c1"># with {num_gpus} GPUs.&quot;)</span>
    <span class="n">client</span> <span class="o">=</span> <span class="n">job_submission</span><span class="o">.</span><span class="n">JobSubmissionClient</span><span class="p">(</span><span class="n">address</span><span class="p">)</span>
    <span class="n">runtime_env</span> <span class="o">=</span> <span class="p">{</span><span class="s2">&quot;working_dir&quot;</span><span class="p">:</span> <span class="n">CONFIG</span><span class="p">[</span><span class="s2">&quot;working_dir&quot;</span><span class="p">],</span> <span class="s2">&quot;executable&quot;</span><span class="p">:</span> <span class="n">CONFIG</span><span class="p">[</span><span class="s2">&quot;executable&quot;</span><span class="p">]}</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;[INFO]: Checking contents of the directory: </span><span class="si">{</span><span class="n">CONFIG</span><span class="p">[</span><span class="s1">&#39;working_dir&#39;</span><span class="p">]</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="k">try</span><span class="p">:</span>
        <span class="n">dir_contents</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">listdir</span><span class="p">(</span><span class="n">CONFIG</span><span class="p">[</span><span class="s2">&quot;working_dir&quot;</span><span class="p">])</span>
        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;[INFO]: Directory contents: </span><span class="si">{</span><span class="n">dir_contents</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="k">except</span> <span class="ne">Exception</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;[INFO]: Failed to list directory contents: </span><span class="si">{</span><span class="nb">str</span><span class="p">(</span><span class="n">e</span><span class="p">)</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="n">entrypoint</span> <span class="o">=</span> <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">CONFIG</span><span class="p">[</span><span class="s1">&#39;executable&#39;</span><span class="p">]</span><span class="si">}</span><span class="s2"> </span><span class="si">{</span><span class="n">job_command</span><span class="si">}</span><span class="s2">&quot;</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;[INFO]: Attempting entrypoint </span><span class="si">{</span><span class="n">entrypoint</span><span class="si">=}</span><span class="s2"> in cluster </span><span class="si">{</span><span class="n">cluster</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="n">job_id</span> <span class="o">=</span> <span class="n">client</span><span class="o">.</span><span class="n">submit_job</span><span class="p">(</span><span class="n">entrypoint</span><span class="o">=</span><span class="n">entrypoint</span><span class="p">,</span> <span class="n">runtime_env</span><span class="o">=</span><span class="n">runtime_env</span><span class="p">)</span>
    <span class="n">status</span> <span class="o">=</span> <span class="n">client</span><span class="o">.</span><span class="n">get_job_status</span><span class="p">(</span><span class="n">job_id</span><span class="p">)</span>
    <span class="k">while</span> <span class="n">status</span> <span class="ow">in</span> <span class="p">[</span><span class="n">job_submission</span><span class="o">.</span><span class="n">JobStatus</span><span class="o">.</span><span class="n">PENDING</span><span class="p">,</span> <span class="n">job_submission</span><span class="o">.</span><span class="n">JobStatus</span><span class="o">.</span><span class="n">RUNNING</span><span class="p">]:</span>
        <span class="n">time</span><span class="o">.</span><span class="n">sleep</span><span class="p">(</span><span class="mi">5</span><span class="p">)</span>
        <span class="n">status</span> <span class="o">=</span> <span class="n">client</span><span class="o">.</span><span class="n">get_job_status</span><span class="p">(</span><span class="n">job_id</span><span class="p">)</span>

    <span class="n">final_logs</span> <span class="o">=</span> <span class="n">client</span><span class="o">.</span><span class="n">get_job_logs</span><span class="p">(</span><span class="n">job_id</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;----------------------------------------------------&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;[INFO]: Cluster </span><span class="si">{</span><span class="n">cluster_name</span><span class="si">}</span><span class="s2"> Logs: </span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">final_logs</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;----------------------------------------------------&quot;</span><span class="p">)</span>


<span class="k">def</span><span class="w"> </span><span class="nf">submit_jobs_to_clusters</span><span class="p">(</span><span class="n">jobs</span><span class="p">:</span> <span class="nb">list</span><span class="p">[</span><span class="nb">str</span><span class="p">],</span> <span class="n">clusters</span><span class="p">:</span> <span class="nb">list</span><span class="p">[</span><span class="nb">dict</span><span class="p">])</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Submit all jobs to their respective clusters, cycling through clusters if there are more jobs than clusters.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="n">clusters</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;No clusters available for job submission.&quot;</span><span class="p">)</span>

    <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">jobs</span><span class="p">)</span> <span class="o">&lt;</span> <span class="nb">len</span><span class="p">(</span><span class="n">clusters</span><span class="p">):</span>
        <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;[INFO]: Less jobs than clusters, some clusters will not receive jobs&quot;</span><span class="p">)</span>
    <span class="k">elif</span> <span class="nb">len</span><span class="p">(</span><span class="n">jobs</span><span class="p">)</span> <span class="o">==</span> <span class="nb">len</span><span class="p">(</span><span class="n">clusters</span><span class="p">):</span>
        <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;[INFO]: Exactly one job per cluster&quot;</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;[INFO]: More jobs than clusters, jobs submitted as clusters become available.&quot;</span><span class="p">)</span>
    <span class="k">with</span> <span class="n">ThreadPoolExecutor</span><span class="p">()</span> <span class="k">as</span> <span class="n">executor</span><span class="p">:</span>
        <span class="k">for</span> <span class="n">idx</span><span class="p">,</span> <span class="n">job_command</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">jobs</span><span class="p">):</span>
            <span class="c1"># Cycle through clusters using modulus to wrap around if there are more jobs than clusters</span>
            <span class="n">cluster</span> <span class="o">=</span> <span class="n">clusters</span><span class="p">[</span><span class="n">idx</span> <span class="o">%</span> <span class="nb">len</span><span class="p">(</span><span class="n">clusters</span><span class="p">)]</span>
            <span class="n">executor</span><span class="o">.</span><span class="n">submit</span><span class="p">(</span><span class="n">submit_job</span><span class="p">,</span> <span class="n">cluster</span><span class="p">,</span> <span class="n">job_command</span><span class="p">)</span>


<span class="k">if</span> <span class="vm">__name__</span> <span class="o">==</span> <span class="s2">&quot;__main__&quot;</span><span class="p">:</span>
    <span class="n">parser</span> <span class="o">=</span> <span class="n">argparse</span><span class="o">.</span><span class="n">ArgumentParser</span><span class="p">(</span><span class="n">description</span><span class="o">=</span><span class="s2">&quot;Submit multiple GPU jobs to multiple Ray clusters.&quot;</span><span class="p">)</span>
    <span class="n">parser</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span><span class="s2">&quot;--config_file&quot;</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="s2">&quot;~/.cluster_config&quot;</span><span class="p">,</span> <span class="n">help</span><span class="o">=</span><span class="s2">&quot;The cluster config path.&quot;</span><span class="p">)</span>
    <span class="n">parser</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span>
        <span class="s2">&quot;--aggregate_jobs&quot;</span><span class="p">,</span>
        <span class="nb">type</span><span class="o">=</span><span class="nb">str</span><span class="p">,</span>
        <span class="n">nargs</span><span class="o">=</span><span class="n">argparse</span><span class="o">.</span><span class="n">REMAINDER</span><span class="p">,</span>
        <span class="n">help</span><span class="o">=</span><span class="s2">&quot;This should be last argument. The aggregate jobs to submit separated by the * delimiter.&quot;</span><span class="p">,</span>
    <span class="p">)</span>
    <span class="n">args</span> <span class="o">=</span> <span class="n">parser</span><span class="o">.</span><span class="n">parse_args</span><span class="p">()</span>
    <span class="k">if</span> <span class="n">args</span><span class="o">.</span><span class="n">aggregate_jobs</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">jobs</span> <span class="o">=</span> <span class="s2">&quot; &quot;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">args</span><span class="o">.</span><span class="n">aggregate_jobs</span><span class="p">)</span>
        <span class="n">formatted_jobs</span> <span class="o">=</span> <span class="n">jobs</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s2">&quot;*&quot;</span><span class="p">)</span>
        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">formatted_jobs</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">:</span>
            <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Warning; Split jobs by cluster with the * delimiter&quot;</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">formatted_jobs</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;[INFO]: Isaac Ray Wrapper received jobs </span><span class="si">{</span><span class="n">formatted_jobs</span><span class="si">=}</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="n">clusters</span> <span class="o">=</span> <span class="n">read_cluster_spec</span><span class="p">(</span><span class="n">args</span><span class="o">.</span><span class="n">config_file</span><span class="p">)</span>
    <span class="n">submit_jobs_to_clusters</span><span class="p">(</span><span class="n">formatted_jobs</span><span class="p">,</span> <span class="n">clusters</span><span class="p">)</span>
</pre></div>
</div>
</div>
</details><p>3.) 对于调优任务，指定调优任务 / 超参数搜索作为 <code class="xref py py-class docutils literal notranslate"><span class="pre">JobCfg</span></code> 。由于环境入口点和 Hydra 参数的差异，所包含的 <code class="xref py py-class docutils literal notranslate"><span class="pre">JobCfg</span></code> 仅支持 <code class="docutils literal notranslate"><span class="pre">rl_games</span></code> 工作流，尽管如果提供兼容的 <code class="xref py py-class docutils literal notranslate"><span class="pre">JobCfg</span></code> ，其他工作流也可以正常运行。</p>
<details class="sd-sphinx-override sd-dropdown sd-card sd-mb-3">
<summary class="sd-summary-title sd-card-header">
<span class="sd-summary-icon"><svg version="1.1" width="1.0em" height="1.0em" class="sd-octicon sd-octicon-code" viewBox="0 0 16 16" aria-hidden="true"><path d="m11.28 3.22 4.25 4.25a.75.75 0 0 1 0 1.06l-4.25 4.25a.749.749 0 0 1-1.275-.326.749.749 0 0 1 .215-.734L13.94 8l-3.72-3.72a.749.749 0 0 1 .326-1.275.749.749 0 0 1 .734.215Zm-6.56 0a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042L2.06 8l3.72 3.72a.749.749 0 0 1-.326 1.275.749.749 0 0 1-.734-.215L.47 8.53a.75.75 0 0 1 0-1.06Z"></path></svg></span><span class="sd-summary-text">scripts/reinforcement_learning/ray/tuner.py (JobCfg 定义)</span><span class="sd-summary-state-marker sd-summary-chevron-right"><svg version="1.1" width="1.5em" height="1.5em" class="sd-octicon sd-octicon-chevron-right" viewBox="0 0 24 24" aria-hidden="true"><path d="M8.72 18.78a.75.75 0 0 1 0-1.06L14.44 12 8.72 6.28a.751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018l6.25 6.25a.75.75 0 0 1 0 1.06l-6.25 6.25a.75.75 0 0 1-1.06 0Z"></path></svg></span></summary><div class="sd-summary-content sd-card-body docutils">
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">class</span><span class="w"> </span><span class="nc">JobCfg</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;To be compatible with :meth: invoke_tuning_run and :class:IsaacLabTuneTrainable,</span>
<span class="sd">    at a minimum, the tune job should inherit from this class.&quot;&quot;&quot;</span>

    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">cfg</span><span class="p">:</span> <span class="nb">dict</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Runner args include command line arguments passed to the task.</span>
<span class="sd">        For example:</span>
<span class="sd">        cfg[&quot;runner_args&quot;][&quot;headless_singleton&quot;] = &quot;--headless&quot;</span>
<span class="sd">        cfg[&quot;runner_args&quot;][&quot;enable_cameras_singleton&quot;] = &quot;--enable_cameras&quot;</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">assert</span> <span class="s2">&quot;runner_args&quot;</span> <span class="ow">in</span> <span class="n">cfg</span><span class="p">,</span> <span class="s2">&quot;No runner arguments specified.&quot;</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Task is the desired task to train on. For example:</span>
<span class="sd">        cfg[&quot;runner_args&quot;][&quot;--task&quot;] = tune.choice([&quot;Isaac-Cartpole-RGB-TheiaTiny-v0&quot;])</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">assert</span> <span class="s2">&quot;--task&quot;</span> <span class="ow">in</span> <span class="n">cfg</span><span class="p">[</span><span class="s2">&quot;runner_args&quot;</span><span class="p">],</span> <span class="s2">&quot;No task specified.&quot;</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Hydra args define the hyperparameters varied within the sweep. For example:</span>
<span class="sd">        cfg[&quot;hydra_args&quot;][&quot;agent.params.network.cnn.activation&quot;] = tune.choice([&quot;relu&quot;, &quot;elu&quot;])</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">assert</span> <span class="s2">&quot;hydra_args&quot;</span> <span class="ow">in</span> <span class="n">cfg</span><span class="p">,</span> <span class="s2">&quot;No hyperparameters specified.&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">cfg</span> <span class="o">=</span> <span class="n">cfg</span>
</pre></div>
</div>
</div>
</details><p>例如，请参阅 Cartpole 示例配置。</p>
<details class="sd-sphinx-override sd-dropdown sd-card sd-mb-3">
<summary class="sd-summary-title sd-card-header">
<span class="sd-summary-icon"><svg version="1.1" width="1.0em" height="1.0em" class="sd-octicon sd-octicon-code" viewBox="0 0 16 16" aria-hidden="true"><path d="m11.28 3.22 4.25 4.25a.75.75 0 0 1 0 1.06l-4.25 4.25a.749.749 0 0 1-1.275-.326.749.749 0 0 1 .215-.734L13.94 8l-3.72-3.72a.749.749 0 0 1 .326-1.275.749.749 0 0 1 .734.215Zm-6.56 0a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042L2.06 8l3.72 3.72a.749.749 0 0 1-.326 1.275.749.749 0 0 1-.734-.215L.47 8.53a.75.75 0 0 1 0-1.06Z"></path></svg></span><span class="sd-summary-text">scripts/reinforcement_learning/ray/hyperparameter_tuning/vision_cartpole_cfg.py</span><span class="sd-summary-state-marker sd-summary-chevron-right"><svg version="1.1" width="1.5em" height="1.5em" class="sd-octicon sd-octicon-chevron-right" viewBox="0 0 24 24" aria-hidden="true"><path d="M8.72 18.78a.75.75 0 0 1 0-1.06L14.44 12 8.72 6.28a.751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018l6.25 6.25a.75.75 0 0 1 0 1.06l-6.25 6.25a.75.75 0 0 1-1.06 0Z"></path></svg></span></summary><div class="sd-summary-content sd-card-body docutils">
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># Copyright (c) 2022-2025, The Isaac Lab Project Developers (https://github.com/isaac-sim/IsaacLab/blob/main/CONTRIBUTORS.md).</span>
<span class="c1"># All rights reserved.</span>
<span class="c1">#</span>
<span class="c1"># SPDX-License-Identifier: BSD-3-Clause</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">pathlib</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">sys</span>

<span class="c1"># Allow for import of items from the ray workflow.</span>
<span class="n">CUR_DIR</span> <span class="o">=</span> <span class="n">pathlib</span><span class="o">.</span><span class="n">Path</span><span class="p">(</span><span class="vm">__file__</span><span class="p">)</span><span class="o">.</span><span class="n">parent</span>
<span class="n">UTIL_DIR</span> <span class="o">=</span> <span class="n">CUR_DIR</span><span class="o">.</span><span class="n">parent</span>
<span class="n">sys</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">extend</span><span class="p">([</span><span class="nb">str</span><span class="p">(</span><span class="n">UTIL_DIR</span><span class="p">),</span> <span class="nb">str</span><span class="p">(</span><span class="n">CUR_DIR</span><span class="p">)])</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">util</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">vision_cfg</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">ray</span><span class="w"> </span><span class="kn">import</span> <span class="n">tune</span>


<span class="k">class</span><span class="w"> </span><span class="nc">CartpoleRGBNoTuneJobCfg</span><span class="p">(</span><span class="n">vision_cfg</span><span class="o">.</span><span class="n">CameraJobCfg</span><span class="p">):</span>
    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">cfg</span><span class="p">:</span> <span class="nb">dict</span> <span class="o">=</span> <span class="p">{}):</span>
        <span class="n">cfg</span> <span class="o">=</span> <span class="n">util</span><span class="o">.</span><span class="n">populate_isaac_ray_cfg_args</span><span class="p">(</span><span class="n">cfg</span><span class="p">)</span>
        <span class="n">cfg</span><span class="p">[</span><span class="s2">&quot;runner_args&quot;</span><span class="p">][</span><span class="s2">&quot;--task&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">tune</span><span class="o">.</span><span class="n">choice</span><span class="p">([</span><span class="s2">&quot;Isaac-Cartpole-RGB-v0&quot;</span><span class="p">])</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">cfg</span><span class="p">,</span> <span class="n">vary_env_count</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">vary_cnn</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">vary_mlp</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>


<span class="k">class</span><span class="w"> </span><span class="nc">CartpoleRGBCNNOnlyJobCfg</span><span class="p">(</span><span class="n">vision_cfg</span><span class="o">.</span><span class="n">CameraJobCfg</span><span class="p">):</span>
    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">cfg</span><span class="p">:</span> <span class="nb">dict</span> <span class="o">=</span> <span class="p">{}):</span>
        <span class="n">cfg</span> <span class="o">=</span> <span class="n">util</span><span class="o">.</span><span class="n">populate_isaac_ray_cfg_args</span><span class="p">(</span><span class="n">cfg</span><span class="p">)</span>
        <span class="n">cfg</span><span class="p">[</span><span class="s2">&quot;runner_args&quot;</span><span class="p">][</span><span class="s2">&quot;--task&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">tune</span><span class="o">.</span><span class="n">choice</span><span class="p">([</span><span class="s2">&quot;Isaac-Cartpole-RGB-v0&quot;</span><span class="p">])</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">cfg</span><span class="p">,</span> <span class="n">vary_env_count</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">vary_cnn</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">vary_mlp</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>


<span class="k">class</span><span class="w"> </span><span class="nc">CartpoleRGBJobCfg</span><span class="p">(</span><span class="n">vision_cfg</span><span class="o">.</span><span class="n">CameraJobCfg</span><span class="p">):</span>
    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">cfg</span><span class="p">:</span> <span class="nb">dict</span> <span class="o">=</span> <span class="p">{}):</span>
        <span class="n">cfg</span> <span class="o">=</span> <span class="n">util</span><span class="o">.</span><span class="n">populate_isaac_ray_cfg_args</span><span class="p">(</span><span class="n">cfg</span><span class="p">)</span>
        <span class="n">cfg</span><span class="p">[</span><span class="s2">&quot;runner_args&quot;</span><span class="p">][</span><span class="s2">&quot;--task&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">tune</span><span class="o">.</span><span class="n">choice</span><span class="p">([</span><span class="s2">&quot;Isaac-Cartpole-RGB-v0&quot;</span><span class="p">])</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">cfg</span><span class="p">,</span> <span class="n">vary_env_count</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">vary_cnn</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">vary_mlp</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>


<span class="k">class</span><span class="w"> </span><span class="nc">CartpoleResNetJobCfg</span><span class="p">(</span><span class="n">vision_cfg</span><span class="o">.</span><span class="n">ResNetCameraJob</span><span class="p">):</span>
    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">cfg</span><span class="p">:</span> <span class="nb">dict</span> <span class="o">=</span> <span class="p">{}):</span>
        <span class="n">cfg</span> <span class="o">=</span> <span class="n">util</span><span class="o">.</span><span class="n">populate_isaac_ray_cfg_args</span><span class="p">(</span><span class="n">cfg</span><span class="p">)</span>
        <span class="n">cfg</span><span class="p">[</span><span class="s2">&quot;runner_args&quot;</span><span class="p">][</span><span class="s2">&quot;--task&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">tune</span><span class="o">.</span><span class="n">choice</span><span class="p">([</span><span class="s2">&quot;Isaac-Cartpole-RGB-ResNet18-v0&quot;</span><span class="p">])</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">cfg</span><span class="p">)</span>


<span class="k">class</span><span class="w"> </span><span class="nc">CartpoleTheiaJobCfg</span><span class="p">(</span><span class="n">vision_cfg</span><span class="o">.</span><span class="n">TheiaCameraJob</span><span class="p">):</span>
    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">cfg</span><span class="p">:</span> <span class="nb">dict</span> <span class="o">=</span> <span class="p">{}):</span>
        <span class="n">cfg</span> <span class="o">=</span> <span class="n">util</span><span class="o">.</span><span class="n">populate_isaac_ray_cfg_args</span><span class="p">(</span><span class="n">cfg</span><span class="p">)</span>
        <span class="n">cfg</span><span class="p">[</span><span class="s2">&quot;runner_args&quot;</span><span class="p">][</span><span class="s2">&quot;--task&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">tune</span><span class="o">.</span><span class="n">choice</span><span class="p">([</span><span class="s2">&quot;Isaac-Cartpole-RGB-TheiaTiny-v0&quot;</span><span class="p">])</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">cfg</span><span class="p">)</span>
</pre></div>
</div>
</div>
</details><p>要查看调优结果，请查看您创建的服务器的 MLFlow 仪表板。对于 KubeRay，可以通过端口转发 MLFlow 仪表板来实现，方法如下:</p>
<p><code class="docutils literal notranslate"><span class="pre">kubectl</span> <span class="pre">port-forward</span> <span class="pre">service/isaacray-mlflow</span> <span class="pre">5000:5000</span></code></p>
<p>然后在浏览器中访问以下地址。</p>
<p><code class="docutils literal notranslate"><span class="pre">localhost:5000</span></code></p>
<p>如果如上所述转发了 MLFlow 端口，则可以使用以下命令将其转换为 TensorBoard 日志。</p>
<p><code class="docutils literal notranslate"><span class="pre">./isaaclab.sh</span> <span class="pre">-p</span> <span class="pre">scripts/reinforcement_learning/ray/mlflow_to_local_tensorboard.py</span> <span class="pre">\</span>
<span class="pre">--uri</span> <span class="pre">http://localhost:5000</span> <span class="pre">--experiment-name</span> <span class="pre">IsaacRay-&lt;CLASS_JOB_CFG&gt;-tune</span> <span class="pre">--download-dir</span> <span class="pre">test</span></code></p>
<section id="kubernetes-cluster-cleanup">
<h4>Kubernetes集群清理<a class="headerlink" href="#kubernetes-cluster-cleanup" title="此标题的永久链接">#</a></h4>
<p>为了节省资源，并可能为其他人在共享计算平台上使用宝贵的 GPU 资源，请在使用后销毁 Ray 集群。它们可以轻松地重新创建！对于 KubeRay 集群，可以按照以下方法进行。</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>kubectl<span class="w"> </span>get<span class="w"> </span>raycluster<span class="w"> </span><span class="p">|</span><span class="w"> </span>egrep<span class="w"> </span><span class="s1">&#39;isaacray&#39;</span><span class="w"> </span><span class="p">|</span><span class="w"> </span>awk<span class="w"> </span><span class="s1">&#39;{print $1}&#39;</span><span class="w"> </span><span class="p">|</span><span class="w"> </span>xargs<span class="w"> </span>kubectl<span class="w"> </span>delete<span class="w"> </span>raycluster<span class="w"> </span><span class="o">&amp;&amp;</span>
kubectl<span class="w"> </span>get<span class="w"> </span>deployments<span class="w"> </span><span class="p">|</span><span class="w"> </span>egrep<span class="w"> </span><span class="s1">&#39;mlflow&#39;</span><span class="w"> </span><span class="p">|</span><span class="w"> </span>awk<span class="w"> </span><span class="s1">&#39;{print $1}&#39;</span><span class="w"> </span><span class="p">|</span><span class="w"> </span>xargs<span class="w"> </span>kubectl<span class="w"> </span>delete<span class="w"> </span>deployment<span class="w"> </span><span class="o">&amp;&amp;</span>
kubectl<span class="w"> </span>get<span class="w"> </span>services<span class="w"> </span><span class="p">|</span><span class="w"> </span>egrep<span class="w"> </span><span class="s1">&#39;mlflow&#39;</span><span class="w"> </span><span class="p">|</span><span class="w"> </span>awk<span class="w"> </span><span class="s1">&#39;{print $1}&#39;</span><span class="w"> </span><span class="p">|</span><span class="w"> </span>xargs<span class="w"> </span>kubectl<span class="w"> </span>delete<span class="w"> </span>service<span class="w"> </span><span class="o">&amp;&amp;</span>
kubectl<span class="w"> </span>get<span class="w"> </span>services<span class="w"> </span><span class="p">|</span><span class="w"> </span>egrep<span class="w"> </span><span class="s1">&#39;isaacray&#39;</span><span class="w"> </span><span class="p">|</span><span class="w"> </span>awk<span class="w"> </span><span class="s1">&#39;{print $1}&#39;</span><span class="w"> </span><span class="p">|</span><span class="w"> </span>xargs<span class="w"> </span>kubectl<span class="w"> </span>delete<span class="w"> </span>service
</pre></div>
</div>
</section>
</section>
</section>
</section>


                </article>
              

              
              
              
              
                <footer class="prev-next-footer d-print-none">
                  
<div class="prev-next-area">
    <a class="left-prev"
       href="multi_gpu.html"
       title="上一页">
      <i class="fa-solid fa-angle-left"></i>
      <div class="prev-next-info">
        <p class="prev-next-subtitle">上一页</p>
        <p class="prev-next-title">多GPU和多节点训练</p>
      </div>
    </a>
    <a class="right-next"
       href="reproducibility.html"
       title="下一页">
      <div class="prev-next-info">
        <p class="prev-next-subtitle">下一页</p>
        <p class="prev-next-title">可重现性和确定性</p>
      </div>
      <i class="fa-solid fa-angle-right"></i>
    </a>
</div>
                </footer>
              
            </div>
            
            
              
                <dialog id="pst-secondary-sidebar-modal"></dialog>
                <div id="pst-secondary-sidebar" class="bd-sidebar-secondary bd-toc"><div class="sidebar-secondary-items sidebar-secondary__inner">


  <div class="sidebar-secondary-item">
  <div class="page-toc tocsection onthispage">
    <i class="fa-solid fa-list"></i> 目录
  </div>
  <nav class="bd-toc-nav page-toc">
    <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#overview">概述</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#docker-based-local-quickstart">基于 Docker 的本地快速启动</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#remote-clusters">远程集群</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#kuberay-setup">KubeRay 安装</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#ray-clusters-without-kubernetes-setup">Ray 集群（不使用 Kubernetes）安装</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#shared-steps-between-kuberay-and-pure-ray-part-i">KubeRay 和纯 Ray 之间的共享步骤 第 I 部分</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#kuberay-clusters-only">仅限KubeRay集群</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#ray-clusters-only-without-kubernetes">仅限Ray Clusters（不含Kubernetes）</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#dispatching-steps-shared-between-kuberay-and-pure-ray-part-ii">KubeRay与Pure Ray共享调度步骤 第 II 部分</a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#kubernetes-cluster-cleanup">Kubernetes集群清理</a></li>
</ul>
</li>
</ul>
</li>
</ul>
  </nav></div>

</div></div>
              
            
          </div>
          <footer class="bd-footer-content">
            
<div class="bd-footer-content__inner container">
  
  <div class="footer-item">
    
<p class="component-author">
作者： The Isaac Lab Project Developers. Translate by 范子琦(Github@fan-ziqi)
</p>

  </div>
  
  <div class="footer-item">
    

  <p class="copyright">
    
      © Copyright 2022-2025, The Isaac Lab Project Developers..
      <br/>
    
  </p>

  </div>
  
  <div class="footer-item">
    <p class="last-updated">
  最后更新于 2025 年 09 月 05 日.
  <br/>
</p>
  </div>
  
  <div class="footer-item">
    
<div class="extra_footer">
  <!--Matomo--><script>var _paq=window._paq=window._paq||[];_paq.push(["setDocumentTitle",document.domain+"/"+document.title]);_paq.push(['trackPageView']);_paq.push(['enableLinkTracking']);(function(){var u="//matomo.robotsfan.com/";_paq.push(['setTrackerUrl',u+'matomo.php']);_paq.push(['setSiteId','2']);var d=document,g=d.createElement('script'),s=d.getElementsByTagName('script')[0];g.async=true;g.src=u+'matomo.js';s.parentNode.insertBefore(g,s)})();</script><!--End Matomo Code-->
</div>
  </div>
  
</div>
          </footer>
        

      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script defer src="../../_static/scripts/bootstrap.js?digest=8878045cc6db502f8baf"></script>
<script defer src="../../_static/scripts/pydata-sphinx-theme.js?digest=8878045cc6db502f8baf"></script>

  <footer class="bd-footer">
  </footer>
  </body>
</html>