# SOME DESCRIPTIVE TITLE.
# Copyright (C) 2022-2024, The Isaac Lab Project Developers.
# This file is distributed under the same license as the Isaac Lab package.
# FIRST AUTHOR <EMAIL@ADDRESS>, 2024.
#
msgid ""
msgstr ""
"Project-Id-Version: Isaac Lab 1.2.0\n"
"Report-Msgid-Bugs-To: \n"
"POT-Creation-Date: 2025-01-31 20:38+0800\n"
"PO-Revision-Date: YEAR-MO-DA HO:MI+ZONE\n"
"Last-Translator: Ziqi Fan <fanziqi614@gmail.com>\n"
"Language-Team: zh_CN <LL@li.org>\n"
"Language: zh_CN\n"
"MIME-Version: 1.0\n"
"Content-Type: text/plain; charset=utf-8\n"
"Content-Transfer-Encoding: 8bit\n"
"Plural-Forms: nplurals=1; plural=0;\n"
"Generated-By: Babel 2.16.0\n"

#: ../../source/refs/reference_architecture/index.rst:2
msgid "Reference Architecture"
msgstr "参考架构"

#: ../../source/refs/reference_architecture/index.rst:4
msgid ""
"This document presents an overview of the end-to-end robot learning process "
"with Isaac Lab and Isaac Sim. This is demonstrated using a reference "
"architecture that highlights the major building blocks for training and "
"deployment workflows. It provides a comprehensive, user-friendly guide on "
"the entire process of developing applications from training to deploying the"
" trained model in the real world, including links to demos, working "
"examples, and documentation."
msgstr ""
"本文档介绍了使用 Isaac Lab 和 Isaac Sim "
"的端到端机器人学习过程概述。通过使用一个参考架构，展示了训练和部署工作流的主要构建模块。它提供了一个全面、用户友好的指南，涵盖了从训练到将训练好的模型部署到现实世界的整个应用开发过程，包括演示链接、工作示例和文档。"

#: ../../source/refs/reference_architecture/index.rst:11
msgid "Who is this document for?"
msgstr "这个文档适用于谁？"

#: ../../source/refs/reference_architecture/index.rst:13
msgid ""
"This document is designed to assist robotics developers and researchers "
"working with NVIDIA Isaac Lab in the robot learning field, including those "
"at research labs, Original Equipment Manufacturers (OEM), Solutions "
"Providers, Solutions Integrators (SI),  and independent software vendors "
"(ISV). It offers guidance on utilizing Isaac Lab’s robot training framework "
"and workflows as a foundational starting point for environment "
"configuration, task design, and policy training and testing."
msgstr ""
"本文档旨在帮助在机器人学习领域使用 NVIDIA Isaac Lab "
"的机器人开发者和研究人员，包括研究实验室、原始设备制造商（OEM）、解决方案提供商、解决方案集成商（SI）以及独立软件供应商（ISV）。它为使用 "
"Isaac Lab 的机器人训练框架和工作流提供指导，作为环境配置、任务设计和策略训练与测试的基础起点。"

#: ../../source/refs/reference_architecture/index.rst:-1
msgid "Isaac Lab Reference Architecture"
msgstr "Isaac Lab 参考架构"

#: ../../source/refs/reference_architecture/index.rst:34
msgid ""
"The reference architecture for Isaac Lab comprises the following components:"
msgstr "Isaac Lab 的参考架构包括以下组件:"

#: ../../source/refs/reference_architecture/index.rst:36
msgid ":ref:`Asset Input<ra-asset-input>`"
msgstr ":ref:`资产输入<ra-asset-input>`"

#: ../../source/refs/reference_architecture/index.rst:37
msgid ":ref:`Configuration - Assets & Scene<ra-configuration>`"
msgstr ":ref:`配置 - 资产与场景-configuration>`"

#: ../../source/refs/reference_architecture/index.rst:38
msgid ":ref:`Robot Learning Task Design<ra-robot-learning-task-design>`"
msgstr ":ref:`机器人学习任务设计<ra-robot-learning-task-design>`"

#: ../../source/refs/reference_architecture/index.rst:39
msgid ":ref:`Register with Gymnasium<ra-register-gym>`"
msgstr ":ref:`在 Gymnasium 中注册<ra-register-gym>`"

#: ../../source/refs/reference_architecture/index.rst:40
msgid ":ref:`Environment Wrapping<ra-env-wrap>`"
msgstr ":ref:`环境封装<ra-env-wrap>`"

#: ../../source/refs/reference_architecture/index.rst:41
msgid ":ref:`Run Training<ra-run-training>`"
msgstr ":ref:`运行训练<ra-run-training>`"

#: ../../source/refs/reference_architecture/index.rst:42
msgid ":ref:`Run Testing<ra-run-testing>`"
msgstr ":ref:`运行测试<ra-run-testing>`"

#: ../../source/refs/reference_architecture/index.rst:48
msgid "Components"
msgstr "组件"

#: ../../source/refs/reference_architecture/index.rst:49
msgid ""
"In this section, we will briefly discuss the individual blocks for creating "
"a sample reference application in Isaac Lab."
msgstr "在本节中，我们将简要讨论为在 Isaac Lab 中创建示例参考应用程序的各个模块。"

#: ../../source/refs/reference_architecture/index.rst:56
msgid "Component 1 - Asset Input"
msgstr "组件 1 - 资产输入"

#: ../../source/refs/reference_architecture/index.rst:57
msgid ""
"Isaac Lab accepts URDF, MJCF XML or USD files for the assets. The first step"
" to training using Isaac Lab is to have the USD file of your asset and the "
"USD or URDF file of your robot. This can be achieved in the following ways:"
msgstr ""
"Isaac Lab 支持 URDF、MJCF XML 或 USD 文件作为资产。使用 Isaac Lab 进行训练的第一步是拥有资产的 USD "
"文件以及机器人的 USD 或 URDF 文件。可以通过以下方式实现:"

#: ../../source/refs/reference_architecture/index.rst:62
msgid "Design your assets or robot in Isaac Sim and export the USD file."
msgstr "在 Isaac Sim 中设计资产或机器人并导出 USD 文件。"

#: ../../source/refs/reference_architecture/index.rst:64
msgid ""
"Design your assets or robot in any software of your choice and export it to "
"USD using Isaac Sim converters. Isaac Sim supports the different "
"converters/importers to USD such as the `CAD Converter`_, `URDF Importer`_, "
"`MJCF Importer`_, `Onshape Importer`_, etc. More details are found in the "
"`Importing Assets section`_ in the `Isaac Sim Reference Architecture`_."
msgstr ""
"在任何您选择的软件中设计资产或机器人，并使用 Isaac Sim 转换器导出为 USD。Isaac Sim 支持不同的转换器/导入器，例如 `CAD "
"Converter`_ 、 `URDF Importer`_ 、 `MJCF Importer`_ 、 `Onshape Importer`_ "
"等。更多细节请参见 `导入资产部分`_ 和 `Isaac Sim 参考架构`_ "
"中的相关内容。"

#: ../../source/refs/reference_architecture/index.rst:66
msgid ""
"If you already have the URDF or MJCF file of your robot, you do not need to "
"convert to USD as Isaac Lab takes URDF and MJCF XML."
msgstr ""
"如果您已经有了机器人 (URDF 或 MJCF) 文件，则不需要转换为 USD，因为 Isaac Lab 支持 URDF 和 MJCF XML 格式。"

#: ../../source/refs/reference_architecture/index.rst:72
msgid "Component 2 -  Configuration (Assets and Scene)"
msgstr "组件 2 - 配置 - 资产与场景"

#: ../../source/refs/reference_architecture/index.rst:75
msgid "Asset Configuration"
msgstr "资产配置"

#: ../../source/refs/reference_architecture/index.rst:77
msgid ""
"Given that you have the asset file for your robot and other assets such as "
"environment objects based on the task, the next step is to import them into "
"Isaac Lab. Isaac Lab uses asset configuration classes to spawn various "
"objects (or prims) into the scene using Python. The first step is to write a"
" configuration class to define the properties for the assets needed to "
"complete the task. For example, a simple go-to-goal task for a mobile robot "
"will include the robot asset, an object like cubes to signify the goal pose "
"visually, lights, ground plane, etc. Isaac Lab understands these assets "
"using the configuration classes. Isaac Lab provides various sim-ready assets"
" such as physically accurate 3D objects that encompass accurate physical "
"properties and behavior. It also provides connected data streams to "
"represent the real world in simulated digital worlds such as `robots "
"<https://github.com/isaac-"
"sim/IsaacLab/tree/main/source/isaaclab_assets/isaaclab_assets>`__ like "
"ANYbotics Anymal, Unitree H1 Humanoid, etc. as well as `sensors "
"<https://github.com/isaac-"
"sim/IsaacLab/tree/main/source/isaaclab/isaaclab/sensors>`__. We provide "
"these assets configuration classes. Users can also define their own assets "
"using the configuration classes."
msgstr ""
"假设您已拥有机器人的资产文件和基于任务所需的其他环境对象资产，接下来的步骤是将它们导入到 Isaac Lab 中。Isaac Lab 使用资产配置类通过"
" Python "
"将各种对象（或原型）生成到场景中。第一步是编写配置类，以定义完成任务所需资产的属性。例如，一个简单的移动机器人前往目标任务会包括机器人资产、一个如立方体的物体来视觉化目标位置、灯光、地面等。Isaac"
" Lab 使用配置类来理解这些资产。Isaac Lab 提供了各种适用于模拟的资产，例如包含准确物理属性和行为的真实物理 3D "
"对象。它还提供了与现实世界相连接的数据流，以在模拟的数字世界中代表真实世界，如 `机器人 <https://github.com/isaac-"
"sim/IsaacLab/tree/main/source/isaaclab_assets/isaaclab_assets>`__ ，包括 "
"ANYbotics Anymal、Unitree H1 Humanoid 等，以及 `传感器 "
"<https://github.com/isaac-"
"sim/IsaacLab/tree/main/source/isaaclab/isaaclab/sensors>`__ "
"。我们提供了这些资产配置类。用户还可以使用配置类定义自己的资产。"

#: ../../source/refs/reference_architecture/index.rst:81
msgid ""
"Follow the tutorial on `how to write an Articulation and ArticulationCfg "
"class <https://isaac-sim.github.io/IsaacLab/main/source/how-"
"to/write_articulation_cfg.html>`__."
msgstr ""
"请参阅关于 `如何编写 Articulation 和 ArticulationCfg 类 <https://isaac-"
"sim.github.io/IsaacLab/main/source/how-to/write_articulation_cfg.html>`__ "
"的教程。"

#: ../../source/refs/reference_architecture/index.rst:84
msgid "Scene Configuration"
msgstr "场景配置"

#: ../../source/refs/reference_architecture/index.rst:86
msgid ""
"Given the individual asset configurations, the next step is to put all the "
"assets together into a scene. The scene configuration is a simple config "
"class that initializes all the assets in the scene that are needed for the "
"task and for visualization. This is an example for the `Cartpole example "
"scene configuration <https://isaac-"
"sim.github.io/IsaacLab/main/source/tutorials/02_scene/create_scene.html#scene-"
"configuration>`__, which includes the cartpole, ground plane, and dome "
"light."
msgstr ""
"在定义了单个资产配置后，接下来是将所有资产组合成一个场景。场景配置是一个简单的配置类，用于初始化场景中完成任务和可视化所需的所有资产。这是 "
"`Cartpole 示例场景配置 <https://isaac-"
"sim.github.io/IsaacLab/main/source/tutorials/02_scene/create_scene.html#scene-"
"configuration>`__ 的一个示例，其中包括了倒立摆、地面和圆顶灯光。"

#: ../../source/refs/reference_architecture/index.rst:96
msgid "Component 3 - Robot Learning Task Design"
msgstr "组件 3 - 机器人学习任务设计"

#: ../../source/refs/reference_architecture/index.rst:97
msgid ""
"Now, we have the scene for the task, but we need to define the robot "
"learning task. We will focus on `reinforcement learning (RL) "
"<https://www.andrew.cmu.edu/course/10-703/textbook/BartoSutton.pdf>`__ "
"algorithm here. We define the RL task that the agent is going to do. RL "
"tasks are defined as a Markov Decision Process (MDP), which is a stochastic "
"decision-making process where optional decisions are made for the agents "
"considering their current state and environment they interact with. The "
"environment provides the agents’ current state or observations, and executes"
" the actions provided by the agent. The environment responds to the agents "
"by providing the next states, reward of taking the action, done flag and "
"information about the current episode. Therefore, different components of "
"the MDP formulation (the environment) – states, actions, rewards, reset, "
"done, etc. — must be defined by the user for the agent to perform the given "
"task."
msgstr ""
"现在，我们有了任务的场景，但还需要定义机器人学习任务。我们将专注于 `强化学习 (RL) "
"<https://www.andrew.cmu.edu/course/10-703/textbook/BartoSutton.pdf>`__ "
"算法。在这里，我们定义智能体将执行的 RL 任务。RL "
"任务被定义为一个马尔科夫决策过程（MDP），它是一种随机决策过程，其中智能体根据当前的状态和与环境的交互做出可选决策。环境为智能体提供当前的状态或观测，并执行智能体提供的动作。环境通过提供下一个状态、奖励、任务完成标志等信息来回应智能体。因此，MDP"
" 的不同组成部分（环境）——状态、动作、奖励、重置、结束等——必须由用户为智能体定义，以便执行给定的任务。"

#: ../../source/refs/reference_architecture/index.rst:108
msgid ""
"In Isaac Lab, we provide two different workflows for designing environments."
msgstr "在 Isaac Lab 中，我们提供了两种不同的环境设计工作流。"

#: ../../source/refs/reference_architecture/index.rst:111
msgid "Manager-based"
msgstr "基于管理器"

#: ../../source/refs/reference_architecture/index.rst:-1
msgid "Manager-based Task Workflow"
msgstr "基于管理器的任务工作流"

#: ../../source/refs/reference_architecture/index.rst:122
msgid ""
"This workflow is modular, and the environment is decomposed into individual "
"components (or managers) that handle the different aspects of the "
"environment, such as computing observations, applying actions, and applying "
"randomization. As a user, you define different configuration classes for "
"each component."
msgstr ""
"此工作流是模块化的，环境被分解为处理不同方面（如计算观测、应用动作和随机化）的单独组件（或管理器）。作为用户，您为每个组件定义不同的配置类。"

#: ../../source/refs/reference_architecture/index.rst:127
msgid "An RL task should have the following configuration classes:"
msgstr "一个 RL 任务应具有以下配置类:"

#: ../../source/refs/reference_architecture/index.rst:129
msgid "Observations Config: Defines the agents’ observations for the task."
msgstr "观测配置: 定义智能体在任务中的观测。"

#: ../../source/refs/reference_architecture/index.rst:130
msgid ""
"Actions Config: Defines the agent’s action type, i.e. how the output of the "
"agent are mapped to the robot's control inputs."
msgstr "动作配置: 定义智能体的动作类型，即如何将智能体的输出映射到机器人的控制输入。"

#: ../../source/refs/reference_architecture/index.rst:132
msgid "Rewards Config: Defines the reward function for the task"
msgstr "奖励配置: 定义任务的奖励函数。"

#: ../../source/refs/reference_architecture/index.rst:133
msgid ""
"Terminations Config: Defines the conditions for termination of an episode or"
" when the task is completed."
msgstr "终止配置: 定义任务完成或任务回合结束的条件。"

#: ../../source/refs/reference_architecture/index.rst:136
msgid ""
"You can add other optional configuration classes such as Event Config which "
"defines the set of randomizations and noisification for the agent and "
"environment, Curriculum Config for tasks that require `curriculum learning`_"
" and Commands Config for tasks where the input is from a controller/setpoint"
" controls e.g. a gamepad controller."
msgstr ""
"您还可以添加其他可选的配置类，例如事件配置，用于定义智能体和环境的随机化和噪声设置；课程配置，用于需要 `课程学习`_ "
"的任务；以及命令配置，用于需要从控制器或设定点控制（例如游戏手柄控制器）的任务。"

#: ../../source/refs/reference_architecture/index.rst:140
msgid ""
"To learn more on how you can design your own manager-based environment, see "
":ref:`tutorial-create-manager-rl-env`."
msgstr "有关如何设计您自己的基于管理器的环境，请参阅 :ref:`tutorial-create-manager-rl-env` 。"

#: ../../source/refs/reference_architecture/index.rst:145
msgid "Direct"
msgstr "直接式"

#: ../../source/refs/reference_architecture/index.rst:-1
msgid "Direct-based Task Workflow"
msgstr "直接式任务工作流"

#: ../../source/refs/reference_architecture/index.rst:156
msgid ""
"In this workflow, you implement a single class that is responsible for "
"computing observations, applying actions, and computing rewards. This "
"workflow allows for direct control of the environment logic."
msgstr "在此工作流中，您实现一个单一的类，负责计算观测、应用动作和计算奖励。此工作流允许直接控制环境逻辑。"

#: ../../source/refs/reference_architecture/index.rst:159
msgid ""
"To learn more on how you can design your own direct environment, see "
":ref:`tutorial-create-direct-rl-env`."
msgstr "有关如何设计您自己的直接环境，请参阅 :ref:`tutorial-create-direct-rl-env` 。"

#: ../../source/refs/reference_architecture/index.rst:161
msgid ""
"Users can choose from Isaac Lab’s large suite of pre-configured environments"
" or users can define their own environments. For more technical information "
"about the two workflows, please see the `documentation <https://isaac-"
"sim.github.io/IsaacLab/main/source/overview/core-"
"concepts/task_workflows.html>`__."
msgstr ""
"用户可以选择使用 Isaac Lab 提供的多种预配置环境，或者用户可以定义自己的环境。有关这两种工作流的更多技术信息，请参阅 `文档 "
"<https://isaac-sim.github.io/IsaacLab/main/source/overview/core-"
"concepts/task_workflows.html>`__ 。"

#: ../../source/refs/reference_architecture/index.rst:166
msgid ""
"In addition to designing the RL task, you will need to design your agent’s "
"model, the neural network policy and value function. To train the RL agent "
"to solve the task, you need to define the hyperparameters such as number of "
"epochs, learning rate, etc. for training and the policy/value model "
"architecture. This is defined in the training configuration file specific to"
" the RL library you want to use. Examples are created under the agent's "
"folder in each task directory. See an example of `RSL-RL "
"<https://github.com/isaac-"
"sim/IsaacLab/blob/main/source/isaaclab_tasks/isaaclab_tasks/manager_based/locomotion/velocity/config/anymal_b/agents/rsl_rl_ppo_cfg.py>`__"
" for Anymal-B."
msgstr ""
"除了设计 RL 任务外，您还需要设计智能体的模型、神经网络策略和价值函数。为了训练 RL "
"智能体解决任务，您需要定义训练的超参数，如训练的轮数、学习率等，以及策略/价值模型的架构。这些内容在特定于您要使用的 RL "
"库的训练配置文件中定义。示例已在每个任务目录下的智能体文件夹中创建。请参见 `RSL-RL <https://github.com/isaac-"
"sim/IsaacLab/blob/main/source/isaaclab_tasks/isaaclab_tasks/manager_based/locomotion/velocity/config/anymal_b/agents/rsl_rl_ppo_cfg.py>`__"
" 中的 Anymal-B 示例。"

#: ../../source/refs/reference_architecture/index.rst:177
msgid "Component 4 - Register with Gymnasium"
msgstr "组件 4 - 在 Gymnasium 中注册"

#: ../../source/refs/reference_architecture/index.rst:179
msgid ""
"The next step is to register the environments with the gymnasium registry to"
" allow you to create the environment using the unique environment name. "
"Registration is a way to make the environment accessible and reusable across"
" different RL algorithms and experiments. This is common in the RL "
"community. Follow the tutorial on `Registering an Environment "
"<https://isaac-"
"sim.github.io/IsaacLab/main/source/tutorials/03_envs/register_rl_env_gym.html>`__"
" to learn more about how to register in your own environment."
msgstr ""
"下一步是将环境注册到 Gymnasium 注册表中，以便使用唯一的环境名称创建环境。注册是一种使环境在不同的 RL "
"算法和实验中可访问和可重用的方式。这在 RL 社区中很常见。请参阅关于 `注册环境 <https://isaac-"
"sim.github.io/IsaacLab/main/source/tutorials/03_envs/register_rl_env_gym.html>`__"
" 的教程，了解如何在自己的环境中注册。"

#: ../../source/refs/reference_architecture/index.rst:187
msgid "Component 5 - Environment Wrapping"
msgstr "组件 5 - 环境封装"

#: ../../source/refs/reference_architecture/index.rst:188
msgid ""
"In running your RL task, you might want to change the behavior of your "
"environment without changing the environment itself. For example, you might "
"want to create functions to modify observations or rewards, record videos, "
"or enforce time limits. Isaac Lab utilizes the API available in the "
"`gymnasium.Wrapper <https://gymnasium.farama.org/api/wrappers/table/>`__ "
"class to create interfaces to the simulated environments."
msgstr ""
"在运行 RL 任务时，您可能希望在不改变环境本身的情况下修改环境的行为。例如，您可能希望创建函数来修改观测或奖励、录制视频或强制执行时间限制。Isaac"
" Lab 利用 `gymnasium.Wrapper "
"<https://gymnasium.farama.org/api/wrappers/table/>`__ 类提供的 API 创建模拟环境的接口。"

#: ../../source/refs/reference_architecture/index.rst:193
msgid "Some wrappers include:"
msgstr "一些封装器包括:"

#: ../../source/refs/reference_architecture/index.rst:195
msgid ""
"`Video Wrappers <https://isaac-sim.github.io/IsaacLab/main/source/how-"
"to/wrap_rl_env.html#wrapper-for-recording-videos>`__"
msgstr ""
"`视频封装器 <https://isaac-sim.github.io/IsaacLab/main/source/how-"
"to/wrap_rl_env.html#wrapper-for-recording-videos>`__"

#: ../../source/refs/reference_architecture/index.rst:196
msgid ""
"`RL Libraries Wrappers <https://isaac-"
"sim.github.io/IsaacLab/main/source/how-to/wrap_rl_env.html#wrapper-for-"
"learning-frameworks>`__"
msgstr ""
"`RL库封装器 <https://isaac-sim.github.io/IsaacLab/main/source/how-"
"to/wrap_rl_env.html#wrapper-for-learning-frameworks>`__"

#: ../../source/refs/reference_architecture/index.rst:198
msgid ""
"Most RL libraries expect their own variation of an environment interface. "
"This means the data types needed by each library differs. Isaac Lab provides"
" its own wrappers to convert the environment into the expected interface by "
"the RL library a user wants to use. These are specified in the `Isaac Lab "
"utils wrapper module <https://isaac-"
"sim.github.io/IsaacLab/main/source/api/lab_tasks/isaaclab_rl.html#module-"
"isaaclab_rl>`__."
msgstr ""
"大多数RL库期望它们自己的环境接口变体。这意味着每个库所需的数据类型是不同的。Isaac "
"Lab提供了自己的封装器，将环境转换为用户希望使用的RL库所期望的接口。这些封装器在 `Isaac Lab utils 包装器模块 "
"<https://isaac-"
"sim.github.io/IsaacLab/main/source/api/lab_tasks/isaaclab_rl.html#module-"
"isaaclab_rl>`__ 中进行说明。"

#: ../../source/refs/reference_architecture/index.rst:203
msgid ""
"See the `full list "
"<https://gymnasium.farama.org/api/wrappers/#gymnasium.Wrapper>`__ of other "
"wrappers APIs. For more information on how these wrappers work, please refer"
" to the `Wrapping environments <https://isaac-"
"sim.github.io/IsaacLab/main/source/how-to/wrap_rl_env.html#how-to-env-"
"wrappers>`__ documentation."
msgstr ""
"查看 `完整列表 <https://gymnasium.farama.org/api/wrappers/#gymnasium.Wrapper>`__ "
"的其他封装器API。有关这些封装器如何工作的更多信息，请参阅 `包装环境 <https://isaac-"
"sim.github.io/IsaacLab/main/source/how-to/wrap_rl_env.html#how-to-env-"
"wrappers>`__ 文档。"

#: ../../source/refs/reference_architecture/index.rst:207
msgid "Adding your own wrappers"
msgstr "添加自己的封装器"

#: ../../source/refs/reference_architecture/index.rst:209
msgid ""
"You can define your own wrappers by adding them to the Isaac Lab utils "
"wrapper module. More information is available `on the GitHub page for "
"wrapping environments <https://isaac-sim.github.io/IsaacLab/main/source/how-"
"to/wrap_rl_env.html#adding-new-wrappers>`__."
msgstr ""
"您可以通过将它们添加到Isaac Lab utils 包装器模块来定义自己的封装器。更多信息请参阅 `GitHub页面上的包装环境说明"
" <https://isaac-sim.github.io/IsaacLab/main/source/how-"
"to/wrap_rl_env.html#adding-new-wrappers>`__ 。"

#: ../../source/refs/reference_architecture/index.rst:214
msgid "Component 6 - Run Training"
msgstr "组件 6 - 运行训练"

#: ../../source/refs/reference_architecture/index.rst:216
msgid ""
"Finally, the last step is to run the training of the RL agent. Isaac Lab "
"provides scripts which utilizes four popular RL libraries for training the "
"models (GPU-based training):"
msgstr "最后一步是运行RL代理的训练。Isaac Lab提供了脚本，利用四个流行的RL库来训练模型（基于GPU的训练）:"

#: ../../source/refs/reference_architecture/index.rst:218
msgid ""
"`StableBaselines3 <https://stable-baselines3.readthedocs.io/en/master/>`__"
msgstr ""
"`StableBaselines3 <https://stable-baselines3.readthedocs.io/en/master/>`__"

#: ../../source/refs/reference_architecture/index.rst:219
msgid "`RSL-RL <https://github.com/leggedrobotics/rsl_rl>`__"
msgstr "`RSL-RL <https://github.com/leggedrobotics/rsl_rl>`__"

#: ../../source/refs/reference_architecture/index.rst:220
msgid "`RL-Games <https://github.com/Denys88/rl_games>`__"
msgstr "`RL-Games <https://github.com/Denys88/rl_games>`__"

#: ../../source/refs/reference_architecture/index.rst:221
msgid "`SKRL <https://skrl.readthedocs.io/en/latest/>`__"
msgstr "`SKRL <https://skrl.readthedocs.io/en/latest/>`__"

#: ../../source/refs/reference_architecture/index.rst:226
msgid ""
"Isaac Lab does not provide the implementation of these RL libraries. They "
"are already implemented by different authors. We provide the environments "
"and framework wrappers for the RL libraries."
msgstr "Isaac Lab不提供这些RL库的实现。它们已经由不同的作者实现。我们提供了用于RL库的环境和框架封装器。"

#: ../../source/refs/reference_architecture/index.rst:230
msgid ""
"If you want to integrate a different version of the provided algorithms or "
"your learning library, you can follow `these instructions <https://isaac-"
"sim.github.io/IsaacLab/main/source/how-to/add_own_library.html>`__."
msgstr ""
"如果您希望集成不同版本的提供算法或您的学习库，可以按照 `这些说明 <https://isaac-"
"sim.github.io/IsaacLab/main/source/how-to/add_own_library.html>`__ 进行操作。"

#: ../../source/refs/reference_architecture/index.rst:236
msgid "Single GPU Training"
msgstr "单GPU训练"

#: ../../source/refs/reference_architecture/index.rst:-1
msgid "Single GPU Training Data Flow"
msgstr "单GPU训练数据流"

#: ../../source/refs/reference_architecture/index.rst:247
msgid ""
"Isaac Lab supports training massively parallel environments to speed up RL "
"training and provides rich data for the model to train. For single GPU "
"training, the following steps show how training works in Isaac Sim and Isaac"
" Lab:"
msgstr ""
"Isaac Lab支持训练大规模并行环境，以加速RL训练，并为模型提供丰富的数据进行训练。对于单GPU训练，以下步骤展示了Isaac Sim和Isaac"
" Lab中训练的工作流程:"

#: ../../source/refs/reference_architecture/index.rst:250
#: ../../source/refs/reference_architecture/index.rst:267
msgid "**In Isaac Sim**"
msgstr "**在Isaac Sim中**"

#: ../../source/refs/reference_architecture/index.rst:252
msgid ""
"Isaac Sim provides the asset states such as robot and sensor states, "
"including the observations defined in the task observation config class."
msgstr "Isaac Sim提供了资产状态，如机器人和传感器状态，包括在任务观察配置类中定义的观察。"

#: ../../source/refs/reference_architecture/index.rst:254
msgid "**In Isaac Lab**"
msgstr "**在Isaac Lab中**"

#: ../../source/refs/reference_architecture/index.rst:256
msgid ""
"Randomizations are added to the states defined in the event configuration "
"class to obtain the observation for the task. Randomizations are however "
"optional. If not defined, the states are the observations."
msgstr "在事件配置类中定义的状态添加了随机化，以获取任务的观察。随机化是可选的。如果未定义，则状态就是观察。"

#: ../../source/refs/reference_architecture/index.rst:257
msgid ""
"The observations are computed as PyTorch tensors, and it can optionally "
"include the action provided by the trained model based on the task."
msgstr "观察被计算为PyTorch张量，并且可以选择性地包括训练模型根据任务提供的动作。"

#: ../../source/refs/reference_architecture/index.rst:259
msgid "**In the RL library**"
msgstr "**在RL库中**"

#: ../../source/refs/reference_architecture/index.rst:261
msgid "The observation is passed to the policy."
msgstr "观察被传递给策略。"

#: ../../source/refs/reference_architecture/index.rst:262
msgid ""
"The policy is trained to output the right actions for the robot using RL "
"library algorithms such as PPO, TRPO, etc."
msgstr "策略通过使用RL库算法（如PPO、TRPO等）进行训练，以输出适合机器人执行的正确动作。"

#: ../../source/refs/reference_architecture/index.rst:263
msgid ""
"The actions can serve either as a setpoint for a controller that generates "
"the action to the robot or used directly as the action to the robot based on"
" the task."
msgstr "动作可以作为控制器的设定点，生成对机器人的动作，或者直接用作基于任务的机器人动作。"

#: ../../source/refs/reference_architecture/index.rst:264
msgid ""
"Action types such as joint position for a quadruped is an input to a joint "
"controller, velocity of 1 or 0 is used to control the cart directly in the "
"cartpole task, etc."
msgstr "例如，四足机器人关节位置的动作作为关节控制器的输入，1或0的速度用于直接控制推车任务中的推车等。"

#: ../../source/refs/reference_architecture/index.rst:265
msgid ""
"In addition, based on how the task is defined, the previous action can be "
"part of the next set of observations that is sent."
msgstr "此外，根据任务的定义，先前的动作可以作为下一个观察集的一部分发送。"

#: ../../source/refs/reference_architecture/index.rst:269
msgid ""
"The actions from the policy are sent back to Isaac Sim to control the agent "
"that is learning i.e. the robot. This is the physics simulation (sim) step. "
"This generates the next states in Isaac Sim and the rewards are calculated "
"in Isaac Lab."
msgstr ""
"来自策略的动作被传回Isaac Sim，以控制正在学习的代理（即机器人）。这是物理仿真（sim）步骤。这会在Isaac "
"Sim中生成下一个状态，并且奖励在Isaac Lab中计算。"

#: ../../source/refs/reference_architecture/index.rst:271
msgid "**Rendering**"
msgstr "**渲染**"

#: ../../source/refs/reference_architecture/index.rst:273
msgid "The scene can be rendered to produce the cameras' images."
msgstr "场景可以被渲染以生成相机的图像。"

#: ../../source/refs/reference_architecture/index.rst:276
msgid ""
"The next state is then passed in the flow till the training reaches the "
"specified training steps or epochs. The final product is the trained "
"model/agent."
msgstr "然后在流程中传递下一个状态，直到训练达到指定的训练步骤或时期。最终产品是经过训练的模型/代理。"

#: ../../source/refs/reference_architecture/index.rst:281
msgid "Multi-GPU and Multi-Node Training"
msgstr "多GPU和多节点训练"

#: ../../source/refs/reference_architecture/index.rst:-1
msgid "Multi GPU Training Data Flow"
msgstr "多 GPU 训练数据流"

#: ../../source/refs/reference_architecture/index.rst:293
msgid ""
"Isaac Lab supports scaling up training by taking advantage of multi-GPU and "
"multi-node training on Linux. Follow the tutorial on `Multi-GPU training "
"<https://isaac-"
"sim.github.io/IsaacLab/main/source/features/multi_gpu.html#multi-gpu-"
"training>`__ and `Multi-Node training <https://isaac-"
"sim.github.io/IsaacLab/main/source/features/multi_gpu.html#multi-node-"
"training>`__ to get started."
msgstr ""
"Isaac Lab支持通过利用Linux上的多GPU和多节点训练来扩展训练。请参阅 `多GPU训练 <https://isaac-"
"sim.github.io/IsaacLab/main/source/features/multi_gpu.html#multi-gpu-"
"training>`__ 和 `多节点训练 <https://isaac-"
"sim.github.io/IsaacLab/main/source/features/multi_gpu.html#multi-node-"
"training>`__ 教程以开始使用。"

#: ../../source/refs/reference_architecture/index.rst:297
msgid "Cloud-Based Training"
msgstr "基于云的训练"

#: ../../source/refs/reference_architecture/index.rst:298
msgid ""
"Isaac Lab can be deployed alongside Isaac Sim onto the public clouds with "
"`Isaac Automator <https://github.com/isaac-sim/IsaacAutomator>`__. AWS, GCP,"
" Azure, and Alibaba Cloud are currently supported. Follow the tutorial on "
"`how to run Isaac Lab in the cloud <https://isaac-"
"sim.github.io/IsaacLab/main/source/setup/installation/cloud_installation.html>`__."
msgstr ""
"Isaac Lab可以与Isaac Sim一起部署到公共云上，使用 `Isaac Automator "
"<https://github.com/isaac-sim/IsaacAutomator>`__ 。目前支持AWS、GCP、Azure和阿里云。请参阅 "
"`如何在云上运行Isaac Lab <https://isaac-"
"sim.github.io/IsaacLab/main/source/setup/installation/cloud_installation.html>`__"
" 教程。"

#: ../../source/refs/reference_architecture/index.rst:302
msgid ""
"Both multi-GPU and multi-node jobs can be easily scaled across heterogeneous"
" environments with `OSMO <https://developer.nvidia.com/osmo>`__, a cloud-"
"native, orchestration platform for scheduling complex multi-stage and multi-"
"container heterogeneous computing workflows. Isaac Lab also provides the "
"tools to run your RL task in Docker. See more details on `container "
"deployment <https://isaac-"
"sim.github.io/IsaacLab/main/source/deployment/index.html>`__."
msgstr ""
"多GPU和多节点作业可以通过 `OSMO <https://developer.nvidia.com/osmo>`__ "
"，一个用于调度复杂的多阶段和多容器异构计算工作流的云原生编排平台，轻松地在异构环境中扩展。Isaac "
"Lab还提供了运行RL任务的工具，支持Docker容器。有关容器部署的更多详细信息，请参阅 `容器部署 <https://isaac-"
"sim.github.io/IsaacLab/main/source/deployment/index.html>`__ 。"

#: ../../source/refs/reference_architecture/index.rst:307
msgid "Component 7: Run Testing"
msgstr "组件 7: 运行测试"

#: ../../source/refs/reference_architecture/index.rst:308
msgid ""
"Isaac Lab provides scripts for `testing/playing the trained policy "
"<https://isaac-"
"sim.github.io/IsaacLab/main/source/tutorials/03_envs/run_rl_training.html#playing-"
"the-trained-agent>`__ on the environment and functions for converting the "
"trained model from .pt to .jit and .onnx for deployment."
msgstr ""
"Isaac Lab提供了脚本用于 `测试/执行训练后的策略 <https://isaac-"
"sim.github.io/IsaacLab/main/source/tutorials/03_envs/run_rl_training.html#playing-"
"the-trained-agent>`__ ，并提供了将训练好的模型从 .pt 格式转换为 .jit 和 .onnx 格式以进行部署的功能。"

#: ../../source/refs/reference_architecture/index.rst:313
msgid "Deployment on Physical Robots"
msgstr "物理机器人上的部署"

#: ../../source/refs/reference_architecture/index.rst:-1
msgid "Isaac Lab Trained Policy Deployment"
msgstr "Isaac Lab 训练的策略部署"

#: ../../source/refs/reference_architecture/index.rst:326
msgid ""
"To deploy your trained model on a real robot, you would need what is shown "
"in the flow diagram. Note, this is a sample reference architecture, hence it"
" can be tweaked for a different application. First, you need a robot with "
"the required sensors and processing computer such as `NVIDIA Jetson "
"<https://www.nvidia.com/en-us/autonomous-machines/embedded-systems/>`__ to "
"deploy on. Next, you need a state estimator for your robot. The state "
"estimator should be able to deliver the list of observations used for "
"training."
msgstr ""
"要将训练好的模型部署到真实机器人上，您需要如流程图所示的内容。请注意，这是一个示范参考架构，因此可以根据不同的应用进行调整。首先，您需要一台带有必要传感器和处理计算机（如"
" `NVIDIA Jetson <https://www.nvidia.com/en-us/autonomous-machines/embedded-"
"systems/>`__ ）的机器人来部署。接下来，您需要为机器人配置状态估计器。状态估计器应该能够提供用于训练的观察列表。"

#: ../../source/refs/reference_architecture/index.rst:329
msgid ""
"Once the observations are extracted, they are passed into the model which "
"delivers the action using the model inferencing runtime. The commanded "
"action from the model serves as setpoints for the action controller. The "
"action controller outputs scaled actions which are then used to control the "
"robot to get to the next state, and this continues till the task is done."
msgstr ""
"一旦提取出观测，它们会传递到模型中，模型通过推理运行时生成动作。模型中的命令动作作为设定点传递给动作控制器。动作控制器输出缩放后的动作，然后用于控制机器人到达下一个状态，直到任务完成。"

#: ../../source/refs/reference_architecture/index.rst:331
#, python-format
msgid ""
"NVIDIA Isaac platform provides some tools for state estimation, including "
"visual slam and inferencing engines such as `TensorRT "
"<https://developer.nvidia.com/tensorrt-getting-"
"started#:~:text=NVIDIA%C2%AE%20TensorRT%E2%84%A2%20is,high%20throughput%20for%20production%20applications.>`__."
" Other inferencing runtime includes `OnnxRuntime "
"<https://onnxruntime.ai/>`__, direct inferencing on the PyTorch model, etc."
msgstr ""
"NVIDIA Isaac平台提供了一些用于状态估计的工具，包括视觉SLAM和推理引擎，如 `TensorRT "
"<https://developer.nvidia.com/tensorrt-getting-"
"started#:~:text=NVIDIA%C2%AE%20TensorRT%E2%84%A2%20is,high%20throughput%20for%20production%20applications.>`__"
" 。其他推理运行时包括 `OnnxRuntime <https://onnxruntime.ai/>`__ ，直接在PyTorch模型上进行推理等。"

#: ../../source/refs/reference_architecture/index.rst:337
msgid "Summary"
msgstr "总结"

#: ../../source/refs/reference_architecture/index.rst:339
msgid ""
"This document presents a reference architecture for Isaac Lab that has "
"undergone SQA testing. We have provided a user-friendly guide to end-to-end "
"robot learning with Isaac Lab and Isaac Sim from training to real-world "
"deployment, including demos, examples, and documentation links."
msgstr ""
"本文档展示了经过SQA测试的Isaac Lab参考架构。我们提供了一个面向用户的端到端机器人学习指南，涵盖了从训练到实际部署的Isaac "
"Lab和Isaac Sim，包括演示、示例和文档链接。"

#: ../../source/refs/reference_architecture/index.rst:343
msgid "How to Get Started"
msgstr "如何开始"

#: ../../source/refs/reference_architecture/index.rst:344
msgid "Check out our resources on using Isaac Lab with your robots."
msgstr "查看我们的资源，了解如何将Isaac Lab与您的机器人结合使用。"

#: ../../source/refs/reference_architecture/index.rst:346
msgid "Review Our Documentation & Samples Resources"
msgstr "查看我们的文档与示例资源"

#: ../../source/refs/reference_architecture/index.rst:348
msgid "`Isaac Lab Tutorials`_"
msgstr "`Isaac Lab 教程`_"

#: ../../source/refs/reference_architecture/index.rst:349
msgid "`Fast-Track Robot Learning in Simulation Using NVIDIA Isaac Lab`_"
msgstr "`使用NVIDIA Isaac Lab在仿真中快速跟踪机器人学习`_"

#: ../../source/refs/reference_architecture/index.rst:350
msgid ""
"`Supercharge Robotics Workflows with AI and Simulation Using NVIDIA Isaac "
"Sim 4.0 and NVIDIA Isaac Lab`_"
msgstr "`使用NVIDIA Isaac Sim 4.0和NVIDIA Isaac Lab进行人工智能和模拟的超级充电机器人工作流程`_"

#: ../../source/refs/reference_architecture/index.rst:351
msgid ""
"`Closing the Sim-to-Real Gap: Training Spot Quadruped Locomotion with NVIDIA"
" Isaac Lab <https://developer.nvidia.com/blog/closing-the-sim-to-real-gap-"
"training-spot-quadruped-locomotion-with-nvidia-isaac-lab/>`__"
msgstr ""
"`缩小Sim-to-Real差距: 使用NVIDIA Isaac Lab训练Spot四足运动 "
"<https://developer.nvidia.com/blog/closing-the-sim-to-real-gap-training-"
"spot-quadruped-locomotion-with-nvidia-isaac-lab/>`__"

#: ../../source/refs/reference_architecture/index.rst:352
msgid "`Additional Resources`_"
msgstr "`其他资源`_"

#: ../../source/refs/reference_architecture/index.rst:354
msgid "Learn More About Featured NVIDIA Solutions"
msgstr "了解有关NVIDIA特色解决方案的更多信息"

#: ../../source/refs/reference_architecture/index.rst:356
msgid "`Scale AI-Enabled Robotics Development Workloads with NVIDIA OSMO`_"
msgstr "`使用NVIDIA OSMO扩展人工智能机器人开发工作量`_"

#: ../../source/refs/reference_architecture/index.rst:357
msgid ""
"`Parkour and More: How Simulation-Based RL Helps to Push the Boundaries in "
"Legged Locomotion (GTC session) <https://www.nvidia.com/en-us/on-"
"demand/session/gtc24-s63140/>`__"
msgstr ""
"`跑酷与更多: 基于仿真的强化学习如何推动四足行走的边界（GTC 会议） <https://www.nvidia.com/en-us/on-"
"demand/session/gtc24-s63140/>`__"

#: ../../source/refs/reference_architecture/index.rst:358
msgid "`Isaac Perceptor`_"
msgstr "`Isaac 感知器`_"

#: ../../source/refs/reference_architecture/index.rst:359
msgid "`Isaac Manipulator`_"
msgstr "`Isaac 操作器`_"
