# SOME DESCRIPTIVE TITLE.
# Copyright (C) 2022-2024, The Isaac Lab Project Developers.
# This file is distributed under the same license as the Isaac Lab package.
# FIRST AUTHOR <EMAIL@ADDRESS>, 2024.
msgid ""
msgstr ""
"Project-Id-Version: Isaac Lab 1.0.0\n"
"Report-Msgid-Bugs-To: \n"
"POT-Creation-Date: 2025-01-31 19:21+0800\n"
"PO-Revision-Date: YEAR-MO-DA HO:MI+ZONE\n"
"Last-Translator: Ziqi Fan <fanziqi614@gmail.com>\n"
"Language-Team: zh_CN <LL@li.org>\n"
"Language: zh_CN\n"
"MIME-Version: 1.0\n"
"Content-Type: text/plain; charset=utf-8\n"
"Content-Transfer-Encoding: 8bit\n"
"Plural-Forms: nplurals=1; plural=0;\n"
"Generated-By: Babel 2.16.0\n"

#: ../../source/tutorials/03_envs/create_manager_rl_env.rst:5
msgid "Creating a Manager-Based RL Environment"
msgstr "创建基于管理器的强化学习环境"

#: ../../source/tutorials/03_envs/create_manager_rl_env.rst:9
msgid ""
"Having learnt how to create a base environment in :ref:`tutorial-create-"
"manager-base-env`, we will now look at how to create a manager-based task "
"environment for reinforcement learning."
msgstr ""
"在 :ref:`tutorial-create-manager-base-env` "
"中学习了如何创建基础环境后，我们现在将学习如何为强化学习创建基于管理器的任务环境。"

#: ../../source/tutorials/03_envs/create_manager_rl_env.rst:12
msgid ""
"The base environment is designed as an sense-act environment where the agent"
" can send commands to the environment and receive observations from the "
"environment. This minimal interface is sufficient for many applications such"
" as traditional motion planning and controls. However, many applications "
"require a task-specification which often serves as the learning objective "
"for the agent. For instance, in a navigation task, the agent may be required"
" to reach a goal location. To this end, we use the "
":class:`envs.ManagerBasedRLEnv` class which extends the base environment to "
"include a task specification."
msgstr ""
"基础环境被设计为一种感知-"
"行为环境，智能体可以向环境发送命令，并从环境中接收观测。这种最小接口对于许多应用程序，如传统运动规划和控制，是足够的。然而，许多应用程序需要任务规范，这通常用作智能体的学习目标。例如，在导航任务中，智能体可能需要到达目标位置。为此，我们使用"
" :class:`envs.ManagerBasedRLEnv` 类扩展基础环境以包含任务规范。"

#: ../../source/tutorials/03_envs/create_manager_rl_env.rst:19
msgid ""
"Similar to other components in Isaac Lab, instead of directly modifying the "
"base class :class:`envs.ManagerBasedRLEnv`, we encourage users to simply "
"implement a configuration :class:`envs.ManagerBasedRLEnvCfg` for their task "
"environment. This practice allows us to separate the task specification from"
" the environment implementation, making it easier to reuse components of the"
" same environment for different tasks."
msgstr ""
"与 Isaac Lab 中的其他组件类似，我们鼓励用户不要直接修改 :class:`envs.ManagerBasedRLEnv` "
"基类，而是简单地为他们的任务环境实现一个配置 :class:`envs.ManagerBasedRLEnvCfg` "
"。这种做法使我们能够将任务规范与环境实现分开，使得更容易地重用相同环境的组件用于不同的任务。"

#: ../../source/tutorials/03_envs/create_manager_rl_env.rst:24
msgid ""
"In this tutorial, we will configure the cartpole environment using the "
":class:`envs.ManagerBasedRLEnvCfg` to create a manager-based task for "
"balancing the pole upright. We will learn how to specify the task using "
"reward terms, termination criteria, curriculum and commands."
msgstr ""
"在本教程中，我们将使用 :class:`envs.ManagerBasedRLEnvCfg` 配置 cartpole "
"环境，以创建一个平衡杆的基于管理器的任务。我们将学习如何使用奖励项、终止条件、课程和命令来指定任务。"

#: ../../source/tutorials/03_envs/create_manager_rl_env.rst:30
msgid "The Code"
msgstr "代码"

#: ../../source/tutorials/03_envs/create_manager_rl_env.rst:32
msgid ""
"For this tutorial, we use the cartpole environment defined in "
"``isaaclab_tasks.manager_based.classic.cartpole`` module."
msgstr ""
"在本教程中，我们使用 ``isaaclab_tasks.manager_based.classic.cartpole`` 模块中定义的 cartpole"
" 环境。"

#: ../../source/tutorials/03_envs/create_manager_rl_env.rst
msgid "Code for cartpole_env_cfg.py"
msgstr "cartpole_env_cfg.py 代码"

#: ../../source/tutorials/03_envs/create_manager_rl_env.rst:42
msgid ""
"The script for running the environment ``run_cartpole_rl_env.py`` is present"
" in the ``isaaclab/scripts/tutorials/03_envs`` directory. The script is "
"similar to the ``cartpole_base_env.py`` script in the previous tutorial, "
"except that it uses the :class:`envs.ManagerBasedRLEnv` instead of the "
":class:`envs.ManagerBasedEnv`."
msgstr ""
"用于运行环境的脚本 ``run_cartpole_rl_env.py`` 存在于 "
"``isaaclab/scripts/tutorials/03_envs`` 目录中。该脚本与前一个教程中的 "
"``cartpole_base_env.py`` 脚本类似，只是它使用 :class:`envs.ManagerBasedRLEnv` 而不是 "
":class:`envs.ManagerBasedEnv` 。"

#: ../../source/tutorials/03_envs/create_manager_rl_env.rst
msgid "Code for run_cartpole_rl_env.py"
msgstr "run_cartpole_rl_env.py 代码"

#: ../../source/tutorials/03_envs/create_manager_rl_env.rst:57
msgid "The Code Explained"
msgstr "代码解释"

#: ../../source/tutorials/03_envs/create_manager_rl_env.rst:59
msgid ""
"We already went through parts of the above in the :ref:`tutorial-create-"
"manager-base-env` tutorial to learn about how to specify the scene, "
"observations, actions and events. Thus, in this tutorial, we will focus only"
" on the RL components of the environment."
msgstr ""
"我们已经在 :ref:`tutorial-create-manager-base-env` "
"教程中学习了上述部分，以了解如何指定场景、观测、动作和事件。因此，在本教程中，我们将只专注于环境的强化学习组件。"

#: ../../source/tutorials/03_envs/create_manager_rl_env.rst:63
msgid ""
"In Isaac Lab, we provide various implementations of different terms in the "
":mod:`envs.mdp` module. We will use some of these terms in this tutorial, "
"but users are free to define their own terms as well. These are usually "
"placed in their task-specific sub-package (for instance, in "
":mod:`isaaclab_tasks.manager_based.classic.cartpole.mdp`)."
msgstr ""
"在 Isaac Lab 中，我们提供了 :mod:`envs.mdp` "
"模块中不同术语的各种实现。我们将在本教程中使用其中一些术语，但用户也可以自由定义自己的术语。这些通常被放置在他们任务特定的子包中（例如，在 "
":mod:`isaaclab_tasks.manager_based.classic.cartpole.mdp` 中）。"

#: ../../source/tutorials/03_envs/create_manager_rl_env.rst:70
msgid "Defining rewards"
msgstr "定义奖励"

#: ../../source/tutorials/03_envs/create_manager_rl_env.rst:72
msgid ""
"The :class:`managers.RewardManager` is used to compute the reward terms for "
"the agent. Similar to the other managers, its terms are configured using the"
" :class:`managers.RewardTermCfg` class. The :class:`managers.RewardTermCfg` "
"class specifies the function or callable class that computes the reward as "
"well as the weighting associated with it. It also takes in dictionary of "
"arguments, ``\"params\"`` that are passed to the reward function when it is "
"called."
msgstr ""
":class:`managers.RewardManager` 用于计算智能体的奖励项。与其他管理器类似，它的术语是使用 "
":class:`managers.RewardTermCfg` 配置的。 :class:`managers.RewardTermCfg` "
"类指定了计算奖励的函数或可调用类，以及与之相关联的权重。它还使用 ``\"params\"`` 的参数字典，在奖励函数被调用时传递参数。"

#: ../../source/tutorials/03_envs/create_manager_rl_env.rst:78
msgid "For the cartpole task, we will use the following reward terms:"
msgstr "对于 cartpole 任务，我们将使用以下奖励项: "

#: ../../source/tutorials/03_envs/create_manager_rl_env.rst:80
msgid ""
"**Alive Reward**: Encourage the agent to stay alive for as long as possible."
msgstr "**存活奖励**: 鼓励智能体尽可能长时间保持存活状态。"

#: ../../source/tutorials/03_envs/create_manager_rl_env.rst:81
msgid "**Terminating Reward**: Similarly penalize the agent for terminating."
msgstr "**终止奖励**: 同样惩罚智能体的终止。"

#: ../../source/tutorials/03_envs/create_manager_rl_env.rst:82
msgid ""
"**Pole Angle Reward**: Encourage the agent to keep the pole at the desired "
"upright position."
msgstr "**杆角度奖励**: 鼓励智能体保持杆在期望的直立位置。"

#: ../../source/tutorials/03_envs/create_manager_rl_env.rst:83
msgid ""
"**Cart Velocity Reward**: Encourage the agent to keep the cart velocity as "
"small as possible."
msgstr "**小车速度奖励**: 鼓励智能体尽可能保持小车速度较小。"

#: ../../source/tutorials/03_envs/create_manager_rl_env.rst:84
msgid ""
"**Pole Velocity Reward**: Encourage the agent to keep the pole velocity as "
"small as possible."
msgstr "**杆速度奖励**: 鼓励智能体尽可能保持杆速度较小。"

#: ../../source/tutorials/03_envs/create_manager_rl_env.rst:91
msgid "Defining termination criteria"
msgstr "定义终止条件"

#: ../../source/tutorials/03_envs/create_manager_rl_env.rst:93
msgid ""
"Most learning tasks happen over a finite number of steps that we call an "
"episode. For instance, in the cartpole task, we want the agent to balance "
"the pole for as long as possible. However, if the agent reaches an unstable "
"or unsafe state, we want to terminate the episode. On the other hand, if the"
" agent is able to balance the pole for a long time, we want to terminate the"
" episode and start a new one so that the agent can learn to balance the pole"
" from a different starting configuration."
msgstr ""
"大多数学习任务在有限数量的步骤中进行，我们称之为一个回合。例如，在 cartpole "
"任务中，我们希望智能体尽可能长时间地保持杆的平衡。然而，如果智能体达到不稳定或不安全状态，我们希望终止回合。另一方面，如果智能体能够长时间保持杆平衡，我们希望终止回合并开始新的回合，以便智能体可以学会从不同的起始配置中平衡杆。"

#: ../../source/tutorials/03_envs/create_manager_rl_env.rst:99
msgid ""
"The :class:`managers.TerminationsCfg` configures what constitutes for an "
"episode to terminate. In this example, we want the task to terminate when "
"either of the following conditions is met:"
msgstr ""
":class:`managers.TerminationsCfg` 配置了何时终止一个回合。在本例中，我们希望当满足以下任一条件时终止任务: "

#: ../../source/tutorials/03_envs/create_manager_rl_env.rst:102
msgid ""
"**Episode Length** The episode length is greater than the defined "
"max_episode_length"
msgstr "**回合长度**: 回合长度大于定义的最大回合长度。"

#: ../../source/tutorials/03_envs/create_manager_rl_env.rst:103
msgid "**Cart out of bounds** The cart goes outside of the bounds [-3, 3]"
msgstr "**小车越界**: 小车走出边界 [-3, 3]。"

#: ../../source/tutorials/03_envs/create_manager_rl_env.rst:105
msgid ""
"The flag :attr:`managers.TerminationsCfg.time_out` specifies whether the "
"term is a time-out (truncation) term or terminated term. These are used to "
"indicate the two types of terminations as described in `Gymnasium's "
"documentation "
"<https://gymnasium.farama.org/tutorials/gymnasium_basics/handling_time_limits/>`_."
msgstr ""
"标志 :attr:`managers.TerminationsCfg.time_out` 指定了术语是时间限制（截断）术语还是终止术语。这些用于指示 "
"`Gymnasium's documentation "
"<https://gymnasium.farama.org/tutorials/gymnasium_basics/handling_time_limits/>`_"
" 中描述的两种终止类型。"

#: ../../source/tutorials/03_envs/create_manager_rl_env.rst:114
msgid "Defining commands"
msgstr "定义命令"

#: ../../source/tutorials/03_envs/create_manager_rl_env.rst:116
msgid ""
"For various goal-conditioned tasks, it is useful to specify the goals or "
"commands for the agent. These are handled through the "
":class:`managers.CommandManager`. The command manager handles resampling and"
" updating the commands at each step. It can also be used to provide the "
"commands as an observation to the agent."
msgstr ""
"对于各种目标条件的任务，指定智能体的目标或命令是有用的。这通过 :class:`managers.CommandManager` "
"处理。命令管理器在每一步中处理重新采样和更新命令。它还可以用作向智能体提供命令的观测。"

#: ../../source/tutorials/03_envs/create_manager_rl_env.rst:120
msgid ""
"For this simple task, we do not use any commands. Hence, we leave this "
"attribute as its default value, which is None. You can see an example of how"
" to define a command manager in the other locomotion or manipulation tasks."
msgstr ""
"对于这个简单的任务，我们不使用任何命令。因此，我们将这个属性保留为默认值，即 None。您可以在其他运动或操控任务中看到如何定义命令管理器的示例。"

#: ../../source/tutorials/03_envs/create_manager_rl_env.rst:124
msgid "Defining curriculum"
msgstr "定义课程"

#: ../../source/tutorials/03_envs/create_manager_rl_env.rst:126
msgid ""
"Often times when training a learning agent, it helps to start with a simple "
"task and gradually increase the tasks's difficulty as the agent training "
"progresses. This is the idea behind curriculum learning. In Isaac Lab, we "
"provide a :class:`managers.CurriculumManager` class that can be used to "
"define a curriculum for your environment."
msgstr ""
"在训练学习智能体时，往往从一个简单的任务开始，并随着智能体的训练逐渐增加任务的难度。这就是课程学习的理念。在 Isaac Lab 中，我们提供了一个 "
":class:`managers.CurriculumManager` 类，可以用来为您的环境定义课程。"

#: ../../source/tutorials/03_envs/create_manager_rl_env.rst:130
msgid ""
"In this tutorial we don't implement a curriculum for simplicity, but you can"
" see an example of a curriculum definition in the other locomotion or "
"manipulation tasks."
msgstr ""
"在本教程中，为了简单起见，我们不实现课程，但是您可以在其他 locomotion 或 manipulation "
"任务中看到课程定义的示例。我们使用一个简单的经过课程来定义一个不修改环境的课程管理器。"

#: ../../source/tutorials/03_envs/create_manager_rl_env.rst:134
msgid "Tying it all together"
msgstr "将所有内容联系起来"

#: ../../source/tutorials/03_envs/create_manager_rl_env.rst:136
msgid ""
"With all the above components defined, we can now create the "
":class:`ManagerBasedRLEnvCfg` configuration for the cartpole environment. "
"This is similar to the :class:`ManagerBasedEnvCfg` defined in "
":ref:`tutorial-create-manager-base-env`, only with the added RL components "
"explained in the above sections."
msgstr ""
"通过定义上述所有组件，我们现在可以为 cartpole 环境创建 :class:`ManagerBasedRLEnvCfg` 配置。这类似于 "
":ref:`tutorial-create-manager-base-env` 中定义的 :class:`ManagerBasedEnvCfg` "
"，只是在上述部分中添加了解释的强化学习组件。"

#: ../../source/tutorials/03_envs/create_manager_rl_env.rst:145
msgid "Running the simulation loop"
msgstr "运行仿真循环"

#: ../../source/tutorials/03_envs/create_manager_rl_env.rst:147
msgid ""
"Coming back to the ``run_cartpole_rl_env.py`` script, the simulation loop is"
" similar to the previous tutorial. The only difference is that we create an "
"instance of :class:`envs.ManagerBasedRLEnv` instead of the "
":class:`envs.ManagerBasedEnv`. Consequently, now the "
":meth:`envs.ManagerBasedRLEnv.step` method returns additional signals such "
"as the reward and termination status. The information dictionary also "
"maintains logging of quantities such as the reward contribution from "
"individual terms, the termination status of each term, the episode length "
"etc."
msgstr ""
"回到 ``run_cartpole_rl_env.py`` 脚本，仿真循环类似于之前的教程。唯一的区别是，我们创建了一个 "
":class:`envs.ManagerBasedRLEnv` 的实例，而不是 :class:`envs.ManagerBasedEnv` 。因此，现在"
" :meth:`envs.ManagerBasedRLEnv.step` "
"方法返回额外的信号，例如奖励和终止状态。信息字典还保持记录诸如来自各个术语奖励的贡献，每个术语的终止状态，回合长度等的日志。"

#: ../../source/tutorials/03_envs/create_manager_rl_env.rst:159
msgid "The Code Execution"
msgstr "代码执行"

#: ../../source/tutorials/03_envs/create_manager_rl_env.rst:162
msgid ""
"Similar to the previous tutorial, we can run the environment by executing "
"the ``run_cartpole_rl_env.py`` script."
msgstr "与之前的教程类似，可以通过执行 ``run_cartpole_rl_env.py`` 脚本来运行环境。"

#: ../../source/tutorials/03_envs/create_manager_rl_env.rst:169
msgid ""
"This should open a similar simulation as in the previous tutorial. However, "
"this time, the environment returns more signals that specify the reward and "
"termination status. Additionally, the individual environments reset "
"themselves when they terminate based on the termination criteria specified "
"in the configuration."
msgstr ""
"这应该会打开与上一个教程中类似的仿真。然而，这次，环境返回了更多的信号，指定了奖励和终止状态。此外，各个环境在根据配置中指定的终止条件终止时会重新进行重置。"

#: ../../source/tutorials/03_envs/create_manager_rl_env.rst:-1
msgid "result of run_cartpole_rl_env.py"
msgstr "run_cartpole_rl_env.py的结果"

#: ../../source/tutorials/03_envs/create_manager_rl_env.rst:179
msgid ""
"To stop the simulation, you can either close the window, or press ``Ctrl+C``"
" in the terminal where you started the simulation."
msgstr "要停止仿真，您可以关闭窗口，或者在启动仿真的终端中按 ``Ctrl+C`` 。"

#: ../../source/tutorials/03_envs/create_manager_rl_env.rst:182
msgid ""
"In this tutorial, we learnt how to create a task environment for "
"reinforcement learning. We do this by extending the base environment to "
"include the rewards, terminations, commands and curriculum terms. We also "
"learnt how to use the :class:`envs.ManagerBasedRLEnv` class to run the "
"environment and receive various signals from it."
msgstr ""
"在本教程中，我们学习了如何为强化学习创建任务环境。我们通过扩展基础环境来包括奖励、终止条件、命令和课程术语来实现这一点。我们还学习了如何使用 "
":class:`envs.ManagerBasedRLEnv` 类来运行环境并从中接收各种信号。"

#: ../../source/tutorials/03_envs/create_manager_rl_env.rst:187
msgid ""
"While it is possible to manually create an instance of "
":class:`envs.ManagerBasedRLEnv` class for a desired task, this is not "
"scalable as it requires specialized scripts for each task. Thus, we exploit "
"the :meth:`gymnasium.make` function to create the environment with the gym "
"interface. We will learn how to do this in the next tutorial."
msgstr ""
"虽然可以手动为所需的任务创建 :class:`envs.ManagerBasedRLEnv` "
"类的实例，但这并不可伸缩，因为它需要为每个任务使用专门的脚本。因此，我们利用 :meth:`gymnasium.make` 函数来创建具有 gym "
"接口的环境。我们将在下一个教程中学习如何做到这一点。"
