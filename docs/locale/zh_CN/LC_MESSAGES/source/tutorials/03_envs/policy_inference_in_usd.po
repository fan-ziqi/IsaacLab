# SOME DESCRIPTIVE TITLE.
# Copyright (C) 2022-2024, The Isaac Lab Project Developers.
# This file is distributed under the same license as the Isaac Lab package.
# FIRST AUTHOR <EMAIL@ADDRESS>, 2025.
msgid ""
msgstr ""
"Project-Id-Version: Isaac Lab 2.0.0\n"
"Report-Msgid-Bugs-To: \n"
"POT-Creation-Date: 2025-07-23 23:22+0800\n"
"PO-Revision-Date: YEAR-MO-DA HO:MI+ZONE\n"
"Last-Translator: Ziqi Fan <fanziqi614@gmail.com>\n"
"Language-Team: zh_CN <LL@li.org>\n"
"Language: zh_CN\n"
"MIME-Version: 1.0\n"
"Content-Type: text/plain; charset=utf-8\n"
"Content-Transfer-Encoding: 8bit\n"
"Plural-Forms: nplurals=1; plural=0;\n"
"Generated-By: Babel 2.17.0\n"

#: ../../source/tutorials/03_envs/policy_inference_in_usd.rst:5
msgid "Policy Inference in USD Environment"
msgstr "USD 环境中的策略推理"

#: ../../source/tutorials/03_envs/policy_inference_in_usd.rst:9
msgid ""
"Having learnt how to modify a task in :ref:`tutorial-modify-direct-rl-env`, "
"we will now look at how to run a trained policy in a prebuilt USD scene."
msgstr ""
"学习了如何在 :ref:`tutorial-modify-direct-rl-env` 中修改任务后，我们现在将了解如何在预构建的 USD "
"场景中运行训练好的策略。"

#: ../../source/tutorials/03_envs/policy_inference_in_usd.rst:11
msgid ""
"In this tutorial, we will use the RSL RL library and the trained policy from"
" the Humanoid Rough Terrain ``Isaac-Velocity-Rough-H1-v0`` task in a simple "
"warehouse USD."
msgstr ""
"在本教程中，我们将使用 RSL RL 库和来自 Humanoid Rough Terrain ``Isaac-Velocity-"
"Rough-H1-v0`` 任务的训练策略，在一个简单的仓库 USD 中。"

#: ../../source/tutorials/03_envs/policy_inference_in_usd.rst:15
msgid "The Tutorial Code"
msgstr "教程代码"

#: ../../source/tutorials/03_envs/policy_inference_in_usd.rst:17
msgid ""
"For this tutorial, we use the trained policy's checkpoint exported as jit "
"(which is an offline version of the policy)."
msgstr "对于本教程，我们使用训练好的策略的检查点，导出为 jit（这是策略的离线版本）。"

#: ../../source/tutorials/03_envs/policy_inference_in_usd.rst:19
msgid ""
"The ``H1RoughEnvCfg_PLAY`` cfg encapsulates the configuration values of the "
"inference environment, including the assets to be instantiated."
msgstr "``H1RoughEnvCfg_PLAY`` 配置封装了推理环境的配置值，包括要实例化的资产。"

#: ../../source/tutorials/03_envs/policy_inference_in_usd.rst:22
msgid ""
"In order to use a prebuilt USD environment instead of the terrain generator "
"specified, we make the following changes to the config before passing it to "
"the ``ManagerBasedRLEnv``."
msgstr ""
"为了使用预构建的 USD 环境而不是指定的地形生成器，我们在将其传递给 ``ManagerBasedRLEnv`` 之前对配置进行以下更改。"

#: ../../source/tutorials/03_envs/policy_inference_in_usd.rst
msgid "Code for policy_inference_in_usd.py"
msgstr "policy_inference_in_usd.py的代码"

#: ../../source/tutorials/03_envs/policy_inference_in_usd.rst:34
msgid ""
"Note that we have set the device to ``CPU`` and disabled the use of Fabric "
"for inferencing. This is because when simulating a small number of "
"environment, CPU simulation can often perform faster than GPU simulation."
msgstr ""
"请注意，我们已将设备设置为 ``CPU`` 并禁用了使用 Fabric 进行推理。这是因为在仿真少量环境时，CPU 仿真通常比 GPU 仿真执行得更快。"

#: ../../source/tutorials/03_envs/policy_inference_in_usd.rst:39
msgid "The Code Execution"
msgstr "代码执行"

#: ../../source/tutorials/03_envs/policy_inference_in_usd.rst:41
msgid ""
"First, we need to train the ``Isaac-Velocity-Rough-H1-v0`` task by running "
"the following:"
msgstr "首先，我们需要通过运行以下命令来训练 ``Isaac-Velocity-Rough-H1-v0`` 任务:"

#: ../../source/tutorials/03_envs/policy_inference_in_usd.rst:47
msgid ""
"When the training is finished, we can visualize the result with the "
"following command. To stop the simulation, you can either close the window, "
"or press ``Ctrl+C`` in the terminal where you started the simulation."
msgstr "当训练完成后，我们可以使用以下命令来可视化结果。要停止仿真，您可以关闭窗口，或者在您启动仿真的终端中按 ``Ctrl+C`` 。"

#: ../../source/tutorials/03_envs/policy_inference_in_usd.rst:56
msgid ""
"After running the play script, the policy will be exported to jit and onnx "
"files under the experiment logs directory. Note that not all learning "
"libraries support exporting the policy to a jit or onnx file. For libraries "
"that don't currently support this functionality, please refer to the "
"corresponding ``play.py`` script for the library to learn about how to "
"initialize the policy."
msgstr ""
"运行播放脚本后，策略将被导出为 jit 和 onnx 文件，存储在实验日志目录下。请注意，并非所有学习库都支持将策略导出为 jit 或 onnx "
"文件。对于当前不支持此功能的库，请参考相应的 ``play.py`` 脚本，以了解如何初始化策略。"

#: ../../source/tutorials/03_envs/policy_inference_in_usd.rst:61
msgid ""
"We can then load the warehouse asset and run inference on the H1 robot using"
" the exported jit policy (``policy.pt`` file in the ``exported/`` "
"directory)."
msgstr ""
"我们可以加载仓库资产，并使用导出的 jit 策略在 H1 机器人上运行推理 (``policy.pt`` 文件在 ``exported/`` 路径下)。"

#: ../../source/tutorials/03_envs/policy_inference_in_usd.rst:-1
msgid "result of training Isaac-H1-Direct-v0 task"
msgstr "训练 Isaac-H1-Direct-v0 任务的结果"

#: ../../source/tutorials/03_envs/policy_inference_in_usd.rst:74
msgid ""
"In this tutorial, we learnt how to make minor modifications to an existing "
"environment config to run policy inference in a prebuilt usd environment."
msgstr "在本教程中，我们学习了如何对现有环境配置进行一些小修改，以在预构建的 usd 环境中运行策略推理。"
