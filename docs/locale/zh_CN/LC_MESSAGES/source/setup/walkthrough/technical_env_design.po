# SOME DESCRIPTIVE TITLE.
# Copyright (C) 2022-2025, The Isaac Lab Project Developers.
# This file is distributed under the same license as the Isaac Lab package.
# FIRST AUTHOR <EMAIL@ADDRESS>, 2025.
#
msgid ""
msgstr ""
"Project-Id-Version: Isaac Lab 2.1.0\n"
"Report-Msgid-Bugs-To: \n"
"POT-Creation-Date: 2025-06-14 10:59+0800\n"
"PO-Revision-Date: YEAR-MO-DA HO:MI+ZONE\n"
"Last-Translator: Ziqi Fan <fanziqi614@gmail.com>\n"
"Language-Team: zh_CN <LL@li.org>\n"
"Language: zh_CN\n"
"MIME-Version: 1.0\n"
"Content-Type: text/plain; charset=utf-8\n"
"Content-Transfer-Encoding: 8bit\n"
"Plural-Forms: nplurals=1; plural=0;\n"
"Generated-By: Babel 2.17.0\n"

#: ../../source/setup/walkthrough/technical_env_design.rst:4
msgid "Environment Design"
msgstr "环境设计"

#: ../../source/setup/walkthrough/technical_env_design.rst:6
msgid ""
"Armed with our understanding of the project and its structure, we are ready "
"to start modifying the code to suit our Jetbot training needs. Our template "
"is set up for the **direct** workflow, which means the environment class "
"will manage all of these details centrally. We will need to write the code "
"that will..."
msgstr ""
"凭借我们对项目及其结构的理解，我们准备开始修改代码以适应我们的 Jetbot 训练需求。我们的模板设置为 **直接** "
"工作流程，这意味着环境类将集中管理所有这些细节。我们需要编写代码来..."

#: ../../source/setup/walkthrough/technical_env_design.rst:10
msgid "Define the robot"
msgstr "定义机器人"

#: ../../source/setup/walkthrough/technical_env_design.rst:11
msgid "Define the training simulation and manage cloning"
msgstr "定义训练仿真并管理克隆"

#: ../../source/setup/walkthrough/technical_env_design.rst:12
msgid "Apply the actions from the agent to the robot"
msgstr "将智能体的动作应用于机器人"

#: ../../source/setup/walkthrough/technical_env_design.rst:13
msgid "Calculate and return the rewards and observations"
msgstr "计算并返回奖励和观测"

#: ../../source/setup/walkthrough/technical_env_design.rst:14
msgid "Manage resetting and terminal states"
msgstr "管理重置和终止状态"

#: ../../source/setup/walkthrough/technical_env_design.rst:16
msgid ""
"As a first step, our goal will be to get the environment training pipeline "
"to load and run.  We will use a dummy reward signal for the purposes of this"
" part of the walkthrough. You can find the code for these modifications "
"`here <https://github.com/isaac-sim/IsaacLabTutorial/tree/jetbot-"
"intro-1-1>`_!"
msgstr ""
"作为第一步，我们的目标将是让环境训练流程加载并运行。在本教程的这一部分，我们将使用一个虚假的奖励信号。你可以在 `这里 "
"<https://github.com/isaac-sim/IsaacLabTutorial/tree/jetbot-intro-1-1>`_ "
"找到这些修改的代码!"

#: ../../source/setup/walkthrough/technical_env_design.rst:20
msgid "Define the Robot"
msgstr "定义机器人"

#: ../../source/setup/walkthrough/technical_env_design.rst:22
msgid ""
"As our project grows, we may have many robots that we want to train. With "
"malice aforethought we will add a new ``module`` to our tutorial "
"``extension`` named ``robots`` where we will keep the definitions for robots"
" as individual python scripts. Navigate to "
"``isaac_lab_tutorial/source/isaac_lab_tutorial/isaac_lab_tutorial`` and "
"create a new folder called ``robots``. Within this folder create two files: "
"``__init__.py`` and ``jetbot.py``. The ``__init__.py`` file marks this "
"directory as a python module and we will be able to import the contents of "
"``jetbot.py`` in the usual way."
msgstr ""
"随着我们项目的壮大，我们可能会有许多想要训练的机器人。我们预谋添加一个名为 ``robots`` 的新 ``module`` 到我们的教程 "
"``extension`` 中，我们将在其中保留机器人的定义作为单独的 python 脚本。导航到 "
"``isaac_lab_tutorial/source/isaac_lab_tutorial/isaac_lab_tutorial`` ，创建一个名为 "
"``robots`` 的新文件夹。在此文件夹中创建两个文件: ``__init__.py`` 和 ``jetbot.py`` 。 "
"``__init__.py`` 文件将该目录标记为 python 模块，我们将能够以常规方式导入 ``jetbot.py`` 的内容。"

#: ../../source/setup/walkthrough/technical_env_design.rst:28
msgid "The contents of ``jetbot.py`` is fairly minimal"
msgstr "``jetbot.py`` 的内容非常简单"

#: ../../source/setup/walkthrough/technical_env_design.rst:42
msgid ""
"The only purpose of this file is to define a unique scope in which to save "
"our configurations. The details of robot configurations can be explored in "
":ref:`this tutorial <tutorial-add-new-robot>` but most noteworthy for this "
"walkthrough is the ``usd_path`` for the ``spawn`` argument of this "
"``ArticulationCfg``. The Jetbot asset is available to the public via a "
"hosted nucleus server, and that path is defined by ``ISAAC_NUCLEUS_DIR``, "
"however any path to a USD file is valid, including local ones!"
msgstr ""
"此文件的唯一目的是定义一个唯一的范围，用来保存我们的配置。有关机器人配置的详细信息可以在 :ref:`这个教程 <tutorial-add-new-"
"robot>` 中探索，但对于本教程而言，最值得关注的是 ``ArticulationCfg`` 中 ``spawn`` 参数的 "
"``usd_path`` 。 ``Jetbot`` 资源可通过托管的nucleus服务器公开获得，并且该路径由 "
"``ISAAC_NUCLEUS_DIR`` 定义，但任何到 USD 文件的路径都是有效的，包括本地路径!"

#: ../../source/setup/walkthrough/technical_env_design.rst:48
msgid "Environment Configuration"
msgstr "环境配置"

#: ../../source/setup/walkthrough/technical_env_design.rst:50
msgid ""
"Navigate to the environment configuration, "
"``isaac_lab_tutorial/source/isaac_lab_tutorial/isaac_lab_tutorial/tasks/direct/isaac_lab_tutorial/isaac_lab_tutorial_env_cfg.py``,"
" and replace its contents with the following"
msgstr ""
"导航到环境配置， "
"``isaac_lab_tutorial/source/isaac_lab_tutorial/isaac_lab_tutorial/tasks/direct/isaac_lab_tutorial/isaac_lab_tutorial_env_cfg.py``"
" ，并用以下内容替换其内容"

#: ../../source/setup/walkthrough/technical_env_design.rst:80
msgid ""
"Here we have, effectively, the same environment configuration as before, but"
" with the Jetbot instead of the cartpole. The parameters ``decimation``, "
"``episode_length_s``, ``action_space``, ``observation_space``, and "
"``state_space`` are members of the base class, ``DirectRLEnvCfg``, and must "
"be defined for every ``DirectRLEnv``. The space parameters are interpreted "
"as vectors of the given integer dimension, but they can also be defined as "
"`gymnasium spaces <https://gymnasium.farama.org/api/spaces/>`_!"
msgstr ""
"这里，我们实际上有与之前相同的环境配置，但是使用 Jetbot 替换了 cartpole。参数 ``decimation`` 、 "
"``episode_length_s`` 、 ``action_space`` 、 ``observation_space`` 和 "
"``state_space`` 都是基类 ``DirectRLEnvCfg`` 的成员，并且必须为每个 ``DirectRLEnv`` "
"进行定义。空间参数被解释为给定整数维度的向量，但也可以定义为 `gymnasium spaces "
"<https://gymnasium.farama.org/api/spaces/>`_!"

#: ../../source/setup/walkthrough/technical_env_design.rst:85
msgid ""
"Notice the difference in the action and observation spaces.  As the "
"designers of the environment, we get to choose these.  For the Jetbot, we "
"want to directly control the joints of the robot, of which only two are "
"actuated (hence the action space of two). The observation space is *chosen* "
"to be 3 because we are just going to feed the agent the linear velocity of "
"the Jetbot, for now.  We will change these later as we develop the "
"environment. Our policy isn't going to need an internal state maintained, so"
" our state space is zero."
msgstr ""
"请注意动作和观测空间的差异。作为环境的设计者，我们可以选择这些。对于 "
"Jetbot，我们希望直接控制机器人的关节，其中只有两个被驱动（因此动作空间为两个）。观测空间选择为 3，因为我们现在只是要将 Jetbot "
"的线速度提供给智能体。随着环境的发展，稍后我们会更改这些。我们的策略不需要维护内部状态，所以我们的状态空间为零。"

#: ../../source/setup/walkthrough/technical_env_design.rst:91
msgid "Attack of the clones"
msgstr "克隆的攻击"

#: ../../source/setup/walkthrough/technical_env_design.rst:93
msgid ""
"With the config defined, it's time to fill in the details of the "
"environment, starting with the initialization and setup. Navigate to the "
"environment definition, "
"``isaac_lab_tutorial/source/isaac_lab_tutorial/isaac_lab_tutorial/tasks/direct/isaac_lab_tutorial/isaac_lab_tutorial_env.py``,"
" and replace the contents of the ``__init__`` and ``_setup_scene`` methods "
"with the following."
msgstr ""
"配置定义完成后，是时候填写环境的细节，从初始化和设置开始。导航到环境定义， "
"``isaac_lab_tutorial/source/isaac_lab_tutorial/isaac_lab_tutorial/tasks/direct/isaac_lab_tutorial/isaac_lab_tutorial_env.py``"
" ，并用以下内容替换 ``__init__`` 和 ``_setup_scene`` 方法的内容。"

#: ../../source/setup/walkthrough/technical_env_design.rst:119
msgid ""
"Notice that the ``_setup_scene`` method doesn't change and the ``_init__`` "
"method is simply grabbing the joint indices from the robot (remember, setup "
"is called in super)."
msgstr ""
"请注意， ``_setup_scene`` 方法没有变化，而 ``_init__`` 方法只是从机器人获取关节索引（记住，setup 是在 super "
"中调用的）。"

#: ../../source/setup/walkthrough/technical_env_design.rst:121
msgid ""
"The next thing our environment needs is the definitions for how to handle "
"actions, observations, and rewards. First, replace the contents of "
"``_pre_physics_step`` and ``_apply_action`` with the following."
msgstr ""
"我们的环境需要的下一步是处理动作、观测和奖励的定义。首先，用以下内容替换 ``_pre_physics_step`` 和 "
"``_apply_action`` 的内容。"

#: ../../source/setup/walkthrough/technical_env_design.rst:132
msgid ""
"Here the act of applying actions to the robot in the environment is broken "
"into two steps: ``_pre_physics_step`` and ``_apply_action``. The physics "
"simulation is decimated with respect to querying the policy for actions, "
"meaning that multiple physics steps may occur per action taken by the "
"policy. The ``_pre_physics_step`` method is called just before this "
"simulation step takes place and lets us detach the process of getting data "
"from the policy being trained and applying updates to the physics "
"simulation. The ``_apply_action`` method is where those actions are actually"
" applied to the robots on the stage, after which the simulation is actually "
"stepped forward in time."
msgstr ""
"这里将将动作应用于环境中的机器人分为两步: ``_pre_physics_step`` 和 ``_apply_action`` "
"。物理仿真相对于查询用于动作的策略被降低，这意味着在策略采取的每个动作之间可能发生多次物理步骤。 ``_pre_physics_step`` "
"方法在实际仿真步骤发生之前调用，让我们分离出从正在训练的策略获取数据并应用更新到物理仿真的过程。 ``_apply_action`` "
"方法是将这些动作应用于场景中的机器人的地方，之后仿真会向前推进时间。"

#: ../../source/setup/walkthrough/technical_env_design.rst:138
msgid ""
"Next is the observations and rewards, which is just going to depend on the "
"linear velocity of the Jetbot in the body frame of the robot. Replace the "
"contents of ``_get_observations`` and ``_get_rewards`` with the following."
msgstr ""
"接下来是观测和奖励，这将取决于 Jetbot 在机器人本体坐标系中的线速度。用以下内容替换 ``_get_observations`` 和 "
"``_get_rewards`` 的内容。"

#: ../../source/setup/walkthrough/technical_env_design.rst:152
msgid ""
"The robot exists as an Articulation object within the Isaac Lab API. That "
"object carries a data class, the ``ArticulationData``, which contains all "
"the data for **specific** robots on the stage. When we talk about a scene "
"entity like the robot, we can either be talking about the robot broadly, as "
"an entity that exists in every scene, or we can be describing a specific, "
"singular clone of the robot on the stage. The ``ArticulationData`` contains "
"the data for those individual clones. This includes things like various "
"kinematic vectors (like ``root_com_lin_vel_b``) and reference vectors (like "
"``robot.data.FORWARD_VEC_B``)."
msgstr ""
"机器人在 Isaac Lab API 中是作为 Articulation 对象存在的。该对象包含一个数据类，即 ``ArticulationData``"
" ，其中包含场景上 **特定** "
"机器人的所有数据。当我们谈论一个像机器人这样的场景实体时，我们可以是广义上的讨论每个场景中存在的机器人实体，也可以是描述场景上特定单个机器人的。 "
"``ArticulationData`` 包含这些单个克隆的数据。这包括诸如各种运动学向量（如 ``root_com_lin_vel_b`` "
"）和参考向量（如 ``robot.data.FORWARD_VEC_B`` ）等。"

#: ../../source/setup/walkthrough/technical_env_design.rst:157
msgid ""
"Notice how in the ``_apply_action`` method, we are calling a method of "
"``self.robot`` which is a method of ``Articulation``. The actions being "
"applied are in the form of a 2D tensor of shape ``[num_envs, num_actions]``."
" We are applying actions to **all** robots on the stage at once! Here, when "
"we need to get the observations, we need the body frame velocity for all "
"robots on the stage, and so access ``self.robot.data`` to get that "
"information. The ``root_com_lin_vel_b`` is a property of the "
"``ArticulationData`` that handles the conversion of the center-of-mass "
"linear velocity from the world frame to the body frame for us. Finally, "
"Isaac Lab expects the observations to be returned as a dictionary, with "
"``policy`` defining those observations for the policy model and ``critic`` "
"defining those observations for the critic model (in the case of asymmetric "
"actor critic training). Since we are not doing asymmetric actor critic, we "
"only need to define ``policy``."
msgstr ""
"请注意，在 ``_apply_action`` 方法中，我们调用了 ``self.robot`` 的方法，这是 ``Articulation`` "
"的一个方法。被应用的动作以 ``[num_envs, num_actions]`` 形状的 2D 张量的形式存在。我们同时将动作应用于 **所有** "
"场景上的机器人!在这里，当我们需要获取观测时，我们需要所有场景上机器人的本体系速度，因此访问 ``self.robot.data`` 以获取这些信息。 "
"``root_com_lin_vel_b`` 是 ``ArticulationData`` "
"的一个属性，处理了质心线性速度从世界坐标系到本体坐标系的转换。最后，Isaac Lab 期望观测以字典形式返回，其中 ``policy`` "
"为策略模型定义观测， ``critic`` 为评论模型定义观测（在非对称的 actor critic 训练中）。由于我们不执行非对称的 actor "
"critic，我们只需要定义 ``policy`` 。"

#: ../../source/setup/walkthrough/technical_env_design.rst:163
msgid ""
"The rewards are more straightforward. For each clone of the scene, we need "
"to compute a reward value and return it as a tensor of shape ``[num_envs, "
"1]``. As a place holder, we will make the reward the magnitude of the linear"
" velocity of the Jetbot in the body frame. With this reward and observation "
"space, the agent should learn to drive the Jetbot forward or backward, with "
"the direction determined at random shortly after training starts."
msgstr ""
"奖励则更为直接。对于每个场景的克隆，我们需要计算一个奖励值，并将其作为形状为 ``[num_envs, 1]`` "
"的张量返回。作为占位符，我们将将奖励设定为 Jetbot "
"在本体坐标系中的线性速度的大小。有了这个奖励和观测空间，智能体应该会学会在训练开始后不久就随机确定方向，将 Jetbot 往前或往后驱动。"

#: ../../source/setup/walkthrough/technical_env_design.rst:167
msgid ""
"Finally, we can write the parts of the environment to handle termination and"
" resetting.  Replace the contents of ``_get_dones`` and ``_reset_idx`` with "
"the following."
msgstr "最后，我们可以编写环境的部分来处理终止和重置。 用以下内容替换 ``_get_dones`` 和 ``_reset_idx`` 的内容。"

#: ../../source/setup/walkthrough/technical_env_design.rst:186
msgid ""
"Like the actions, termination and resetting are handled in two parts.  First"
" is the ``_get_dones`` method, the goal of which is simply to mark which "
"environments need to be reset and why. Traditionally in reinforcement "
"learning, an \"episode\" ends in one of two ways: either the agent reaches a"
" terminal state, or the episode reaches a maximum duration. Isaac Lab is "
"kind to us, because it manages all of this episode duration tracking behind "
"the scenes.  The configuration parameter ``episode_length_s`` defines this "
"maximum episode length in seconds and the parameters ``episode_length_buff``"
" and ``max_episode_length`` contain the number of steps taken by individual "
"scenes (allowing for asynchronous running of the environment) and the "
"maximum length of the episode as converted from ``episode_length_s``. The "
"boolean operation computing ``time_out`` just compares the current buffer "
"size to the max and returns true if it's greater, thus indicating which "
"scenes are at the episode length limit. Since our current environment is a "
"dummy, we don't define terminal states and so just return ``False`` for the "
"first tensor (this gets projected automatically to the correct shape through"
" the power of pytorch)."
msgstr ""
"与动作类似，终止和重置是分成两部分进行处理的。首先是 ``_get_dones`` "
"方法，其目标仅仅是标记哪些环境需要重置以及原因。传统上，在强化学习中，一个 \"episode\" 以两种方式结束: "
"要么是智能体达到一个终止状态，要么是达到最大持续时间。Isaac Lab 对我们很好，因为它在幕后管理所有这些周期长度跟踪。配置参数 "
"``episode_length_s`` 定义了这个最大的 episode 长度（以秒为单位），参数 ``episode_length_buff`` 和"
" ``max_episode_length`` 包含单个场景所采取的步数（允许环境异步运行）以及从 ``episode_length_s`` "
"转换过来的最大 episode 长度。计算 ``time_out`` 的布尔运算仅仅比较当前缓冲区大小和最大值，如果大于最大值，则返回 "
"true，从而指示哪些场景达到了 episode 长度限制。由于我们当前的环境是一个虚拟的环境，我们没有定义终止状态，所以对于第一个张量返回 "
"``False`` （PyTorch 的强大之处使其自动转换成正确的形状）。"

#: ../../source/setup/walkthrough/technical_env_design.rst:194
msgid ""
"Finally, the ``_reset_idx`` method accepts a tensor of booleans indicating "
"which scenes need to be reset, and resets them. Notice that this is the only"
" other method of ``DirectRLEnv`` that directly calls ``super``, which is "
"done so here to manage the internal buffers related to episode length.  For "
"those environments indicated by ``env_ids`` we retrieve the root default "
"state, and reset the robot to that state while also offsetting the position "
"of each robot according to the origin of the corresponding scene. This is a "
"consequence of the cloning procedure, which starts with a single robot and a"
" single default state defined in the world frame. Don't forget this step for"
" your own custom environments!"
msgstr ""
"最后， ``_reset_idx`` 方法接受一个指示哪些场景需要重置的布尔张量，并对它们进行重置。请注意，这是 ``DirectRLEnv`` "
"的仅存在的另一个直接调用 ``super`` 的方法，这样做是为了管理与 episode 长度相关的内部缓冲。对于 ``env_ids`` "
"指示的环境，我们获取根默认状态，并将机器人重置到该状态，同时根据对应场景的原点偏移每个机器人的位置。这是克隆过程的一个结果，该过程从世界坐标系中定义的单个机器人和单个默认状态开始。不要忘记为您自己的自定义环境执行此步骤!"

#: ../../source/setup/walkthrough/technical_env_design.rst:199
msgid ""
"With these changes complete, you should see the Jetbot slowly learn to drive"
" forward when you launch the task with the template ``train.py`` script."
msgstr "完成这些更改后，当您使用模板 ``train.py`` 脚本启动任务时，您应该会看到 Jetbot 慢慢学会向前驾驶。"

#: ../../source/setup/walkthrough/technical_env_design.rst:-1
msgid "The Jetbot invasion begins!"
msgstr "Jetbot 入侵开始!"
