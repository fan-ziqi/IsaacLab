# SOME DESCRIPTIVE TITLE.
# Copyright (C) 2022-2025, The Isaac Lab Project Developers.
# This file is distributed under the same license as the Isaac Lab package.
# FIRST AUTHOR <EMAIL@ADDRESS>, 2025.
#
msgid ""
msgstr ""
"Project-Id-Version: Isaac Lab 2.2.0\n"
"Report-Msgid-Bugs-To: \n"
"POT-Creation-Date: 2025-08-27 09:50+0800\n"
"PO-Revision-Date: YEAR-MO-DA HO:MI+ZONE\n"
"Last-Translator: Ziqi Fan <fanziqi614@gmail.com>\n"
"Language-Team: zh_CN <LL@li.org>\n"
"Language: zh_CN\n"
"MIME-Version: 1.0\n"
"Content-Type: text/plain; charset=utf-8\n"
"Content-Transfer-Encoding: 8bit\n"
"Plural-Forms: nplurals=1; plural=0;\n"
"Generated-By: Babel 2.17.0\n"

#: ../../source/experimental-features/newton-physics-integration/training-environments.rst:2
msgid "Training Environments"
msgstr "训练环境"

#: ../../source/experimental-features/newton-physics-integration/training-environments.rst:4
msgid ""
"To run training, we follow the standard Isaac Lab workflow. If you are new "
"to Isaac Lab, we recommend that you review the `Quickstart Guide here "
"<https://isaac-sim.github.io/IsaacLab/main/source/setup/quickstart.html#>`_."
msgstr ""
"要运行训练，我们遵循标准的Isaac Lab工作流程。如果您是Isaac Lab的新手，我们建议您查看 `此处的快速入门指南 "
"<https://isaac-sim.github.io/IsaacLab/main/source/setup/quickstart.html#>`_."

#: ../../source/experimental-features/newton-physics-integration/training-environments.rst:6
msgid "The currently supported tasks are as follows:"
msgstr "目前支持的任务如下："

#: ../../source/experimental-features/newton-physics-integration/training-environments.rst:8
msgid "Isaac-Cartpole-Direct-v0"
msgstr "Isaac-Cartpole-Direct-v0"

#: ../../source/experimental-features/newton-physics-integration/training-environments.rst:9
msgid "Isaac-Ant-Direct-v0"
msgstr "Isaac-Ant-Direct-v0"

#: ../../source/experimental-features/newton-physics-integration/training-environments.rst:10
msgid "Isaac-Humanoid-Direct-v0"
msgstr "Isaac-Humanoid-Direct-v0"

#: ../../source/experimental-features/newton-physics-integration/training-environments.rst:11
msgid "Isaac-Velocity-Flat-Anymal-D-v0"
msgstr "Isaac-Velocity-Flat-Anymal-D-v0"

#: ../../source/experimental-features/newton-physics-integration/training-environments.rst:12
msgid "Isaac-Velocity-Flat-G1-v0"
msgstr "Isaac-Velocity-Flat-G1-v0"

#: ../../source/experimental-features/newton-physics-integration/training-environments.rst:13
msgid "Isaac-Velocity-Flat-G1-v1 (Sim-to-Real tested)"
msgstr "Isaac-Velocity-Flat-G1-v1 (已测试 Sim-to-Real)"

#: ../../source/experimental-features/newton-physics-integration/training-environments.rst:14
msgid "Isaac-Velocity-Flat-H1-v0"
msgstr "Isaac-Velocity-Flat-H1-v0"

#: ../../source/experimental-features/newton-physics-integration/training-environments.rst:16
msgid ""
"To launch an environment and check that it loads as expected, we can start "
"by trying it out with zero actions sent to its actuators. This can be done "
"as follows, where ``TASK_NAME`` is the name of the task you’d like to run, "
"and ``NUM_ENVS`` is the number of instances of the task that you’d like to "
"create."
msgstr ""
"要启动环境并检查它是否按预期加载，可以尝试将zero actions发送到其执行器。可以按如下方式进行，其中 ``TASK_NAME`` 是您想要运行的任务名称， ``NUM_ENVS`` 是您想要创建的任务实例数。"

#: ../../source/experimental-features/newton-physics-integration/training-environments.rst:23
msgid "For cartpole with 128 instances it would look like this:"
msgstr "对于128个实例的cartpole，看起来是这样的："

#: ../../source/experimental-features/newton-physics-integration/training-environments.rst:29
msgid ""
"To run the same environment with random actions we can use a different "
"script:"
msgstr "要使用随机actions运行相同的环境，可以使用不同的脚本："

#: ../../source/experimental-features/newton-physics-integration/training-environments.rst:35
msgid ""
"To train the environment we provide hooks to different rl frameworks. See "
"the `Reinforcement Learning Scripts documentation <https://isaac-"
"sim.github.io/IsaacLab/main/source/overview/reinforcement-"
"learning/rl_existing_scripts.html>`_ for more information."
msgstr ""
"要训练环境，我们提供了与不同RL框架的hooks。有关更多信息，请参阅 `强化学习脚本文档 <https://isaac-"
"sim.github.io/IsaacLab/main/source/overview/reinforcement-"
"learning/rl_existing_scripts.html>`_。"

#: ../../source/experimental-features/newton-physics-integration/training-environments.rst:37
msgid ""
"Here are some examples on how to run training on several different RL "
"frameworks. Note that we are explicitly setting the number of environments "
"to 4096 to benefit more from GPU parallelization. We also disable the "
"Omniverse UI visualization to train the environment as quickly as possible "
"by using the ``--headless`` option."
msgstr ""
"以下是如何在几种不同的RL框架上进行训练的一些示例。请注意，我们明确设置了环境的数量为4096，以更多地从GPU并行化中受益。我们还通过使用 ``--headless`` 选项来禁用Omniverse"
" UI可视化，以尽快训练环境。"

#: ../../source/experimental-features/newton-physics-integration/training-environments.rst:52
msgid ""
"Once a policy is trained we can visualize it by using the play scripts. But "
"first, we need to find the checkpoint of the trained policy. Typically, "
"these are stored under: ``logs/NAME_OF_RL_FRAMEWORK/TASK_NAME/DATE``."
msgstr ""
"一旦训练了策略，我们可以通过使用play脚本来可视化它。但首先，我们需要找到经过训练的策略的checkpoint。通常，这些存储在: ``logs/NAME_OF_RL_FRAMEWORK/TASK_NAME/DATE`` 下。"

#: ../../source/experimental-features/newton-physics-integration/training-environments.rst:55
msgid ""
"For instance with our rsl_rl example it could look like this: "
"``logs/rsl_rl/cartpole_direct/2025-08-21_15-45-30/model_299.pt``"
msgstr ""
"例如，对于我们的rsl_rl示例，可能是这样的: ``logs/rsl_rl/cartpole_direct/2025-08-21_15-45-30/model_299.pt``"

#: ../../source/experimental-features/newton-physics-integration/training-environments.rst:58
msgid ""
"To then run this policy we can use the following command, note that we "
"reduced the number of environments and removed the ``--headless`` option so "
"that we can see our policy in action!"
msgstr ""
"然后，我们可以使用以下命令运行此策略，请注意，我们减少了环境的数量并删除了 ``--headless`` 选项，以便我们可以看到我们的策略在实际操作中的表现！"

#: ../../source/experimental-features/newton-physics-integration/training-environments.rst:64
msgid "The same approach applies to all other frameworks."
msgstr "相同的方法适用于所有其他框架。"

#: ../../source/experimental-features/newton-physics-integration/training-environments.rst:66
msgid ""
"Note that not all environments are supported in all frameworks. For example,"
" several of the locomotion environments are only supported in the rsl_rl "
"framework."
msgstr "请注意，并非所有环境都受到所有框架的支持。例如，一些运动环境只受到rsl_rl框架的支持。"
