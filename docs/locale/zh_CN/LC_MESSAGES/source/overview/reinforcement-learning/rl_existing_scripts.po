# SOME DESCRIPTIVE TITLE.
# Copyright (C) 2022-2024, The Isaac Lab Project Developers.
# This file is distributed under the same license as the Isaac Lab package.
# FIRST AUTHOR <EMAIL@ADDRESS>, 2024.
msgid ""
msgstr ""
"Project-Id-Version: Isaac Lab 1.1.0\n"
"Report-Msgid-Bugs-To: \n"
"POT-Creation-Date: 2025-08-10 09:49+0800\n"
"PO-Revision-Date: YEAR-MO-DA HO:MI+ZONE\n"
"Last-Translator: Ziqi Fan <fanziqi614@gmail.com>\n"
"Language-Team: zh_CN <LL@li.org>\n"
"Language: zh_CN\n"
"MIME-Version: 1.0\n"
"Content-Type: text/plain; charset=utf-8\n"
"Content-Transfer-Encoding: 8bit\n"
"Plural-Forms: nplurals=1; plural=0;\n"
"Generated-By: Babel 2.17.0\n"

#: ../../source/overview/reinforcement-learning/rl_existing_scripts.rst:2
msgid "Reinforcement Learning Scripts"
msgstr "强化学习脚本"

#: ../../source/overview/reinforcement-learning/rl_existing_scripts.rst:4
msgid ""
"We provide wrappers to different reinforcement libraries. These wrappers "
"convert the data from the environments into the respective libraries "
"function argument and return types."
msgstr "我们提供对不同强化学习库的包装器。这些包装器将环境中的数据转换为各自库的函数参数和返回类型。"

#: ../../source/overview/reinforcement-learning/rl_existing_scripts.rst:9
msgid "RL-Games"
msgstr "RL-Games"

#: ../../source/overview/reinforcement-learning/rl_existing_scripts.rst:11
msgid ""
"Training an agent with `RL-Games <https://github.com/Denys88/rl_games>`__ on"
" ``Isaac-Ant-v0``:"
msgstr ""
"使用 `RL-Games <https://github.com/Denys88/rl_games>`__ 在 ``Isaac-Ant-v0`` "
"上训练智能体"

#: ../../source/overview/reinforcement-learning/rl_existing_scripts.rst
msgid ":icon:`fa-brands fa-linux` Linux"
msgstr ":icon:`fa-brands fa-linux` Linux"

#: ../../source/overview/reinforcement-learning/rl_existing_scripts.rst
msgid ":icon:`fa-brands fa-windows` Windows"
msgstr ":icon:`fa-brands fa-windows` Windows"

#: ../../source/overview/reinforcement-learning/rl_existing_scripts.rst:50
msgid "RSL-RL"
msgstr "RSL-RL"

#: ../../source/overview/reinforcement-learning/rl_existing_scripts.rst:52
msgid ""
"Training an agent with `RSL-RL <https://github.com/leggedrobotics/rsl_rl>`__"
" on ``Isaac-Reach-Franka-v0``:"
msgstr ""
"用 `RSL-RL <https://github.com/leggedrobotics/rsl_rl>`__ 在 ``Isaac-Reach-"
"Franka-v0`` 上训练一个agent:"

#: ../../source/overview/reinforcement-learning/rl_existing_scripts.rst:91
msgid "SKRL"
msgstr "SKRL"

#: ../../source/overview/reinforcement-learning/rl_existing_scripts.rst:93
msgid ""
"Training an agent with `SKRL <https://skrl.readthedocs.io>`__ on ``Isaac-"
"Reach-Franka-v0``:"
msgstr ""
"使用 `SKRL <https://skrl.readthedocs.io>`__ 在 ``Isaac-Reach-Franka-v0`` "
"上训练智能体: "

#: ../../source/overview/reinforcement-learning/rl_existing_scripts.rst
msgid "PyTorch"
msgstr "PyTorch"

#: ../../source/overview/reinforcement-learning/rl_existing_scripts.rst
msgid "JAX"
msgstr "JAX"

#: ../../source/overview/reinforcement-learning/rl_existing_scripts.rst:139
msgid ""
"It is recommended to `install JAX "
"<https://jax.readthedocs.io/en/latest/installation.html>`_ manually before "
"proceeding to install skrl and its dependencies, as JAX installs its CPU "
"version by default. Visit the **skrl** `installation "
"<https://skrl.readthedocs.io/en/latest/intro/installation.html>`_ page for "
"more details. Note that JAX GPU support is only available on Linux."
msgstr ""
"建议在继续安装 skrl 及其依赖项之前，手动 `安装 JAX "
"<https://jax.readthedocs.io/en/latest/installation.html>`_ ，因为 JAX 默认安装的是其 "
"CPU 版本。有关更多详细信息，请访问 **skrl** `安装 "
"<https://skrl.readthedocs.io/en/latest/intro/installation.html>`_ 页面。请注意，JAX"
" GPU支持仅在Linux上可用。"

#: ../../source/overview/reinforcement-learning/rl_existing_scripts.rst:143
msgid ""
"JAX 0.6.0 or higher (built on CuDNN v9.8) is incompatible with Isaac Lab's "
"PyTorch 2.7 (built on CuDNN v9.7), and therefore not supported. To install a"
" compatible version of JAX for CUDA 12 use ``pip install "
"\"jax[cuda12]<0.6.0\"``, for example."
msgstr ""
"JAX 0.6.0 或更高版本（构建在 CuDNN v9.8 上）与 Isacc Lab 的 PyTorch 2.7（构建在 CuDNN v9.7 "
"上）不兼容，因此不受支持。要安装 CUDA 12 兼容版本的 JAX，请使用 ``pip install "
"\"jax[cuda12]<0.6.0\"``，例如。"

#: ../../source/overview/reinforcement-learning/rl_existing_scripts.rst:161
msgid ""
"Training the multi-agent environment ``Isaac-Shadow-Hand-Over-Direct-v0`` "
"with skrl:"
msgstr "用skrl训练多智能体环境 ``Isaac-Shadow-Hand-Over-Direct-v0`` 。"

#: ../../source/overview/reinforcement-learning/rl_existing_scripts.rst:191
msgid "Stable-Baselines3"
msgstr "Stable-Baselines3"

#: ../../source/overview/reinforcement-learning/rl_existing_scripts.rst:193
msgid ""
"Training an agent with `Stable-Baselines3 <https://stable-"
"baselines3.readthedocs.io/en/master/index.html>`__ on ``Isaac-Velocity-Flat-"
"Unitree-A1-v0``:"
msgstr ""
"在 ``Isaac-Velocity-Flat-Unitree-A1-v0`` 上使用 `Stable-Baselines3 "
"<https://stable-baselines3.readthedocs.io/en/master/index.html>`__ 训练一个智能体:"

#: ../../source/overview/reinforcement-learning/rl_existing_scripts.rst:232
msgid ""
"All the scripts above log the training progress to `Tensorboard`_ in the "
"``logs`` directory in the root of the repository. The logs directory follows"
" the pattern ``logs/<library>/<task>/<date-time>``, where ``<library>`` is "
"the name of the learning framework, ``<task>`` is the task name, and "
"``<date-time>`` is the timestamp at which the training script was executed."
msgstr ""
"所有上述脚本将训练进度记录到存储库根目录中的 ``logs`` 目录中的 `Tensorboard`_ 。logs目录遵循模式 "
"``logs/<library>/<task>/<date-time>`` ，其中 ``<library>`` 为学习框架的名称， ``<task>``"
" 为任务名称， ``<date-time>`` 为执行训练脚本的时间戳。"

#: ../../source/overview/reinforcement-learning/rl_existing_scripts.rst:237
msgid "To view the logs, run:"
msgstr "要查看日志，请运行: "
