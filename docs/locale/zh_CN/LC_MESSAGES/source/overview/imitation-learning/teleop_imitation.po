# SOME DESCRIPTIVE TITLE.
# Copyright (C) 2022-2024, The Isaac Lab Project Developers.
# This file is distributed under the same license as the Isaac Lab package.
# FIRST AUTHOR <EMAIL@ADDRESS>, 2024.
msgid ""
msgstr ""
"Project-Id-Version: Isaac Lab 1.1.0\n"
"Report-Msgid-Bugs-To: \n"
"POT-Creation-Date: 2025-08-30 10:41+0800\n"
"PO-Revision-Date: YEAR-MO-DA HO:MI+ZONE\n"
"Last-Translator: Ziqi Fan <fanziqi614@gmail.com>\n"
"Language-Team: zh_CN <LL@li.org>\n"
"Language: zh_CN\n"
"MIME-Version: 1.0\n"
"Content-Type: text/plain; charset=utf-8\n"
"Content-Transfer-Encoding: 8bit\n"
"Plural-Forms: nplurals=1; plural=0;\n"
"Generated-By: Babel 2.17.0\n"

#: ../../source/overview/imitation-learning/teleop_imitation.rst:4
msgid "Teleoperation and Imitation Learning with Isaac Lab Mimic"
msgstr "​​Isaac Lab Mimic 中的遥操作与模仿学习​"

#: ../../source/overview/imitation-learning/teleop_imitation.rst:8
msgid "Teleoperation"
msgstr "遥操作"

#: ../../source/overview/imitation-learning/teleop_imitation.rst:10
msgid ""
"We provide interfaces for providing commands in SE(2) and SE(3) space for "
"robot control. In case of SE(2) teleoperation, the returned command is the "
"linear x-y velocity and yaw rate, while in SE(3), the returned command is a "
"6-D vector representing the change in pose."
msgstr ""
"我们提供接口以便在 SE(2) 和 SE(3) 空间中提供机器人控制命令。在 SE(2) 遥操作的情况下，返回的命令是x-y线速度和yaw角度率，而在 "
"SE(3) 中，返回的命令是一个表示姿态变化的 6-D 向量。"

#: ../../source/overview/imitation-learning/teleop_imitation.rst:17
msgid "Presently, Isaac Lab Mimic is only supported in Linux."
msgstr "当前，Isaac Lab Mimic 仅支持 Linux。"

#: ../../source/overview/imitation-learning/teleop_imitation.rst:19
msgid "To play inverse kinematics (IK) control with a keyboard device:"
msgstr "要使用键盘设备进行反向运动学（IK）控制: "

#: ../../source/overview/imitation-learning/teleop_imitation.rst:25
msgid ""
"For smoother operation and off-axis operation, we recommend using a "
"SpaceMouse as the input device. Providing smoother demonstrations will make "
"it easier for the policy to clone the behavior. To use a SpaceMouse, simply "
"change the teleop device accordingly:"
msgstr ""
"为了更流畅的操作和离轴操作，我们推荐使用 SpaceMouse 作为输入设备。提供更流畅的演示将使得策略更容易克隆行为。要使用 "
"SpaceMouse，只需相应地更改远程操作设备:"

#: ../../source/overview/imitation-learning/teleop_imitation.rst:33
msgid ""
"If the SpaceMouse is not detected, you may need to grant additional user "
"permissions by running ``sudo chmod 666 /dev/hidraw<#>`` where ``<#>`` "
"corresponds to the device index of the connected SpaceMouse."
msgstr ""
"如果未检测到 SpaceMouse，您可能需要通过运行 ``sudo chmod 666 /dev/hidraw<#>`` 来授予额外的用户权限，其中 "
"``<#>`` 对应于连接的 SpaceMouse 的设备索引。"

#: ../../source/overview/imitation-learning/teleop_imitation.rst:36
msgid ""
"To determine the device index, list all ``hidraw`` devices by running ``ls "
"-l /dev/hidraw*``. Identify the device corresponding to the SpaceMouse by "
"running ``cat /sys/class/hidraw/hidraw<#>/device/uevent`` on each of the "
"devices listed from the prior step."
msgstr ""
"为了确定设备索引，运行 ``ls -l /dev/hidraw*`` 列出所有 ``hidraw`` 设备。通过运行 ``cat "
"/sys/class/hidraw/hidraw<#>/device/uevent`` 在每个先前步骤列出的设备上，识别与 SpaceMouse "
"对应的设备。"

#: ../../source/overview/imitation-learning/teleop_imitation.rst:40
msgid ""
"We recommend using local deployment of Isaac Lab to use the SpaceMouse. If "
"using container deployment (:ref:`deployment-docker`), you must manually "
"mount the SpaceMouse to the ``isaac-lab-base`` container by adding a "
"``devices`` attribute with the path to the device in your ``docker-"
"compose.yaml`` file:"
msgstr ""
"我们建议使用Isaac Lab的本地部署来使用SpaceMouse。如果使用容器部署 (:ref:`deployment-docker`)，必须通过在 "
"``docker-compose.yaml`` 文件中添加一个带有设备路径的 ``devices`` 属性，将SpaceMouse手动挂载到 "
"``isaac-lab-base`` 容器中: "

#: ../../source/overview/imitation-learning/teleop_imitation.rst:48
msgid "where ``<#>`` is the device index of the connected SpaceMouse."
msgstr "其中 ``<#>`` 是连接的SpaceMouse的设备索引。"

#: ../../source/overview/imitation-learning/teleop_imitation.rst:50
msgid ""
"If you are using the IsaacLab + CloudXR container deployment (:ref:`cloudxr-"
"teleoperation`), you can add the ``devices`` attribute under the ``services "
"-> isaac-lab-base`` section of the ``docker/docker-compose.cloudxr-"
"runtime.patch.yaml`` file."
msgstr ""
"如果您正在使用 IsaacLab + CloudXR 容器部署 (:ref:`cloudxr-teleoperation`)，您可以在 "
"``docker/docker-compose.cloudxr-runtime.patch.yaml`` 文件的 ``services -> "
"isaac-lab-base`` 部分下添加 ``devices`` 属性。"

#: ../../source/overview/imitation-learning/teleop_imitation.rst:53
msgid ""
"Isaac Lab is only compatible with the SpaceMouse Wireless and SpaceMouse "
"Compact models from 3Dconnexion."
msgstr ""
"Isaac Lab 仅兼容 3Dconnexion 的 SpaceMouse Wireless 和 SpaceMouse Compact 型号。"

#: ../../source/overview/imitation-learning/teleop_imitation.rst:56
msgid ""
"For tasks that benefit from the use of an extended reality (XR) device with "
"hand tracking, Isaac Lab supports using NVIDIA CloudXR to immersively stream"
" the scene to compatible XR devices for teleoperation. Note that when using "
"hand tracking we recommend using the absolute variant of the task (``Isaac-"
"Stack-Cube-Franka-IK-Abs-v0``), which requires the ``handtracking`` device:"
msgstr ""
"对于需要配合扩展现实(XR)设备使用手部追踪的任务，Isaac Lab支持通过NVIDIA "
"CloudXR将场景实时沉浸式串流至兼容XR设备进行遥操作。请注意使用手部追踪时，我们推荐选用任务的绝对变量版本( ``Isaac-Stack-"
"Cube-Franka-IK-Abs-v0`` )，该版本需要配合 ``handtracking`` 设备使用: "

#: ../../source/overview/imitation-learning/teleop_imitation.rst:64
msgid ""
"See :ref:`cloudxr-teleoperation` to learn more about using CloudXR with "
"Isaac Lab."
msgstr "请查看 :ref:`cloudxr-teleoperation` 了解如何在Isaac Lab中使用CloudXR的更多信息。"

#: ../../source/overview/imitation-learning/teleop_imitation.rst:67
msgid ""
"The script prints the teleoperation events configured. For keyboard, these "
"are as follows:"
msgstr "脚本打印配置的遥操作事件。对于键盘，它们如下: "

#: ../../source/overview/imitation-learning/teleop_imitation.rst:82
msgid "For SpaceMouse, these are as follows:"
msgstr "对于 SpaceMouse，具体如下:"

#: ../../source/overview/imitation-learning/teleop_imitation.rst:93
msgid ""
"The next section describes how teleoperation devices can be used for data "
"collection for imitation learning."
msgstr "下一节描述了如何使用遥操作设备进行模仿学习的数据收集。"

#: ../../source/overview/imitation-learning/teleop_imitation.rst:97
msgid "Imitation Learning with Isaac Lab Mimic"
msgstr "​​Isaac Lab Mimic 中的模仿学习​"

#: ../../source/overview/imitation-learning/teleop_imitation.rst:99
msgid ""
"Using the teleoperation devices, it is also possible to collect data for "
"learning from demonstrations (LfD). For this, we provide scripts to collect "
"data into the open HDF5 format."
msgstr "使用遥操作设备，还可以收集用于示范学习（LfD）的数据。为此，我们提供脚本将数据收集到开放的 HDF5 格式中。"

#: ../../source/overview/imitation-learning/teleop_imitation.rst:103
msgid "Collecting demonstrations"
msgstr "收集演示"

#: ../../source/overview/imitation-learning/teleop_imitation.rst:105
msgid ""
"To collect demonstrations with teleoperation for the environment ``Isaac-"
"Stack-Cube-Franka-IK-Rel-v0``, use the following commands:"
msgstr "要收集环境 ``Isaac-Stack-Cube-Franka-IK-Rel-v0`` 的遥操作示范，请使用以下命令:"

#: ../../source/overview/imitation-learning/teleop_imitation.rst:120
msgid ""
"The order of the stacked cubes should be blue (bottom), red (middle), green "
"(top)."
msgstr "堆叠立方体的顺序应为蓝色（底部）、红色（中间）、绿色（顶部）。"

#: ../../source/overview/imitation-learning/teleop_imitation.rst:124
msgid ""
"When using an XR device, we suggest collecting demonstrations with the "
"``Isaac-Stack-Cube-Frank-IK-Abs-v0`` version of the task and "
"``--teleop_device handtracking``, which controls the end effector using the "
"absolute position of the hand."
msgstr ""
"在使用XR设备时，我们建议使用任务的 ``Isaac-Stack-Cube-Franka-IK-Abs-v0`` 版本和 "
"``--teleop_device handtracking`` 来收集演示，该命令可控制末端执行器使用手部的绝对位置。"

#: ../../source/overview/imitation-learning/teleop_imitation.rst:126
msgid ""
"About 10 successful demonstrations are required in order for the following "
"steps to succeed."
msgstr "为了后续步骤成功，通常需要大约 10 次成功演示。"

#: ../../source/overview/imitation-learning/teleop_imitation.rst:128
msgid ""
"Here are some tips to perform demonstrations that lead to successful policy "
"training:"
msgstr "以下是一些执行演示并成功进行策略训练的技巧:"

#: ../../source/overview/imitation-learning/teleop_imitation.rst:130
msgid ""
"Keep demonstrations short. Shorter demonstrations mean fewer decisions for "
"the policy, making training easier."
msgstr "保持演示简短。简短的演示意味着策略需要做出的决策更少，从而使训练变得更容易。"

#: ../../source/overview/imitation-learning/teleop_imitation.rst:131
msgid ""
"Take a direct path. Do not follow along arbitrary axis, but move straight "
"toward the goal."
msgstr "走一条直接的路径。不要沿着任意轴线移动，而是直线朝着目标前进。"

#: ../../source/overview/imitation-learning/teleop_imitation.rst:132
msgid ""
"Do not pause. Perform smooth, continuous motions instead. It is not obvious "
"for a policy why and when to pause, hence continuous motions are easier to "
"learn."
msgstr "不要暂停。请执行平滑、连续的动作。由于策略并不明显地解释何时以及为何要暂停，因此连续的动作更容易学习。"

#: ../../source/overview/imitation-learning/teleop_imitation.rst:134
msgid ""
"If, while performing a demonstration, a mistake is made, or the current "
"demonstration should not be recorded for some other reason, press the ``R`` "
"key to discard the current demonstration, and reset to a new starting "
"position."
msgstr "如果在进行演示时出现错误，或者当前的演示由于其他原因不应被记录，请按 ``R`` 键丢弃当前演示，并重置到新的起始位置。"

#: ../../source/overview/imitation-learning/teleop_imitation.rst:137
#: ../../source/overview/imitation-learning/teleop_imitation.rst:402
msgid ""
"Non-determinism may be observed during replay as physics in IsaacLab are not"
" determimnistically reproducible when using ``env.reset``."
msgstr "非确定性可能会在回放过程中观察到，因为在使用 ``env.reset`` 时，IsaacLab 中的物理现象无法确定性地重现。"

#: ../../source/overview/imitation-learning/teleop_imitation.rst:140
msgid "Pre-recorded demonstrations"
msgstr "预先录制的演示"

#: ../../source/overview/imitation-learning/teleop_imitation.rst:142
msgid ""
"We provide a pre-recorded ``dataset.hdf5`` containing 10 human "
"demonstrations for ``Isaac-Stack-Cube-Franka-IK-Rel-v0`` `here "
"<https://omniverse-content-production.s3-us-"
"west-2.amazonaws.com/Assets/Isaac/5.0/Isaac/IsaacLab/Mimic/franka_stack_datasets/dataset.hdf5>`_."
" This dataset may be downloaded and used in the remaining tutorial steps if "
"you do not wish to collect your own demonstrations."
msgstr ""
"我们提供了一个预先录制的 ``dataset.hdf5`` ，包含 10 个关于 ``Isaac-Stack-Cube-Franka-IK-"
"Rel-v0`` 的人类示范，您可以在 `这里 <https://omniverse-content-production.s3-us-"
"west-2.amazonaws.com/Assets/Isaac/5.0/Isaac/IsaacLab/Mimic/franka_stack_datasets/dataset.hdf5>`_"
" 下载该数据集。如果您不希望收集自己的示范，可以在接下来的教程步骤中使用此数据集。"

#: ../../source/overview/imitation-learning/teleop_imitation.rst:147
msgid "Use of the pre-recorded dataset is optional."
msgstr "使用预录制的数据集是可选的。"

#: ../../source/overview/imitation-learning/teleop_imitation.rst:150
msgid "Generating additional demonstrations with Isaac Lab Mimic"
msgstr "使用 Isaac Lab Mimic 生成额外的演示"

#: ../../source/overview/imitation-learning/teleop_imitation.rst:152
msgid "Additional demonstrations can be generated using Isaac Lab Mimic."
msgstr "额外的演示可以使用 Isaac Lab Mimic 生成。"

#: ../../source/overview/imitation-learning/teleop_imitation.rst:154
msgid ""
"Isaac Lab Mimic is a feature in Isaac Lab that allows generation of "
"additional demonstrations automatically, allowing a policy to learn "
"successfully even from just a handful of manual demonstrations."
msgstr ""
"Isaac Lab Mimic 是 Isaac Lab 中的一个功能，允许自动生成额外的示范，从而使得一个策略即使仅通过少量的手动示范也能够成功学习。"

#: ../../source/overview/imitation-learning/teleop_imitation.rst:156
msgid ""
"In the following example, we will show how to use Isaac Lab Mimic to "
"generate additional demonstrations that can be used to train either a state-"
"based policy (using the ``Isaac-Stack-Cube-Franka-IK-Rel-Mimic-v0`` "
"environment) or visuomotor policy (using the ``Isaac-Stack-Cube-Franka-IK-"
"Rel-Visuomotor-Mimic-v0`` environment)."
msgstr ""
"在下面的示例中，我们将展示如何使用Isaac Lab Mimic生成额外的演示，可用于训练基于状态的策略 (使用 ``Isaac-Stack-Cube-"
"Franka-IK-Rel-Mimic-v0`` 环境)或视觉运动策略 (使用 ``Isaac-Stack-Cube-Franka-IK-Rel-"
"Visuomotor-Mimic-v0`` 环境)。"

#: ../../source/overview/imitation-learning/teleop_imitation.rst:161
msgid ""
"All commands in the following sections must keep a consistent policy type. "
"For example, if choosing to use a state-based policy, then all commands used"
" should be from the \"State-based policy\" tab."
msgstr "以下各节中的所有命令必须保持一致的策略类型。例如，如果选择使用基于状态的策略，那么所有使用的命令都应来自 \"基于状态的策略\" 选项卡。"

#: ../../source/overview/imitation-learning/teleop_imitation.rst:163
msgid ""
"In order to use Isaac Lab Mimic with the recorded dataset, first annotate "
"the subtasks in the recording:"
msgstr "为了使用 Isaac Lab Mimic 和录制的数据集，首先在录制中标注子任务:"

#: ../../source/overview/imitation-learning/teleop_imitation.rst
msgid "State-based policy"
msgstr "基于状态的策略"

#: ../../source/overview/imitation-learning/teleop_imitation.rst
msgid "Visuomotor policy"
msgstr "视觉运动策略"

#: ../../source/overview/imitation-learning/teleop_imitation.rst:187
msgid "Then, use Isaac Lab Mimic to generate some additional demonstrations:"
msgstr "然后，使用 Isaac Lab Mimic 生成一些额外的示范:"

#: ../../source/overview/imitation-learning/teleop_imitation.rst:212
msgid ""
"The output_file of the ``annotate_demos.py`` script is the input_file to the"
" ``generate_dataset.py`` script"
msgstr ""
"``annotate_demos.py`` 脚本的 output_file 是 ``generate_dataset.py`` 脚本的 "
"input_file。"

#: ../../source/overview/imitation-learning/teleop_imitation.rst:214
msgid ""
"Inspect the output of generated data (filename: "
"``generated_dataset_small.hdf5``), and if satisfactory, generate the full "
"dataset:"
msgstr "检查生成的数据输出（文件名: ``generated_dataset_small.hdf5`` ），如果满意，生成完整数据集:"

#: ../../source/overview/imitation-learning/teleop_imitation.rst:238
msgid ""
"The number of demonstrations can be increased or decreased, 1000 "
"demonstrations have been shown to provide good training results for this "
"task."
msgstr "展示的数量可以增加或减少，1000 个展示已被证明能够为此任务提供良好的训练结果。"

#: ../../source/overview/imitation-learning/teleop_imitation.rst:240
msgid ""
"Additionally, the number of environments in the ``--num_envs`` parameter can"
" be adjusted to speed up data generation. The suggested number of 10 can be "
"executed on a moderate laptop GPU. On a more powerful desktop machine, use a"
" larger number of environments for a significant speedup of this step."
msgstr ""
"此外，可以调整 ``--num_envs`` 参数中的环境数量，以加快数据生成。建议的数量为10，可以在中等规模的笔记本 GPU "
"上执行。在更强大的台式机上，使用更多的环境可以显著加快这一步的速度。"

#: ../../source/overview/imitation-learning/teleop_imitation.rst:245
msgid "Robomimic setup"
msgstr "Robomimic 设置"

#: ../../source/overview/imitation-learning/teleop_imitation.rst:247
msgid ""
"As an example, we will train a BC agent implemented in `Robomimic "
"<https://robomimic.github.io/>`__ to train a policy. Any other framework or "
"training method could be used."
msgstr ""
"作为一个例子，我们将训练一个在 `Robomimic <https://robomimic.github.io/>`__ 中实现的 BC "
"智能体来训练一个策略。可以使用任何其他框架或训练方法。"

#: ../../source/overview/imitation-learning/teleop_imitation.rst:249
msgid "To install the robomimic framework, use the following commands:"
msgstr "要安装 robomimic 框架，请使用以下命令:"

#: ../../source/overview/imitation-learning/teleop_imitation.rst:259
msgid "Training an agent"
msgstr "训练一个智能体"

#: ../../source/overview/imitation-learning/teleop_imitation.rst:261
msgid ""
"Using the Mimic generated data we can now train a state-based BC agent for "
"``Isaac-Stack-Cube-Franka-IK-Rel-v0``, or a visuomotor BC agent for ``Isaac-"
"Stack-Cube-Franka-IK-Rel-Visuomotor-v0``:"
msgstr ""
"使用Mimic生成的数据，现在我们可以训练一个针对 ``Isaac-Stack-Cube-Franka-IK-Rel-v0`` "
"的基于状态的BC智能体，或者为 ``Isaac-Stack-Cube-Franka-IK-Rel-Visuomotor-v0`` "
"训练一个视觉运动BC智能体: "

#: ../../source/overview/imitation-learning/teleop_imitation.rst:285
#: ../../source/overview/imitation-learning/teleop_imitation.rst:480
msgid ""
"By default the trained models and logs will be saved to "
"``IssacLab/logs/robomimic``."
msgstr "默认情况下，训练的模型和日志将保存到 ``IssacLab/logs/robomimic`` 中。"

#: ../../source/overview/imitation-learning/teleop_imitation.rst:288
msgid "Visualizing results"
msgstr "可视化结果"

#: ../../source/overview/imitation-learning/teleop_imitation.rst:290
msgid ""
"By inferencing using the generated model, we can visualize the results of "
"the policy:"
msgstr "通过使用生成的模型进行推理，我们可以可视化策略的结果:"

#: ../../source/overview/imitation-learning/teleop_imitation.rst:315
msgid "Demo 1: Data Generation and Policy Training for a Humanoid Robot"
msgstr "演示1: 人形机器人的数据生成和策略训练"

#: ../../source/overview/imitation-learning/teleop_imitation.rst:-1
#: ../../source/overview/imitation-learning/teleop_imitation.rst:508
msgid "GR-1 humanoid robot performing a pick and place task"
msgstr "GR-1人形机器人执行拾取和放置任务"

#: ../../source/overview/imitation-learning/teleop_imitation.rst:324
msgid ""
"Isaac Lab Mimic supports data generation for robots with multiple end "
"effectors. In the following demonstration, we will show how to generate data"
" to train a Fourier GR-1 humanoid robot to perform a pick and place task."
msgstr ""
"Isaac Lab Mimic支持对多个末端执行器的机器人生成数据。在以下演示中，我们将展示如何生成数据以训练一个Fourier "
"GR-1人形机器人执行拾取和放置任务。"

#: ../../source/overview/imitation-learning/teleop_imitation.rst:328
msgid "Optional: Collect and annotate demonstrations"
msgstr "可选: 收集和标注演示"

#: ../../source/overview/imitation-learning/teleop_imitation.rst:331
msgid "Collect human demonstrations"
msgstr "收集人类演示"

#: ../../source/overview/imitation-learning/teleop_imitation.rst:334
msgid ""
"Data collection for the GR-1 humanoid robot environment requires use of an "
"Apple Vision Pro headset. If you do not have access to an Apple Vision Pro, "
"you may skip this step and continue on to the next step: `Generate the "
"dataset`_. A pre-recorded annotated dataset is provided in the next step."
msgstr ""
"GR-1人形机器人环境的数据收集需要使用Apple Vision Pro头戴式显示器。如果您无法使用Apple Vision "
"Pro，可以跳过此步骤，直接进入下一步: `生成数据集`_ 。下一步将提供预先录制的带标注数据集。"

#: ../../source/overview/imitation-learning/teleop_imitation.rst:339
msgid ""
"The GR1 scene utilizes the wrist poses from the Apple Vision Pro (AVP) as "
"setpoints for a differential IK controller (Pink-IK). The differential IK "
"controller requires the user's wrist pose to be close to the robot's initial"
" or current pose for optimal performance. Rapid movements of the user's "
"wrist may cause it to deviate significantly from the goal state, which could"
" prevent the IK controller from finding the optimal solution. This may "
"result in a mismatch between the user's wrist and the robot's wrist. You can"
" increase the gain of all the `Pink-IK controller's FrameTasks "
"<https://github.com/isaac-"
"sim/IsaacLab/blob/main/source/isaaclab_tasks/isaaclab_tasks/manager_based/manipulation/pick_place/pickplace_gr1t2_env_cfg.py>`__"
" to track the AVP wrist poses with lower latency. However, this may lead to "
"more jerky motion. Separately, the finger joints of the robot are retargeted"
" to the user's finger joints using the `dex-retargeting "
"<https://github.com/dexsuite/dex-retargeting>`_ library."
msgstr ""
"GR1场景利用Apple Vision Pro (AVP)的手腕姿势作为微分 IK 控制器(Pink-IK)的设定点。微分 IK "
"控制器要求用户的手腕姿势接近机器人的初始或当前姿势，以获得最佳性能。用户的手腕快速移动可能导致其明显偏离目标状态，这可能会阻止 IK "
"控制器找到最佳解决方案。这可能导致用户的手腕和机器人手腕之间存在不匹配。您可以增加所有 `Pink-IK控制器的帧任务 "
"<https://github.com/isaac-"
"sim/IsaacLab/blob/main/source/isaaclab_tasks/isaaclab_tasks/manager_based/manipulation/pick_place/pickplace_gr1t2_env_cfg.py>`__"
" 的增益以以较低的延迟跟踪AVP手腕姿势。但是，这可能会导致更多的抖动运动。另外，机器人的手指关节通过 `dex-retargeting "
"<https://github.com/dexsuite/dex-retargeting>`_ 库重新定位到用户的手指关节。"

#: ../../source/overview/imitation-learning/teleop_imitation.rst:347
msgid ""
"Set up the CloudXR Runtime and Apple Vision Pro for teleoperation by "
"following the steps in :ref:`cloudxr-teleoperation`. CPU simulation is used "
"in the following steps for better XR performance when running a single "
"environment."
msgstr ""
"按照 :ref:`cloudxr-teleoperation` 中的步骤设置CloudXR运行时和Apple Vision "
"Pro以进行远程操作。在运行单个环境时，使用CPU仿真可获得更好的XR性能。"

#: ../../source/overview/imitation-learning/teleop_imitation.rst:350
msgid ""
"Collect a set of human demonstrations. A success demo requires the object to"
" be placed in the bin and for the robot's right arm to be retracted to the "
"starting position."
msgstr "收集一组人类演示。成功的演示需要将物体放置在箱子中，并使机器人的右臂缩回到起始位置。"

#: ../../source/overview/imitation-learning/teleop_imitation.rst:353
msgid ""
"The Isaac Lab Mimic Env GR-1 humanoid robot is set up such that the left "
"hand has a single subtask, while the right hand has two subtasks. The first "
"subtask involves the right hand remaining idle while the left hand picks up "
"and moves the object to the position where the right hand will grasp it. "
"This setup allows Isaac Lab Mimic to interpolate the right hand's trajectory"
" accurately by using the object's pose, especially when poses are randomized"
" during data generation. Therefore, avoid moving the right hand while the "
"left hand picks up the object and brings it to a stable position."
msgstr ""
"Isaac Lab Mimic Env GR-1 人形机器人被设置如下: "
"左手有一个子任务，而右手有两个子任务。第一个子任务是右手保持空闲，左手拾起并移动物体到右手将要抓取的位置。这种设置使得Isaac Lab Mimic "
"能够通过使用物体的姿势准确地插值右手的轨迹，尤其是在数据生成过程中姿势被随机化的情况下。因此，在左手拾起物体并将其带到稳定位置时，请避免移动右手。"

#: ../../source/overview/imitation-learning/teleop_imitation.rst:359
msgid "GR-1 humanoid robot performing a good pick and place demonstration"
msgstr "GR-1 人形机器人完成了一个良好的拾取和放置演示"

#: ../../source/overview/imitation-learning/teleop_imitation.rst:363
msgid "GR-1 humanoid robot performing a bad pick and place demonstration"
msgstr "GR-1 人形机器人完成了一个糟糕的拾取和放置演示"

#: ../../source/overview/imitation-learning/teleop_imitation.rst:367
msgid "|good_demo| |bad_demo|"
msgstr "|good_demo| |bad_demo|"

#: ../../source/overview/imitation-learning/teleop_imitation.rst:371
msgid ""
"Left: A good human demonstration with smooth and steady motion. Right: A bad"
" demonstration with jerky and exaggerated motion."
msgstr "左: 一个演示人类动作流畅稳定的好例子。右: 一个动作生硬夸张的糟糕示范。"

#: ../../source/overview/imitation-learning/teleop_imitation.rst:372
msgid "Collect five demonstrations by running the following command:"
msgstr "通过运行以下命令收集五个演示: "

#: ../../source/overview/imitation-learning/teleop_imitation.rst:384
msgid ""
"We also provide a GR-1 pick and place task with waist degrees-of-freedom "
"enabled ``Isaac-PickPlace-GR1T2-WaistEnabled-Abs-v0`` (see "
":ref:`environments` for details on the available environments, including the"
" GR1 Waist Enabled variant). The same command above applies but with the "
"task name changed to ``Isaac-PickPlace-GR1T2-WaistEnabled-Abs-v0``."
msgstr ""
"我们还提供了一个启用腰部自由度的 GR-1 拾取和放置任务 ``Isaac-PickPlace-GR1T2-WaistEnabled-Abs-v0`` "
"（有关可用环境的详细信息，包括 启用腰部的GR1变体，请参阅 :ref:`environments` ）。适用上述相同的命令，"
"但任务名称更改为 ``Isaac-PickPlace-GR1T2-WaistEnabled-Abs-v0``."

#: ../../source/overview/imitation-learning/teleop_imitation.rst:387
msgid ""
"If a demo fails during data collection, the environment can be reset using "
"the teleoperation controls panel in the XR teleop client on the Apple Vision"
" Pro or via voice control by saying \"reset\". See :ref:`teleoperate-apple-"
"vision-pro` for more details."
msgstr ""
"如果在数据收集过程中演示失败，可以使用Apple Vision Pro上的XR远程操控客户端中的远程操控控制面板或通过说 \"reset\" 来重置环境。查看"
" :ref:`teleoperate-apple-vision-pro` 以获取更多详细信息。"

#: ../../source/overview/imitation-learning/teleop_imitation.rst:390
msgid ""
"The robot uses simplified collision meshes for physics calculations that "
"differ from the detailed visual meshes displayed in the simulation. Due to "
"this difference, you may occasionally observe visual artifacts where parts "
"of the robot appear to penetrate other objects or itself, even though proper"
" collision handling is occurring in the physics simulation."
msgstr ""
"机器人使用简化的碰撞网格进行物理计算，该网格与仿真中显示的详细可视网格不同。由于这种差异，您可能偶尔会观察到可视图中机器人的某些部分似乎穿透其他物体或其自身，尽管在物理仿真中正常处理碰撞。"

#: ../../source/overview/imitation-learning/teleop_imitation.rst:392
msgid ""
"You can replay the collected demonstrations by running the following "
"command:"
msgstr "您可以通过运行以下命令重现收集的演示: "

#: ../../source/overview/imitation-learning/teleop_imitation.rst:406
msgid "Annotate the demonstrations"
msgstr "标注演示"

#: ../../source/overview/imitation-learning/teleop_imitation.rst:408
msgid ""
"Unlike the prior Franka stacking task, the GR-1 pick and place task uses "
"manual annotation to define subtasks."
msgstr "与之前的 Franka 堆叠任务不同，GR-1 拾取和放置任务使用手动标注来定义子任务。"

#: ../../source/overview/imitation-learning/teleop_imitation.rst:410
msgid ""
"The pick and place task has one subtask for the left arm (pick) and two "
"subtasks for the right arm (idle, place). Annotations denote the end of a "
"subtask. For the pick and place task, this means there are no annotations "
"for the left arm and one annotation for the right arm (the end of the final "
"subtask is always implicit)."
msgstr ""
"拾取和放置任务有一个左臂子任务（pick）和两个右臂子任务（idle、place）。 标注表示子任务的结束。 对于"
"拾取和放置任务，这意味着左臂子任务没有标注，右臂子任务有一个标注（最后子任务的结束始终是隐式的）。"

#: ../../source/overview/imitation-learning/teleop_imitation.rst:413
msgid ""
"Each demo requires a single annotation between the first and second subtask "
"of the right arm. This annotation (\"S\" button press) should be done when "
"the right robot arm finishes the \"idle\" subtask and begins to move towards"
" the target object. An example of a correct annotation is shown below:"
msgstr ""
"每个演示都需要在右臂的第一个和第二个子任务之间进行一次单独的标注。此标注( \"S\" 按钮按下)应在右侧机器人手臂完成 \"idle\" "
"子任务并开始朝着目标物体移动时完成。下面显示了一个正确标注的示例: "

#: ../../source/overview/imitation-learning/teleop_imitation.rst:420
msgid "Annotate the demonstrations by running the following command:"
msgstr "通过运行以下命令标注演示: "

#: ../../source/overview/imitation-learning/teleop_imitation.rst:432
msgid ""
"The script prints the keyboard commands for manual annotation and the "
"current subtask being annotated:"
msgstr "脚本打印用于手动标注的键盘命令以及当前正在标注的子任务: "

#: ../../source/overview/imitation-learning/teleop_imitation.rst:448
msgid ""
"If the object does not get placed in the bin during annotation, you can "
"press \"N\" to replay the episode and annotate again. Or you can press \"Q\""
" to skip the episode and annotate the next one."
msgstr "如果在标注过程中物体未放入箱子，则可以按 \"N\" 重新播放该事件并重新标注。或者您可以按 \"Q\" 跳过该事件并标注下一个。"

#: ../../source/overview/imitation-learning/teleop_imitation.rst:451
msgid "Generate the dataset"
msgstr "生成数据集"

#: ../../source/overview/imitation-learning/teleop_imitation.rst:453
msgid ""
"If you skipped the prior collection and annotation step, download the pre-"
"recorded annotated dataset ``dataset_annotated_gr1.hdf5`` from `here "
"<https://omniverse-content-production.s3-us-"
"west-2.amazonaws.com/Assets/Isaac/5.0/Isaac/IsaacLab/Mimic/pick_place_datasets/dataset_annotated_gr1.hdf5>`_."
" Place the file under ``IsaacLab/datasets`` and run the following command to"
" generate a new dataset with 1000 demonstrations."
msgstr ""
"如果您跳过了之前的收集和标注步骤，请从 `此处 <https://omniverse-content-production.s3-us-"
"west-2.amazonaws.com/Assets/Isaac/5.0/Isaac/IsaacLab/Mimic/pick_place_datasets/dataset_annotated_gr1.hdf5>`_"
" 下载预先记录的带标注数据集 ``dataset_annotated_gr1.hdf5`` 。将文件放置在 ``IsaacLab/datasets`` "
"下，并运行以下命令以生成一个包含1000个演示的新数据集。"

#: ../../source/overview/imitation-learning/teleop_imitation.rst:464
#: ../../source/overview/imitation-learning/teleop_imitation.rst:579
msgid "Train a policy"
msgstr "训练一个策略"

#: ../../source/overview/imitation-learning/teleop_imitation.rst:466
msgid ""
"Use `Robomimic <https://robomimic.github.io/>`__ to train a policy for the "
"generated dataset."
msgstr "使用 `Robomimic <https://robomimic.github.io/>`__ 为生成的数据集训练一个策略。"

#: ../../source/overview/imitation-learning/teleop_imitation.rst:475
#: ../../source/overview/imitation-learning/teleop_imitation.rst:590
msgid ""
"The training script will normalize the actions in the dataset to the range "
"[-1, 1]. The normalization parameters are saved in the model directory under"
" ``PATH_TO_MODEL_DIRECTORY/logs/normalization_params.txt``. Record the "
"normalization parameters for later use in the visualization step."
msgstr ""
"训练脚本将标准化数据集中的操作到范围[-1, 1]。标准化参数保存在模型目录下的 "
"``PATH_TO_MODEL_DIRECTORY/logs/normalization_params.txt`` "
"文件中。记录标准化参数以备后续在可视化步骤中使用。"

#: ../../source/overview/imitation-learning/teleop_imitation.rst:483
#: ../../source/overview/imitation-learning/teleop_imitation.rst:600
msgid "Visualize the results"
msgstr "可视化结果"

#: ../../source/overview/imitation-learning/teleop_imitation.rst:485
#: ../../source/overview/imitation-learning/teleop_imitation.rst:602
msgid ""
"Visualize the results of the trained policy by running the following "
"command, using the normalization parameters recorded in the prior training "
"step:"
msgstr "通过运行以下命令，使用之前训练步骤中记录的标准化参数来可视化训练策略的结果: "

#: ../../source/overview/imitation-learning/teleop_imitation.rst:500
#: ../../source/overview/imitation-learning/teleop_imitation.rst:619
msgid ""
"Change the ``NORM_FACTOR`` in the above command with the values generated in"
" the training step."
msgstr "将上述命令中的 ``NORM_FACTOR`` 更改为训练步骤中生成的值。"

#: ../../source/overview/imitation-learning/teleop_imitation.rst:508
msgid "The trained policy performing the pick and place task in Isaac Lab."
msgstr "在 Isaac Lab 中执行拾取和放置任务的训练策略。"

#: ../../source/overview/imitation-learning/teleop_imitation.rst:512
msgid "Demo 2: Visuomotor Policy for a Humanoid Robot"
msgstr "演示 2: 人形机器人的视觉动作策略"

#: ../../source/overview/imitation-learning/teleop_imitation.rst:515
msgid "Download the Dataset"
msgstr "下载数据集"

#: ../../source/overview/imitation-learning/teleop_imitation.rst:517
msgid ""
"Download the pre-generated dataset from `here "
"<https://download.isaacsim.omniverse.nvidia.com/isaaclab/dataset/generated_dataset_gr1_nut_pouring.hdf5>`_"
" and place it under "
"``IsaacLab/datasets/generated_dataset_gr1_nut_pouring.hdf5``. The dataset "
"contains 1000 demonstrations of a humanoid robot performing a "
"pouring/placing task that was generated using Isaac Lab Mimic for the "
"``Isaac-NutPour-GR1T2-Pink-IK-Abs-Mimic-v0`` task."
msgstr ""
"从 `这里 "
"<https://download.isaacsim.omniverse.nvidia.com/isaaclab/dataset/generated_dataset_gr1_nut_pouring.hdf5>`_"
" 下载预生成的数据集，并将其放置在 "
"``IsaacLab/datasets/generated_dataset_gr1_nut_pouring.hdf5`` 下。该数据集包含使用Isaac"
" Lab Mimic为 ``Isaac-NutPour-GR1T2-Pink-IK-Abs-Mimic-v0`` "
"任务生成的一个人形机器人执行倾倒/放置任务的1000次演示。"

#: ../../source/overview/imitation-learning/teleop_imitation.rst:523
msgid ""
"If desired, data collection, annotation, and generation can be done using "
"the same commands as the prior examples."
msgstr "如果需要的话，可以使用与之前示例相同的命令进行数据收集、标注和生成。"

#: ../../source/overview/imitation-learning/teleop_imitation.rst:525
msgid ""
"The robot first picks up the red beaker and pours the contents into the "
"yellow bowl. Then, it drops the red beaker into the blue bin. Lastly, it "
"places the yellow bowl onto the white scale. See the video in the "
":ref:`visualize-results-demo-2` section below for a visual demonstration of "
"the task."
msgstr ""
"机器人首先拿起红色烧杯，将内容物倒入黄色碗中。然后，它将红色烧杯放入蓝色垃圾箱中。最后，它将黄色碗放在白色天平上。请参见下面 "
":ref:`visualize-results-demo-2` 部分的视频，以获取任务的视觉演示。"

#: ../../source/overview/imitation-learning/teleop_imitation.rst:529
msgid ""
"**Note that the following commands are only for your reference and are not "
"required for this demo.**"
msgstr "**注意，以下命令仅供参考，对本演示没有必要。**"

#: ../../source/overview/imitation-learning/teleop_imitation.rst:531
msgid "To collect demonstrations:"
msgstr "收集演示: "

#: ../../source/overview/imitation-learning/teleop_imitation.rst:542
msgid ""
"Since this is a visuomotor environment, the ``--enable_cameras`` flag must "
"be added to the annotation and data generation commands."
msgstr "由于这是一个视觉运动环境，必须将 ``--enable_cameras`` 标志添加到标注和数据生成命令中。"

#: ../../source/overview/imitation-learning/teleop_imitation.rst:544
msgid "To annotate the demonstrations:"
msgstr "标注演示: "

#: ../../source/overview/imitation-learning/teleop_imitation.rst:557
msgid ""
"There are multiple right eef annotations for this task. Annotations for "
"subtasks for the same eef cannot have the same action index. Make sure to "
"annotate the right eef subtasks with different action indices."
msgstr "有多个正确的该任务的eef标注。相同eef的子任务标注不能具有相同的动作索引。确保用不同的动作索引标注正确的eef子任务。"

#: ../../source/overview/imitation-learning/teleop_imitation.rst:561
msgid "To generate the dataset:"
msgstr "生成数据集: "

#: ../../source/overview/imitation-learning/teleop_imitation.rst:581
msgid ""
"Use `Robomimic <https://robomimic.github.io/>`__ to train a visuomotor BC "
"agent for the task."
msgstr "使用 `Robomimic <https://robomimic.github.io/>`__ 来为任务训练视觉动作 BC 智能体。"

#: ../../source/overview/imitation-learning/teleop_imitation.rst:595
msgid ""
"By default the trained models and logs will be saved to "
"``IsaacLab/logs/robomimic``."
msgstr "默认情况下，训练的模型和日志将保存到 ``IssacLab/logs/robomimic`` 中。"

#: ../../source/overview/imitation-learning/teleop_imitation.rst:627
msgid "GR-1 humanoid robot performing a pouring task"
msgstr "GR-1 人形机器人执行倾倒任务"

#: ../../source/overview/imitation-learning/teleop_imitation.rst:627
msgid ""
"The trained visuomotor policy performing the pouring task in Isaac Lab."
msgstr "经过训练的视觉运动策略在Isaac Lab中执行倾倒任务"

#: ../../source/overview/imitation-learning/teleop_imitation.rst:630
msgid "Common Pitfalls when Generating Data"
msgstr "生成数据时常见的陷阱"

#: ../../source/overview/imitation-learning/teleop_imitation.rst:632
msgid "**Demonstrations are too long:**"
msgstr "演示时间太长:"

#: ../../source/overview/imitation-learning/teleop_imitation.rst:634
msgid "Longer time horizon is harder to learn for a policy"
msgstr "更长的时间范围对于策略来说更难学习"

#: ../../source/overview/imitation-learning/teleop_imitation.rst:635
msgid "Start close to the first object and minimize motions"
msgstr "从第一个物体开始，尽量减少运动"

#: ../../source/overview/imitation-learning/teleop_imitation.rst:637
msgid "**Demonstrations are not smooth:**"
msgstr "演示不流畅:"

#: ../../source/overview/imitation-learning/teleop_imitation.rst:639
msgid "Irregular motion is hard for policy to decipher"
msgstr "不规则运动很难被策略解读"

#: ../../source/overview/imitation-learning/teleop_imitation.rst:640
msgid ""
"Better teleop devices result in better data (i.e. SpaceMouse is better than "
"Keyboard)"
msgstr "更好的遥控设备带来更好的数据（即 SpaceMouse 比 Keyboard 更好）"

#: ../../source/overview/imitation-learning/teleop_imitation.rst:642
msgid "**Pauses in demonstrations:**"
msgstr "**演示中的暂停:**"

#: ../../source/overview/imitation-learning/teleop_imitation.rst:644
msgid "Pauses are difficult to learn"
msgstr "暂停是难以学习的"

#: ../../source/overview/imitation-learning/teleop_imitation.rst:645
msgid "Keep the human motions smooth and fluid"
msgstr "保持人类动作平滑流畅"

#: ../../source/overview/imitation-learning/teleop_imitation.rst:647
msgid "**Excessive number of subtasks:**"
msgstr "**过多的子任务:**"

#: ../../source/overview/imitation-learning/teleop_imitation.rst:649
msgid "Minimize the number of defined subtasks for completing a given task"
msgstr "最小化完成给定任务所需定义的子任务数量"

#: ../../source/overview/imitation-learning/teleop_imitation.rst:650
msgid ""
"Less subtacks results in less stitching of trajectories, yielding higher "
"data generation success rate"
msgstr "较少的子任务导致较少的轨迹拼接，从而提高了数据生成成功率"

#: ../../source/overview/imitation-learning/teleop_imitation.rst:652
msgid "**Lack of action noise:**"
msgstr "**缺乏动作噪声:**"

#: ../../source/overview/imitation-learning/teleop_imitation.rst:654
msgid "Action noise makes policies more robust"
msgstr "动作从使策略更加鲁棒"

#: ../../source/overview/imitation-learning/teleop_imitation.rst:656
msgid "**Recording cropped too tight:**"
msgstr "**录制裁剪过于紧密:**"

#: ../../source/overview/imitation-learning/teleop_imitation.rst:658
msgid ""
"If recording stops on the frame the success term triggers, it may not re-"
"trigger during replay"
msgstr "如果录制在成功项触发的帧上停止，则在回放期间可能不会重新触发"

#: ../../source/overview/imitation-learning/teleop_imitation.rst:659
msgid "Allow for some buffer at the end of recording"
msgstr "允许在录制结束时留出一些缓冲区"

#: ../../source/overview/imitation-learning/teleop_imitation.rst:661
msgid "**Non-deterministic replay:**"
msgstr "**非确定性重放:**"

#: ../../source/overview/imitation-learning/teleop_imitation.rst:663
msgid ""
"Physics in IsaacLab are not deterministically reproducible when using "
"``env.reset`` so demonstrations may fail on replay"
msgstr "在 IsaacLab 中，使用 ``env.reset`` 时，物理仿真无法确定性地复现，因此在回放时，演示可能会失败。"

#: ../../source/overview/imitation-learning/teleop_imitation.rst:664
msgid ""
"Collect more human demos than needed, use the ones that succeed during "
"annotation"
msgstr "收集比所需更多的人类演示，使用在标注过程中成功的那些"

#: ../../source/overview/imitation-learning/teleop_imitation.rst:665
msgid ""
"All data in Isaac Lab Mimic generated HDF5 file represent a successful demo "
"and can be used for training (even if non-determinism causes failure when "
"replayed)"
msgstr ""
"所有在 Isaac Lab Mimic 生成的 HDF5 文件中的数据都代表一个成功的演示，并且可以用于训练（即使非确定性在重放时导致失败）。"

#: ../../source/overview/imitation-learning/teleop_imitation.rst:669
msgid "Creating Your Own Isaac Lab Mimic Compatible Environments"
msgstr "创建您自己的 Isaac Lab Mimic 兼容环境"

#: ../../source/overview/imitation-learning/teleop_imitation.rst:672
msgid "How it works"
msgstr "它是如何工作的"

#: ../../source/overview/imitation-learning/teleop_imitation.rst:674
msgid ""
"Isaac Lab Mimic works by splitting the input demonstrations into subtasks. "
"Subtasks are user-defined segments in the demonstrations that are common to "
"all demonstrations. Examples for subtasks are \"grasp an object\", \"move "
"end effector to some pre-defined position\", \"release object\" etc.. Note "
"that most subtasks are defined with respect to some object that the robot "
"interacts with."
msgstr ""
"Isaac Lab Mimic 通过将输入的示范分割成子任务来工作。子任务是示范中用户定义的、在所有示范中共有的片段。子任务的例子包括 \"抓取物体\""
" 、 \"将末端执行器移动到某个预定义位置\" 、 \"释放物体\" 等等。请注意，大多数子任务是相对于机器人与之交互的某个物体来定义的。"

#: ../../source/overview/imitation-learning/teleop_imitation.rst:676
msgid ""
"Subtasks need to be defined, and then annotated for each input "
"demonstration. Annotation can either happen algorithmically by defining "
"heuristics for subtask detection, as was done in the example above, or it "
"can be done manually."
msgstr ""
"子任务需要被定义，然后为每个输入示例添加标注。标注可以通过定义用于子任务检测的启发式算法来实现，如上面示例中所做的那样，或者也可以手动完成。"

#: ../../source/overview/imitation-learning/teleop_imitation.rst:678
msgid ""
"With subtasks defined and annotated, Isaac Lab Mimic utilizes a small number"
" of helper methods to then transform the subtask segments, and generate new "
"demonstrations by stitching them together to match the new task at hand."
msgstr ""
"定义并标注了子任务后，Isaac Lab Mimic 利用少量辅助方法来转换子任务片段，并通过将它们拼接在一起生成新的演示，以匹配当前的任务。"

#: ../../source/overview/imitation-learning/teleop_imitation.rst:680
#, python-format
msgid ""
"For each thusly generated candidate demonstration, Isaac Lab Mimic uses a "
"boolean success criteria to determine whether the demonstration succeeded in"
" performing the task, and if so, add it to the output dataset. Success rate "
"of candidate demonstrations can be as high as 70% in simple cases, and as "
"low as <1%, depending on the difficulty of the task, and the complexity of "
"the robot itself."
msgstr ""
"对于每个这样生成的候选演示，Isaac Lab Mimic "
"使用布尔成功标准来判断演示是否成功执行任务，如果成功，则将其添加到输出数据集。候选演示的成功率在简单情况下可以高达 "
"70%，而在复杂任务和机器人本身的复杂性影响下，成功率可能低于 1%。"

#: ../../source/overview/imitation-learning/teleop_imitation.rst:683
msgid "Configuration and subtask definition"
msgstr "配置和子任务定义"

#: ../../source/overview/imitation-learning/teleop_imitation.rst:685
msgid ""
"Subtasks, among other configuration settings for Isaac Lab Mimic, are "
"defined in a Mimic compatible environment configuration class that is "
"created by extending the existing environment config with additional Mimic "
"required parameters."
msgstr ""
"子任务，除了 Isaac Lab Mimic 的其他配置设置外，还在 Mimic 兼容的环境配置类中定义，该类通过扩展现有的环境配置并加入额外的 "
"Mimic 所需参数来创建。"

#: ../../source/overview/imitation-learning/teleop_imitation.rst:687
msgid ""
"All Mimic required config parameters are specified in the "
":class:`~isaaclab.envs.MimicEnvCfg` class."
msgstr "所有 Mimic 所需的配置参数都在 :class:`~isaaclab.envs.MimicEnvCfg` 类中指定。"

#: ../../source/overview/imitation-learning/teleop_imitation.rst:689
msgid ""
"The config class "
":class:`~isaaclab_mimic.envs.FrankaCubeStackIKRelMimicEnvCfg` serves as an "
"example of creating a Mimic compatible environment config class for the "
"Franka stacking task that was used in the examples above."
msgstr ""
"配置类 :class:`~isaaclab_mimic.envs.FrankaCubeStackIKRelMimicEnvCfg` "
"作为一个示例，用于创建一个与 Mimic 兼容的环境配置类，适用于上面示例中使用的 Franka 堆叠任务。"

#: ../../source/overview/imitation-learning/teleop_imitation.rst:691
msgid ""
"The ``DataGenConfig`` member contains various parameters that influence how "
"data is generated. It is initially sufficient to just set the ``name`` "
"parameter, and revise the rest later."
msgstr "``DataGenConfig`` 成员包含各种影响数据生成的参数。最初只需要设置 ``name`` 参数，其他的可以稍后修改。"

#: ../../source/overview/imitation-learning/teleop_imitation.rst:693
msgid ""
"Subtasks are a list of :class:`~isaaclab.envs.SubTaskConfig` objects, of "
"which the most important members are:"
msgstr "子任务是一个 :class:`~isaaclab.envs.SubTaskConfig` 对象的列表，其中最重要的成员是:"

#: ../../source/overview/imitation-learning/teleop_imitation.rst:695
msgid ""
"``object_ref`` is the object that is being interacted with. This will be "
"used to adjust motions relative to this object during data generation. Can "
"be ``None`` if the current subtask does not involve any object."
msgstr ""
"``object_ref`` 是正在交互的对象。它将用于在数据生成过程中相对于该对象调整动作。如果当前子任务不涉及任何对象，则可以是 ``None`` "
"。"

#: ../../source/overview/imitation-learning/teleop_imitation.rst:696
msgid ""
"``subtask_term_signal`` is the ID of the signal indicating whether the "
"subtask is active or not."
msgstr "``subtask_term_signal`` 是指示子任务是否处于活动状态的信号的 ID。"

#: ../../source/overview/imitation-learning/teleop_imitation.rst:698
msgid ""
"For multi end-effector environments, subtask ordering between end-effectors "
"can be enforced by specifying subtask constraints. These constraints are "
"defined in the :class:`~isaaclab.envs.SubTaskConstraintConfig` class."
msgstr ""
"对于具有多个末端执行器的环境，可以通过指定子任务约束来强制定义末端执行器之间的子任务顺序。这些约束在 "
":class:`~isaaclab.envs.SubTaskConstraintConfig` 类中定义。"

#: ../../source/overview/imitation-learning/teleop_imitation.rst:701
msgid "Subtask annotation"
msgstr "子任务标注"

#: ../../source/overview/imitation-learning/teleop_imitation.rst:703
msgid ""
"Once the subtasks are defined, they need to be annotated in the source data."
" There are two methods to annotate source demonstrations for subtask "
"boundaries: Manual annotation or using heuristics."
msgstr "一旦子任务被定义，它们需要在源数据中进行标注。有两种方法可以标注源示范的子任务边界: 手动标注或使用启发式方法。"

#: ../../source/overview/imitation-learning/teleop_imitation.rst:705
msgid ""
"It is often easiest to perform manual annotations, since the number of input"
" demonstrations is usually very small. To perform manual annotations, use "
"the ``annotate_demos.py`` script without the ``--auto`` flag. Then press "
"``B`` to pause, ``N`` to continue, and ``S`` to annotate a subtask boundary."
msgstr ""
"通常手动标注是最简单的，因为输入示例的数量通常非常少。要执行手动标注，请使用 ``annotate_demos.py`` 脚本，且不带 "
"``--auto`` 标志。然后按 ``B`` 暂停，按 ``N`` 继续，按 ``S`` 标注子任务边界。"

#: ../../source/overview/imitation-learning/teleop_imitation.rst:707
msgid ""
"For more accurate boundaries, or to speed up repeated processing of a given "
"task for experiments, heuristics can be implemented to perform the same "
"task. Heuristics are observations in the environment. An example how to add "
"subtask terms can be found in "
"``source/isaaclab_tasks/isaaclab_tasks/manager_based/manipulation/stack/stack_env_cfg.py``,"
" where they are added as an observation group called ``SubtaskCfg``. This "
"example is using prebuilt heuristics, but custom heuristics are easily "
"implemented."
msgstr ""
"为了更精确的边界，或为了加速对给定任务的重复处理以进行实验，可以实现启发式方法来执行相同的任务。启发式方法是对环境中的观测。如何添加子任务项的示例可以在"
" "
"``source/isaaclab_tasks/isaaclab_tasks/manager_based/manipulation/stack/stack_env_cfg.py``"
" 中找到，其中它们作为一个观测组被添加，名为 ``SubtaskCfg`` 。这个示例使用了预构建的启发式方法，但自定义启发式方法也很容易实现。"

#: ../../source/overview/imitation-learning/teleop_imitation.rst:711
msgid "Helpers for demonstration generation"
msgstr "生成演示的帮助程序"

#: ../../source/overview/imitation-learning/teleop_imitation.rst:713
msgid ""
"Helpers needed for Isaac Lab Mimic are defined in the environment. All tasks"
" that are to be used with Isaac Lab Mimic are derived from the "
":class:`~isaaclab.envs.ManagerBasedRLMimicEnv` base class, and must "
"implement the following functions:"
msgstr ""
"在 Isaac Lab Mimic 中需要的帮助程序是在环境中定义的。所有要与 Isaac Lab Mimic 一起使用的任务都源自 "
":class:`~isaaclab.envs.ManagerBasedRLMimicEnv` 基类，并且必须实现以下功能:"

#: ../../source/overview/imitation-learning/teleop_imitation.rst:715
msgid ""
"``get_robot_eef_pose``: Returns the current robot end effector pose in the "
"same frame as used by the robot end effector controller."
msgstr "``get_robot_eef_pose``: 返回当前机器人末端执行器姿态，该姿态与机器人末端执行器控制器使用的坐标系相同。"

#: ../../source/overview/imitation-learning/teleop_imitation.rst:717
msgid ""
"``target_eef_pose_to_action``: Takes a target pose and a gripper action for "
"the end effector controller and returns an action which achieves the target "
"pose."
msgstr ""
"``target_eef_pose_to_action``: 获取目标姿态和夹爪动作，供末端执行器控制器使用，并返回一个能够实现目标姿态的动作。"

#: ../../source/overview/imitation-learning/teleop_imitation.rst:719
msgid ""
"``action_to_target_eef_pose``: Takes an action and returns a target pose for"
" the end effector controller."
msgstr "``action_to_target_eef_pose``: 采取一个动作并返回末端执行器控制器的目标姿态。"

#: ../../source/overview/imitation-learning/teleop_imitation.rst:721
msgid ""
"``actions_to_gripper_actions``: Takes a sequence of actions and returns the "
"gripper actuation part of the actions."
msgstr "``actions_to_gripper_actions``: 接收一系列动作，并返回动作中的夹爪执行器部分。"

#: ../../source/overview/imitation-learning/teleop_imitation.rst:723
msgid ""
"``get_object_poses``: Returns the pose of each object in the scene that is "
"used for data generation."
msgstr "``get_object_poses``: 返回场景中用于数据生成的每个对象的姿势。"

#: ../../source/overview/imitation-learning/teleop_imitation.rst:725
msgid ""
"``get_subtask_term_signals``: Returns a dictionary of binary flags for each "
"subtask in a task. The flag of true is set when the subtask has been "
"completed and false otherwise."
msgstr ""
"``get_subtask_term_signals``: 返回一个字典，包含任务中每个子任务的二进制标志。当子任务已完成时，标志为 true，否则为 "
"false。"

#: ../../source/overview/imitation-learning/teleop_imitation.rst:727
msgid ""
"The class :class:`~isaaclab_mimic.envs.FrankaCubeStackIKRelMimicEnv` shows "
"an example of creating a Mimic compatible environment from an existing Isaac"
" Lab environment."
msgstr ""
"该类 :class:`~isaaclab_mimic.envs.FrankaCubeStackIKRelMimicEnv` 展示了如何从现有的 "
"Isaac Lab 环境创建一个 Mimic 兼容的环境。"

#: ../../source/overview/imitation-learning/teleop_imitation.rst:730
msgid "Registering the environment"
msgstr "注册环境"

#: ../../source/overview/imitation-learning/teleop_imitation.rst:732
msgid ""
"Once both Mimic compatible environment and environment config classes have "
"been created, a new Mimic compatible environment can be registered using "
"``gym.register``. For the Franka stacking task in the examples above, the "
"Mimic environment is registered as ``Isaac-Stack-Cube-Franka-IK-Rel-"
"Mimic-v0``."
msgstr ""
"一旦创建了兼容 Mimic 的环境和环境配置类，就可以使用 ``gym.register`` 注册一个新的 Mimic 兼容环境。对于上面示例中的 "
"Franka 堆叠任务，Mimic 环境被注册为 ``Isaac-Stack-Cube-Franka-IK-Rel-Mimic-v0`` 。"

#: ../../source/overview/imitation-learning/teleop_imitation.rst:734
msgid ""
"The registered environment is now ready to be used with Isaac Lab Mimic."
msgstr "注册的环境现在已准备好与 Isaac Lab Mimic 一起使用。"

#: ../../source/overview/imitation-learning/teleop_imitation.rst:738
msgid "Tips for Successful Data Generation with Isaac Lab Mimic"
msgstr "成功使用 Isaac Lab Mimic 进行数据生成的技巧"

#: ../../source/overview/imitation-learning/teleop_imitation.rst:741
msgid "Splitting subtasks"
msgstr "划分子任务"

#: ../../source/overview/imitation-learning/teleop_imitation.rst:743
msgid ""
"A general rule of thumb is to split the task into as few subtasks as "
"possible, while still being able to complete the task. Isaac Lab Mimic data "
"generation uses linear interpolation to bridge and stitch together subtask "
"segments. More subtasks result in more stitching of trajectories which can "
"result in less smooth motions and more failed demonstrations. For this "
"reason, it is often best to annoatate subtask boundaries where the robot's "
"motion is unlikely to collide with other objects."
msgstr ""
"一个基本的经验法则是把任务分解为尽可能少的子任务，同时仍能完成任务。Isaac Lab "
"Mimic数据生成使用线性插值来连接和拼接子任务段。更多的子任务会导致轨迹的拼接更多，这可能导致动作更不平滑，演示失败的可能性更大。因此，通常最好在机器人的运动不太可能与其他物体相撞的地方标记子任务边界。"

#: ../../source/overview/imitation-learning/teleop_imitation.rst:746
msgid ""
"For example, in the scenario below, there is a subtask partition after the "
"robot's left arm grasps the object. On the left, the subtask annotation is "
"marked immediately after the grasp, while on the right, the annotation is "
"marked after the robot has grasped and lifted the object. In the left case, "
"the interpolation causes the robot's left arm to collide with the table and "
"it's motion lags while on the right the motion is continuous and smooth."
msgstr ""
"例如，在下面的情况中，机器人的左臂抓取物体后有一个子任务分区。在左侧，子任务标注在抓取后立即标记，而在右侧，在机器人抓取并提起物体后标记标注。在左侧情况下，插值导致机器人的左臂与桌子碰撞，并且它的运动延迟，而在右侧，运动是连续和平滑的。"

#: ../../source/overview/imitation-learning/teleop_imitation.rst:-1
msgid "Subtask splitting example"
msgstr "子任务拆分示例"

#: ../../source/overview/imitation-learning/teleop_imitation.rst:757
msgid "Motion lag/collision caused by poor subtask splitting (left)"
msgstr "由于不良子任务分割造成的运动延迟/碰撞（向左）"

#: ../../source/overview/imitation-learning/teleop_imitation.rst:759
msgid "Selecting number of interpolation steps"
msgstr "选择插值步数"

#: ../../source/overview/imitation-learning/teleop_imitation.rst:761
msgid ""
"The number of interpolation steps between subtask segments can be specified "
"in the :class:`~isaaclab.envs.SubTaskConfig` class. Once transformed, the "
"subtask segments don't start/end at the same spot, thus to create a "
"continuous motion, Isaac Lab Mimic will apply linear interpolation between "
"the last point of the previous subtask and the first point of the next "
"subtask."
msgstr ""
"在 :class:`~isaaclab.envs.SubTaskConfig` "
"类中可以指定子任务段之间的插值步数。转换后，子任务段不会在同一位置开始/结束，因此为了创建连续运动，Isaac Lab Mimic "
"将在前一个子任务的最后一个点和下一个子任务的第一个点之间应用线性插值。"

#: ../../source/overview/imitation-learning/teleop_imitation.rst:764
msgid ""
"The number of interpolation steps can be tuned to control the smoothness of "
"the generated demonstrations during this stitching process. The appropriate "
"number of interpolation steps depends on the speed of the robot and the "
"complexity of the task. A complex task with a large object reset "
"distribution will have larger gaps between subtask segments and require more"
" interpolation steps to create a smooth motion. Alternatively, a task with "
"small gaps between subtask segments should use a small number of "
"interpolation steps to avoid unnecessary motion lag caused by too many "
"steps."
msgstr ""
"插值步数的数量可以调整，以控制在这个拼接过程中生成的演示的平滑度。适当的插值步数取决于机器人的速度和任务的复杂性。具有较大物体重置分布的复杂任务将在子任务段之间具有更大的间隙，并需要更多的插值步骤来创建平滑运动。另外，对于子任务段之间间隔较小的任务，应该使用较少的插值步骤，以避免由于过多步骤导致的不必要的动作延迟。"

#: ../../source/overview/imitation-learning/teleop_imitation.rst:768
msgid ""
"An example of how the number of interpolation steps can affect the generated"
" demonstrations is shown below. In the example, an interpolation is applied "
"to the right arm of the robot to bridge the gap between the left arm's grasp"
" and the right arm's placement. With 0 steps, the right arm exhibits a jerky"
" jump in motion while with 20 steps, the motion is laggy. With 5 steps, the "
"motion is smooth and natural."
msgstr ""
"以下显示了插值步数如何影响生成的演示示例。在这个示例中，将对机器人的右臂进行插值，以弥合左臂抓取和右臂放置之间的差距。在0步的情况下，右臂在运动中出现突然跳跃，而在20步的情况下，运动会显得延迟。在5步的情况下，运动是平滑而自然的。"

#: ../../source/overview/imitation-learning/teleop_imitation.rst:772
msgid "GR-1 robot with 0 interpolation steps"
msgstr "GR-1 机器人，0 插值步骤"

#: ../../source/overview/imitation-learning/teleop_imitation.rst:776
msgid "GR-1 robot with 5 interpolation steps"
msgstr "GR-1 机器人，5 个插补步骤"

#: ../../source/overview/imitation-learning/teleop_imitation.rst:780
msgid "GR-1 robot with 20 interpolation steps"
msgstr "GR-1 机器人，20 个插值步骤"

#: ../../source/overview/imitation-learning/teleop_imitation.rst:784
msgid "|0_interp_steps| |5_interp_steps| |20_interp_steps|"
msgstr "|0_interp_steps| |5_interp_steps| |20_interp_steps|"

#: ../../source/overview/imitation-learning/teleop_imitation.rst:786
msgid "Left: 0 steps. Middle: 5 steps. Right: 20 steps."
msgstr "左侧: 0 步。中间: 5 步。右侧: 20 步。"
