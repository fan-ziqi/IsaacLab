# SOME DESCRIPTIVE TITLE.
# Copyright (C) 2022-2024, The Isaac Lab Project Developers.
# This file is distributed under the same license as the Isaac Lab package.
# FIRST AUTHOR <EMAIL@ADDRESS>, 2024.
msgid ""
msgstr ""
"Project-Id-Version: Isaac Lab 1.3.0\n"
"Report-Msgid-Bugs-To: \n"
"POT-Creation-Date: 2024-11-28 10:51+0800\n"
"PO-Revision-Date: YEAR-MO-DA HO:MI+ZONE\n"
"Last-Translator: Ziqi Fan <fanziqi614@gmail.com>\n"
"Language-Team: zh_CN <LL@li.org>\n"
"Language: zh_CN\n"
"MIME-Version: 1.0\n"
"Content-Type: text/plain; charset=utf-8\n"
"Content-Transfer-Encoding: 8bit\n"
"Plural-Forms: nplurals=1; plural=0;\n"
"Generated-By: Babel 2.16.0\n"

#: ../../source/overview/sensors/ray_caster.rst:4
msgid "Ray Caster"
msgstr "光线投射"

#: ../../source/overview/sensors/ray_caster.rst:-1
msgid "A diagram outlining the basic geometry of frame transformations"
msgstr "一个概述框架变换基本几何的图示"

#: ../../source/overview/sensors/ray_caster.rst:11
msgid ""
"The Ray Caster sensor (and the ray caster camera) are similar to RTX based "
"rendering in that they both involve casting rays.  The difference here is "
"that the rays cast by the Ray Caster sensor return strictly collision "
"information along the cast, and the direction of each individual ray can be "
"specified.  They do not bounce, nor are they affected by things like "
"materials or opacity. For each ray specified by the sensor, a line is traced"
" along the path of the ray and the location of first collision with the "
"specified mesh is returned. This is the method used by some of our quadruped"
" examples to measure the local height field."
msgstr ""
"Ray Caster传感器（以及ray caster相机）与基于RTX的渲染类似，二者都涉及到射线投射。不同之处在于，Ray "
"Caster传感器投射的射线严格返回沿投射路径的碰撞信息，并且每条射线的方向可以被指定。它们不会反弹，也不受材质或不透明度等因素的影响。对于传感器指定的每条射线，会沿射线路径追踪一条线，并返回与指定网格的第一次碰撞位置。这是我们的一些四足动物示例中用于测量局部高度场的方法。"

#: ../../source/overview/sensors/ray_caster.rst:13
msgid ""
"To keep the sensor performant when there are many cloned environments, the "
"line tracing is done directly in `Warp <https://nvidia.github.io/warp/>`_. "
"This is the reason why specific meshes need to be identified to cast "
"against: that mesh data is loaded onto the device by warp when the sensor is"
" initialized. As a consequence, the current iteration of this sensor only "
"works for literally static meshes (meshes that *are not changed from the "
"defaults specified in their USD file*).  This constraint will be removed in "
"future releases."
msgstr ""
"为了保持传感器在有多个克隆环境时的性能，线条追踪直接在 `Warp <https://nvidia.github.io/warp/>`_ "
"中完成。这就是为什么需要识别特定网格以进行碰撞的原因：当传感器初始化时，warp "
"会将这些网格数据加载到设备上。因此，当前版本的传感器仅适用于字面上的静态网格（即 *那些没有从其 USD 文件中指定的默认值发生变化的* "
"网格）。这个限制将在未来的版本中移除。"

#: ../../source/overview/sensors/ray_caster.rst:15
msgid ""
"Using a ray caster sensor requires a **pattern** and a parent xform to be "
"attached to.  The pattern defines how the rays are cast, while the prim "
"properties defines the orientation and position of the sensor (additional "
"offsets can be specified for more exact placement).  Isaac Lab supports a "
"number of ray casting pattern configurations, including a generic LIDAR and "
"grid pattern."
msgstr ""
"使用光线投射传感器需要附加一个 **模式** 和一个父级 xform。模式定义了光线如何投射，而 prim "
"属性定义了传感器的方向和位置（可以指定额外的偏移量以实现更精确的放置）。Isaac Lab 支持多种光线投射模式配置，包括通用的 LIDAR "
"和网格模式。"

#: ../../source/overview/sensors/ray_caster.rst:54
msgid ""
"Notice that the units on the pattern config is in degrees! Also, we enable "
"visualization here to explicitly show the pattern in the rendering, but this"
" is not required and should be disabled for performance tuning."
msgstr "注意，模式配置上的单位是以度为单位！另外，我们在这里启用了可视化功能，以便在渲染中明确显示模式，但这不是必需的，并且在性能调优时应该禁用。"

#: ../../source/overview/sensors/ray_caster.rst:-1
msgid "Lidar Pattern visualized"
msgstr "激光雷达模式可视化"

#: ../../source/overview/sensors/ray_caster.rst:61
msgid ""
"Querying the sensor for data can be done at simulation run time like any "
"other sensor."
msgstr "查询传感器的数据可以像其他传感器一样在仿真运行时进行。"

#: ../../source/overview/sensors/ray_caster.rst:99
msgid ""
"Here we can see the data returned by the sensor itself.  Notice first that "
"there are 3 closed brackets at the beginning and the end: this is because "
"the data returned is batched by the number of sensors. The ray cast pattern "
"itself has also been flattened, and so the dimensions of the array are ``[N,"
" B, 3]`` where ``N`` is the number of sensors, ``B`` is the number of cast "
"rays in the pattern, and 3 is the dimension of the casting space. Finally, "
"notice that the first several values in this casting pattern are the same: "
"this is because the lidar pattern is spherical and we have specified our FOV"
"  to be hemispherical, which includes the poles. In this configuration, the "
"\"flattening pattern\" becomes apparent: the first 180 entries will be the "
"same because it's the bottom pole of this hemisphere, and there will be 180 "
"of them because our horizontal FOV is 180 degrees with a resolution of 1 "
"degree."
msgstr ""
"在这里，我们可以看到传感器本身返回的数据。首先请注意，开始和结束处有 3 "
"个闭括号：这是因为返回的数据是按传感器的数量进行分批的。射线投射模式本身也已经被压平，因此数组的维度是 ``[N, B, 3]``，其中 ``N`` "
"是传感器的数量，``B`` 是模式中投射的射线数量，3 是投射空间的维度。最后，请注意，这个投射模式中的前几个值是相同的：这是因为 lidar "
"模式是球形的，我们已将视场（FOV）指定为半球形，这包括了极点。在这种配置下， \"压平模式\" 变得显而易见：前 180 "
"个条目将是相同的，因为它是该半球的底极，并且会有 180 个条目，因为我们的水平视场是 180 度，分辨率为 1 度。"

#: ../../source/overview/sensors/ray_caster.rst:101
msgid ""
"You can use this script to experiment with pattern configurations and build "
"an intuition about how the data is stored by altering the ``triggered`` "
"variable on line 99."
msgstr "您可以使用此脚本来实验不同的模式配置，并通过修改第 99 行的 ``triggered`` 变量来建立对数据存储方式的直觉。"

#: ../../source/overview/sensors/ray_caster.rst
msgid "Code for raycaster_sensor.py"
msgstr "raycaster_sensor.py 的代码"
