# SOME DESCRIPTIVE TITLE.
# Copyright (C) 2022-2024, The Isaac Lab Project Developers.
# This file is distributed under the same license as the Isaac Lab package.
# FIRST AUTHOR <EMAIL@ADDRESS>, 2024.
msgid ""
msgstr ""
"Project-Id-Version: Isaac Lab 1.3.0\n"
"Report-Msgid-Bugs-To: \n"
"POT-Creation-Date: 2025-01-10 11:12+0800\n"
"PO-Revision-Date: YEAR-MO-DA HO:MI+ZONE\n"
"Last-Translator: Ziqi Fan <fanziqi614@gmail.com>\n"
"Language-Team: zh_CN <LL@li.org>\n"
"Language: zh_CN\n"
"MIME-Version: 1.0\n"
"Content-Type: text/plain; charset=utf-8\n"
"Content-Transfer-Encoding: 8bit\n"
"Plural-Forms: nplurals=1; plural=0;\n"
"Generated-By: Babel 2.16.0\n"

#: ../../source/overview/sensors/camera.rst:5
msgid "Camera"
msgstr "相机"

#: ../../source/overview/sensors/camera.rst:7
msgid ""
"Camera sensors are uniquely defined by the use of the ``render_product``, a "
"structure for managing data generated by the rendering pipeline (images). "
"Isaac Lab provides the ability to fully control how these renderings are "
"created through camera parameters like focal length, pose, type, etc... and "
"what kind of data you want to render through the use of Annotators, allowing"
" you to record not only RGB, but also Instance segmentation, object pose, "
"object ID, etc..."
msgstr ""
"相机传感器通过使用 ``render_product`` 独特地定义，这是一个用于管理渲染管道（图像）生成的数据的结构。Isaac Lab "
"提供了完全控制这些渲染如何通过相机参数（如焦距、姿态、类型等）创建的能力，以及通过使用 "
"Annotators，您可以控制希望渲染的数据类型，允许您记录不仅是 RGB 数据，还包括实例分割、物体姿态、物体 ID 等数据。"

#: ../../source/overview/sensors/camera.rst:9
msgid ""
"Rendered images are unique among the supported data types in Isaac Lab due "
"to the inherently large bandwidth requirements for moving those data. A "
"single 800 x 600 image with 32-bit color (a single float per pixel) clocks "
"in at just under 2 MB. If we render at 60 fps and record every frame, that "
"camera needs to move 120 MB/s. Multiply this by the number of cameras in an "
"environment and environments in a simulation, and you can quickly see how "
"scaling a naive vectorization of camera data could lead to bandwidth "
"challenges. NVIDIA's Isaac Lab leverages our expertise in GPU hardware to "
"provide an API that specifically addresses these scaling challenges in the "
"rendering pipeline."
msgstr ""
"渲染的图像在 Isaac Lab 中是唯一的数据类型，因为这些数据的移动具有固有的较大带宽要求。单个 800 x 600 像素、32 "
"位色彩（每个像素一个浮动点）的图像大小接近 2 MB。如果我们以每秒 60 帧的速度渲染并记录每一帧，那么该相机需要以 120 MB/s "
"的速度传输数据。将此值乘以环境中的相机数量和模拟中的环境数量，您可以快速看出，简单地向量化相机数据可能会导致带宽瓶颈。`NVIDIA` 的 `Isaac"
" Sim` 利用我们在 GPU 硬件方面的专业知识，提供了一个专门解决渲染管线中这些扩展挑战的 API。"

#: ../../source/overview/sensors/camera.rst:12
msgid "Tiled Rendering"
msgstr "分块渲染"

#: ../../source/overview/sensors/camera.rst:16
msgid "This feature is only available from Isaac Sim version 4.2.0 onwards."
msgstr "此功能仅适用于 Isaac Sim 版本 4.2.0 及更高版本。"

#: ../../source/overview/sensors/camera.rst:18
msgid ""
"Tiled rendering in combination with image processing networks require heavy "
"memory resources, especially at larger resolutions. We recommend running 512"
" cameras in the scene on RTX 4090 GPUs or similar."
msgstr ""
"分块渲染结合图像处理网络需要大量的内存资源，尤其是在更大分辨率下。我们建议在场景中使用 512 个相机，并配备 RTX 4090 `GPU` "
"或类似的硬件。"

#: ../../source/overview/sensors/camera.rst:21
msgid ""
"The Tiled Rendering APIs provide a vectorized interface for collecting data "
"from camera sensors. This is useful for reinforcement learning environments "
"where parallelization can be exploited to accelerate data collection and "
"thus the training loop. Tiled rendering works by using a single "
"``render_product`` for **all** clones of a single camera in the scene. The "
"desired dimensions of a single image and the number of environments are used"
" to compute a much larger ``render_product``, consisting of the tiled "
"individual renders from the separate clones of the camera. When all cameras "
"have populated their buffers the render product is \"completed\" and can be "
"moved around as a single, large image, dramatically reducing the overhead "
"for moving the data from the host to the device, for example.  Only a single"
" call is used to synchronize the device data, instead of one call per "
"camera, and this is a big part of what makes the Tiled Rendering API more "
"efficient for working with vision data."
msgstr ""
"分块渲染 API "
"提供了一个向量化接口，用于从相机传感器收集数据。这对于强化学习环境非常有用，在这种环境中，可以利用并行化加速数据收集，从而加速训练循环。分块渲染通过使用一个单一的"
" ``render_product`` 来为场景中单个相机的 **所有** 克隆进行操作。单个图像的期望尺寸和环境的数量被用来计算一个更大的 "
"``render_product``，该产品由相机各个克隆的独立渲染组成。 当所有相机都填充完其缓冲区后，渲染产品便 \"完成\" "
"，可以作为一个单一的、大尺寸的图像进行移动，从而大幅减少将数据从主机传输到设备时的开销，例如。只使用一个调用来同步设备数据，而不是每个相机一个调用，这正是分块渲染"
" API 在处理视觉数据时更高效的一个重要原因。"

#: ../../source/overview/sensors/camera.rst:23
msgid ""
"Isaac Lab provides tiled rendering APIs for RGB, depth, along with other "
"annotators through the :class:`~sensors.TiledCamera` class. Configurations "
"for the tiled rendering APIs can be defined through the "
":class:`~sensors.TiledCameraCfg` class, specifying parameters such as the "
"regex expression for all camera paths, the transform for the cameras, the "
"desired data type, the type of cameras to add to the scene, and the camera "
"resolution."
msgstr ""
"Isaac Lab 提供了用于 RGB、深度和其他注释器的分块渲染 API，您可以通过 :class:`~sensors.TiledCamera` "
"类来使用这些 API。分块渲染 API 的配置可以通过 :class:`~sensors.TiledCameraCfg` "
"类定义，指定的参数包括所有相机路径的正则表达式、相机的变换、所需的数据类型、要添加到场景中的相机类型以及相机分辨率。"

#: ../../source/overview/sensors/camera.rst:38
msgid ""
"To access the tiled rendering interface, a :class:`~sensors.TiledCamera` "
"object can be created and used to retrieve data from the cameras."
msgstr "要访问分块渲染接口，可以创建一个 :class:`~sensors.TiledCamera` 对象，并用其从相机获取数据。"

#: ../../source/overview/sensors/camera.rst:46
msgid ""
"The returned data will be transformed into the shape (num_cameras, height, "
"width, num_channels), which can be used directly as observation for "
"reinforcement learning."
msgstr ""
"返回的数据将被转换为形状 (num_cameras, height, width, num_channels)，可以直接作为强化学习的观察值使用。"

#: ../../source/overview/sensors/camera.rst:48
msgid ""
"When working with rendering, make sure to add the ``--enable_cameras`` "
"argument when launching the environment. For example:"
msgstr "在进行渲染时，确保在启动环境时添加 ``--enable_cameras`` 参数。例如："

#: ../../source/overview/sensors/camera.rst:56
msgid "Annotators"
msgstr "标注器"

#: ../../source/overview/sensors/camera.rst:58
msgid ""
"Both :class:`~sensors.TiledCamera` and :class:`~sensors.Camera` classes "
"provide APIs for retrieving various types annotator data from replicator:"
msgstr ""
"两个 :class:`~sensors.TiledCamera` 和 :class:`~sensors.Camera` 类提供用于从 "
"replicator 检索各种类型标注数据的 API："

#: ../../source/overview/sensors/camera.rst:60
msgid "``\"rgb\"``: A 3-channel rendered color image."
msgstr "``\"rgb\"``: 一种三通道渲染的颜色图像。"

#: ../../source/overview/sensors/camera.rst:61
msgid "``\"rgba\"``: A 4-channel rendered color image with alpha channel."
msgstr "``\"rgba\"``: 一个具有 alpha 通道的 4 通道渲染颜色图像。"

#: ../../source/overview/sensors/camera.rst:62
msgid ""
"``\"distance_to_camera\"``: An image containing the distance to camera "
"optical center."
msgstr "``\"distance_to_camera\"``: 包含到相机光学中心的距离的图像。"

#: ../../source/overview/sensors/camera.rst:63
msgid ""
"``\"distance_to_image_plane\"``: An image containing distances of 3D points "
"from camera plane along camera's z-axis."
msgstr "``\"distance_to_image_plane\"``: 一个包含从摄像机平面沿摄像机 z 轴到 3D 点的距离的图像。"

#: ../../source/overview/sensors/camera.rst:64
msgid "``\"depth\"``: The same as ``\"distance_to_image_plane\"``."
msgstr "``\"depth\"``: 与 ``\"distance_to_image_plane\"`` 相同。"

#: ../../source/overview/sensors/camera.rst:65
msgid ""
"``\"normals\"``: An image containing the local surface normal vectors at "
"each pixel."
msgstr "``\"normals\"``: 一个包含每个像素的局部表面法线向量的图像。"

#: ../../source/overview/sensors/camera.rst:66
msgid ""
"``\"motion_vectors\"``: An image containing the motion vector data at each "
"pixel."
msgstr "``\"motion_vectors\"``: 一个包含每个像素处运动矢量数据的图像。"

#: ../../source/overview/sensors/camera.rst:67
msgid "``\"semantic_segmentation\"``: The semantic segmentation data."
msgstr "``\"semantic_segmentation\"``: 语义分割数据。"

#: ../../source/overview/sensors/camera.rst:68
msgid "``\"instance_segmentation_fast\"``: The instance segmentation data."
msgstr "``\"instance_segmentation_fast\"``: 实例分割数据。"

#: ../../source/overview/sensors/camera.rst:69
msgid "``\"instance_id_segmentation_fast\"``: The instance id segmentation data."
msgstr "``\"instance_id_segmentation_fast\"``: 实例 ID 分割数据。"

#: ../../source/overview/sensors/camera.rst:72
msgid "RGB and RGBA"
msgstr "RGB 和 RGBA"

#: ../../source/overview/sensors/camera.rst:-1
msgid "以RGB格式捕获的场景"
msgstr "以RGB格式捕获的场景"

#: ../../source/overview/sensors/camera.rst:79
msgid ""
"``rgb`` data type returns a 3-channel RGB colored image of type "
"``torch.uint8``, with dimension (B, H, W, 3)."
msgstr "``rgb`` 数据类型返回一个 3 通道 RGB 彩色图像，类型为 ``torch.uint8``，维度为 (B, H, W, 3)。"

#: ../../source/overview/sensors/camera.rst:81
msgid ""
"``rgba`` data type returns a 4-channel RGBA colored image of type "
"``torch.uint8``, with dimension (B, H, W, 4)."
msgstr ""
"``rgba`` 数据类型返回一个 4 通道 RGBA 彩色图像，类型为 ``torch.uint8``，维度为 (B, H, W, 4)。"

#: ../../source/overview/sensors/camera.rst:83
msgid ""
"To convert the ``torch.uint8`` data to ``torch.float32``, divide the buffer "
"by 255.0 to obtain a ``torch.float32`` buffer containing data from 0 to 1."
msgstr ""
"将 ``torch.uint8`` 数据转换为 ``torch.float32``，将缓冲区除以 255.0 以获得一个包含 0 到 1 之间数据的 "
"``torch.float32`` 缓冲区。"

#: ../../source/overview/sensors/camera.rst:86
msgid "Depth and Distances"
msgstr "深度和距离"

#: ../../source/overview/sensors/camera.rst:93
msgid ""
"``distance_to_camera`` returns a single-channel depth image with distance to"
" the camera optical center. The dimension for this annotator is (B, H, W, 1)"
" and has type ``torch.float32``."
msgstr ""
"``distance_to_camera`` 返回一个单通道深度图像，表示到相机光学中心的距离。此注释器的维度为 (B, H, W, 1)，类型为 "
"``torch.float32`` 。"

#: ../../source/overview/sensors/camera.rst:95
msgid ""
"``distance_to_image_plane`` returns a single-channel depth image with "
"distances of 3D points from the camera plane along the camera's Z-axis. The "
"dimension for this annotator is (B, H, W, 1) and has type ``torch.float32``."
msgstr ""
"``distance_to_image_plane`` 返回一个单通道深度图像，表示 3D 点相对于相机平面沿相机 Z 轴的距离。该注释器的维度为 "
"(B, H, W, 1)，类型为 ``torch.float32`` 。"

#: ../../source/overview/sensors/camera.rst:97
msgid ""
"``depth`` is provided as an alias for ``distance_to_image_plane`` and will "
"return the same data as the ``distance_to_image_plane`` annotator, with "
"dimension (B, H, W, 1) and type ``torch.float32``."
msgstr ""
"``depth`` 被作为 ``distance_to_image_plane`` 的别名，并将返回与 "
"``distance_to_image_plane`` 注释器相同的数据，维度为 (B, H, W, 1)，类型为 ``torch.float32`` "
"。"

#: ../../source/overview/sensors/camera.rst:100
msgid "Normals"
msgstr "法线"

#: ../../source/overview/sensors/camera.rst:107
msgid ""
"``normals`` returns an image containing the local surface normal vectors at "
"each pixel. The buffer has dimension (B, H, W, 3), containing the (x, y, z) "
"information for each vector, and has data type ``torch.float32``."
msgstr ""
"``normals`` 返回一张包含每个像素局部表面法向量的图像。该缓冲区的维度为 (B, H, W, 3)，包含每个向量的 (x, y, z) "
"信息，并且数据类型为 ``torch.float32`` 。"

#: ../../source/overview/sensors/camera.rst:110
msgid "Motion Vectors"
msgstr "运动向量"

#: ../../source/overview/sensors/camera.rst:112
msgid ""
"``motion_vectors`` returns the per-pixel motion vectors in image space, with"
" a 2D array of motion vectors representing the relative motion of a pixel in"
" the camera’s viewport between frames. The buffer has dimension (B, H, W, "
"2), representing x - the motion distance in the horizontal axis (image "
"width) with movement to the left of the image being positive and movement to"
" the right being negative and y - motion distance in the vertical axis "
"(image height) with movement towards the top of the image being positive and"
" movement to the bottom being negative. The data type is ``torch.float32``."
msgstr ""
"``motion_vectors`` 返回图像空间中的每个像素的运动向量，使用 2D 数组表示每个像素在相机视口中在帧之间的相对运动。缓冲区的维度为 "
"(B, H, W, 2)，其中 x 表示水平方向（图像宽度）的运动距离，向左移动时为正，向右移动时为负；y "
"表示垂直方向（图像高度）的运动距离，向上移动时为正，向下移动时为负。数据类型为 ``torch.float32`` 。"

#: ../../source/overview/sensors/camera.rst:115
msgid "Semantic Segmentation"
msgstr "语义分割"

#: ../../source/overview/sensors/camera.rst:122
msgid ""
"``semantic_segmentation`` outputs semantic segmentation of each entity in "
"the camera’s viewport that has semantic labels. In addition to the image "
"buffer, an ``info`` dictionary can be retrieved with "
"``tiled_camera.data.info['semantic_segmentation']`` containing ID to labels "
"information."
msgstr ""
"``semantic_segmentation`` 输出相机视口中每个具有语义标签的实体的语义分割。除了图像缓冲区外，还可以通过 "
"``tiled_camera.data.info['semantic_segmentation']`` 获取一个 ``info`` 字典，该字典包含 "
"ID 到标签的信息。"

#: ../../source/overview/sensors/camera.rst:124
msgid ""
"If ``colorize_semantic_segmentation=True`` in the camera config, a 4-channel"
" RGBA image will be returned with dimension (B, H, W, 4) and type "
"``torch.uint8``. The info ``idToLabels`` dictionary will be the mapping from"
" color to semantic labels."
msgstr ""
"如果 ``colorize_semantic_segmentation=True`` 在相机配置中，返回的将是一个 4 通道的 RGBA 图像，维度为 "
"(B, H, W, 4)，类型为 ``torch.uint8`` 。信息 ``idToLabels`` 字典将是从颜色到语义标签的映射。"

#: ../../source/overview/sensors/camera.rst:126
msgid ""
"If ``colorize_semantic_segmentation=False``, a buffer of dimension (B, H, W,"
" 1) of type ``torch.int32`` will be returned, containing the semantic ID of "
"each pixel. The info ``idToLabels`` dictionary will be the mapping from "
"semantic ID to semantic labels."
msgstr ""
"如果 ``colorize_semantic_segmentation=False``，则会返回一个维度为 (B, H, W, 1) 且类型为 "
"``torch.int32`` 的缓冲区，包含每个像素的语义 ID。信息 ``idToLabels`` 字典将是从语义 ID 到语义标签的映射。"

#: ../../source/overview/sensors/camera.rst:129
msgid "Instance ID Segmentation"
msgstr "实例 ID 分割"

#: ../../source/overview/sensors/camera.rst:136
msgid ""
"``instance_id_segmentation_fast`` outputs instance ID segmentation of each "
"entity in the camera’s viewport. The instance ID is unique for each prim in "
"the scene with different paths. In addition to the image buffer, an ``info``"
" dictionary can be retrieved with "
"``tiled_camera.data.info['instance_id_segmentation_fast']`` containing ID to"
" labels information."
msgstr ""
"``instance_id_segmentation_fast`` 输出相机视口中每个实体的实例 ID 分割。每个场景中的 prim "
"拥有不同路径的唯一实例 ID。除了图像缓冲区外，还可以通过 "
"``tiled_camera.data.info['instance_id_segmentation_fast']`` 检索到一个 ``info`` "
"字典，其中包含 ID 到标签的映射信息。"

#: ../../source/overview/sensors/camera.rst:138
msgid ""
"The main difference between ``instance_id_segmentation_fast`` and "
"``instance_segmentation_fast`` are that instance segmentation annotator goes"
" down the hierarchy to the lowest level prim which has semantic labels, "
"where instance ID segmentation always goes down to the leaf prim."
msgstr ""
"``instance_id_segmentation_fast`` 和 ``instance_segmentation_fast`` "
"之间的主要区别在于，实例分割注释器会向下遍历层级，直到具有语义标签的最低级 prim，而实例 ID 分割则始终遍历到叶节点 prim。"

#: ../../source/overview/sensors/camera.rst:140
msgid ""
"If ``colorize_instance_id_segmentation=True`` in the camera config, a "
"4-channel RGBA image will be returned with dimension (B, H, W, 4) and type "
"``torch.uint8``. The info ``idToLabels`` dictionary will be the mapping from"
" color to USD prim path of that entity."
msgstr ""
"如果 ``colorize_instance_id_segmentation=True`` 在相机配置中，将返回一个 4 通道的 RGBA 图像，维度为"
" (B, H, W, 4)，类型为 ``torch.uint8`` 。信息 ``idToLabels`` 字典将是颜色到该实体的 USD prim "
"路径的映射。"

#: ../../source/overview/sensors/camera.rst:142
msgid ""
"If ``colorize_instance_id_segmentation=False``, a buffer of dimension (B, H,"
" W, 1) of type ``torch.int32`` will be returned, containing the instance ID "
"of each pixel. The info ``idToLabels`` dictionary will be the mapping from "
"instance ID to USD prim path of that entity."
msgstr ""
"如果 ``colorize_instance_id_segmentation=False``，将返回一个形状为 (B, H, W, 1) 的类型为 "
"``torch.int32`` 的缓冲区，包含每个像素的实例 ID。信息 ``idToLabels`` 字典将是从实例 ID 到该实体的 USD "
"prim 路径的映射。"

#: ../../source/overview/sensors/camera.rst:145
msgid "Instance Segmentation"
msgstr "实例分割"

#: ../../source/overview/sensors/camera.rst:152
msgid ""
"``instance_segmentation_fast`` outputs instance segmentation of each entity "
"in the camera’s viewport. In addition to the image buffer, an ``info`` "
"dictionary can be retrieved with "
"``tiled_camera.data.info['instance_segmentation_fast']`` containing ID to "
"labels and ID to semantic information."
msgstr ""
"``instance_segmentation_fast`` 输出相机视口中每个实体的实例分割。除了图像缓冲区，还可以通过 "
"``tiled_camera.data.info['instance_segmentation_fast']`` 获取 ``info`` 字典，其中包含"
" ID 到标签和 ID 到语义信息。"

#: ../../source/overview/sensors/camera.rst:154
msgid ""
"If ``colorize_instance_segmentation=True`` in the camera config, a 4-channel"
" RGBA image will be returned with dimension (B, H, W, 4) and type "
"``torch.uint8``."
msgstr ""
"如果 ``colorize_instance_segmentation=True`` 在相机配置中，则会返回一个 4 通道的 RGBA 图像，尺寸为 "
"(B, H, W, 4)，类型为 ``torch.uint8`` 。"

#: ../../source/overview/sensors/camera.rst:156
msgid ""
"If ``colorize_instance_segmentation=False``, a buffer of dimension (B, H, W,"
" 1) of type ``torch.int32`` will be returned, containing the instance ID of "
"each pixel."
msgstr ""
"如果 ``colorize_instance_segmentation=False``，则将返回一个维度为 (B, H, W, 1) 且类型为 "
"``torch.int32`` 的缓冲区，其中包含每个像素的实例 ID。"

#: ../../source/overview/sensors/camera.rst:158
msgid ""
"The info ``idToLabels`` dictionary will be the mapping from color to USD "
"prim path of that semantic entity. The info ``idToSemantics`` dictionary "
"will be the mapping from color to semantic labels of that semantic entity."
msgstr ""
"信息 ``idToLabels`` 字典将是从颜色到该语义实体的 USD prim 路径的映射。信息 ``idToSemantics`` "
"字典将是从颜色到该语义实体的语义标签的映射。"

#: ../../source/overview/sensors/camera.rst:162
msgid "Current Limitations"
msgstr "当前的限制"

#: ../../source/overview/sensors/camera.rst:164
msgid ""
"Due to current limitations in the renderer, we can have only **one** "
":class:`~sensors.TiledCamera` instance in the scene. For use cases that "
"require a setup with more than one camera, we can imitate the multi-camera "
"behavior by moving the location of the camera in between render calls in a "
"step."
msgstr ""
"由于当前渲染器的限制，我们在场景中只能有 **一个** :class:`~sensors.TiledCamera` "
"实例。对于需要多个相机的使用场景，我们可以通过在渲染调用之间移动相机的位置来模仿多相机的行为。"

#: ../../source/overview/sensors/camera.rst:168
msgid ""
"For example, in a stereo vision setup, the below snippet can be implemented:"
msgstr "例如，在立体视觉设置中，可以实现以下代码片段："

#: ../../source/overview/sensors/camera.rst:186
msgid ""
"Note that this approach still limits the rendering resolution to be "
"identical for all cameras. Currently, there is no workaround to achieve "
"different resolution images using :class:`~sensors.TiledCamera`. The best "
"approach is to use the largest resolution out of all of the desired "
"resolutions and add additional scaling or cropping operations to the "
"rendered output as a post-processing step."
msgstr ""
"请注意，这种方法仍然将所有相机的渲染分辨率限制为相同。目前，没有解决方案可以使用 :class:`~sensors.TiledCamera` "
"实现不同分辨率的图像。最好的方法是使用所有期望分辨率中的最大分辨率，并在渲染输出中添加额外的缩放或裁剪操作，作为后期处理步骤。"

#: ../../source/overview/sensors/camera.rst:190
msgid ""
"In addition, there may be visible quality differences when comparing render "
"outputs of different numbers of environments. Currently, any combined "
"resolution that has a width less than 265 pixels or height less than 265 "
"will automatically switch to the DLAA anti-aliasing mode, which does not "
"perform up-sampling during anti-aliasing. For resolutions larger than 265 in"
" both width and height dimensions, we default to using the \"performance\" "
"DLSS mode for anti-aliasing for performance benefits. Anti-aliasing modes "
"and other rendering parameters can be specified in the "
":class:`~sim.RenderCfg`."
msgstr ""
"此外，在比较不同环境数量的渲染输出时，可能会出现明显的质量差异。目前，任何宽度小于 265 像素或高度小于 265 像素的合并分辨率，将自动切换到 "
"DLAA 抗锯齿模式，该模式在抗锯齿过程中不会进行上采样。对于宽度和高度都大于 265 的分辨率，我们默认使用 \"performance\" DLSS"
" 模式进行抗锯齿，以获得性能提升。抗锯齿模式和其他渲染参数可以在 :class:`~sim.RenderCfg` 中指定。"
