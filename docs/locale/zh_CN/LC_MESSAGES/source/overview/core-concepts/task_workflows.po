# SOME DESCRIPTIVE TITLE.
# Copyright (C) 2022-2024, The Isaac Lab Project Developers.
# This file is distributed under the same license as the Isaac Lab package.
# FIRST AUTHOR <EMAIL@ADDRESS>, 2024.
msgid ""
msgstr ""
"Project-Id-Version: Isaac Lab 1.1.0\n"
"Report-Msgid-Bugs-To: \n"
"POT-Creation-Date: 2025-01-31 20:38+0800\n"
"PO-Revision-Date: YEAR-MO-DA HO:MI+ZONE\n"
"Last-Translator: Ziqi Fan <fanziqi614@gmail.com>\n"
"Language-Team: zh_CN <LL@li.org>\n"
"Language: zh_CN\n"
"MIME-Version: 1.0\n"
"Content-Type: text/plain; charset=utf-8\n"
"Content-Transfer-Encoding: 8bit\n"
"Plural-Forms: nplurals=1; plural=0;\n"
"Generated-By: Babel 2.16.0\n"

#: ../../source/overview/core-concepts/task_workflows.rst:5
msgid "Task Design Workflows"
msgstr "任务设计工作流程"

#: ../../source/overview/core-concepts/task_workflows.rst:9
msgid ""
"A **Task** is defined by an environment with specific interfaces for "
"observations to and actions from a specific agent (robot). The environment "
"is what provides an agent with the current observations and executes that "
"agent's actions by updating the simulation forward in time. There are many "
"common components of simulating a robot in an environment, regardless of "
"what you might want that robot to do or how it might be trained to do it."
msgstr ""
"一个 **Task** "
"是由一个环境定义的，该环境具有特定的接口，用于接收来自特定代理（机器人）的观察和执行该代理的动作。环境提供给代理当前的观察，并通过将模拟向前推进来执行代理的动作。无论您希望机器人做什么，或它如何被训练去做，都有许多常见的组件来模拟机器人在环境中的表现。"

#: ../../source/overview/core-concepts/task_workflows.rst:11
msgid ""
"This is especially true of Reinforcement Learning (RL), where managing the "
"actions, observations, rewards, etc... across a vectorized GPU simulation "
"can be daunting to even think about! To meet this need, Isaac Lab provides "
"the ability to build your RL environments within our **Manager-based** "
"system, allowing you to trust various minutia of the appropriate manager "
"classes. However, we also recognize the need to exert granular control over "
"an environment, especially during development. For this need, we also "
"provide a **Direct** interface into the simulation, giving you full control!"
msgstr ""
"这在强化学习（RL）中尤为明显，在一个向量化的 GPU 模拟中管理动作、观察、奖励等内容，即使是想一想也让人感到望而生畏！为了满足这一需求，Isaac "
"Lab 提供了在我们的 **Manager-based** 系统中构建 RL "
"环境的能力，允许你信任各种适当的管理类的细节。然而，我们也认识到在开发过程中对环境进行精细控制的需求。为此，我们还提供了一个 **Direct** "
"接口进入模拟，赋予你完全的控制权！"

#: ../../source/overview/core-concepts/task_workflows.rst:13
msgid ""
"**Manager-based**: The environment is decomposed into individual components "
"(or managers) that handle different aspects of the environment (such as "
"computing observations, applying actions, and applying randomization). The "
"user defines configuration classes for each component and the environment is"
" responsible for coordinating the managers and calling their functions."
msgstr ""
"**基于管理器**: "
"环境被分解为单独的组件（或管理器），这些组件处理环境的不同方面（例如计算观察、应用动作和应用随机化）。用户为每个组件定义配置类，环境负责协调管理器并调用它们的函数。"

#: ../../source/overview/core-concepts/task_workflows.rst:18
msgid ""
"**Direct**: The user defines a single class that implements the entire "
"environment directly without the need for separate managers. This class is "
"responsible for computing observations, applying actions, and computing "
"rewards."
msgstr "**直接式**: 用户定义一个单一类，该类直接实现整个环境，而无需单独的管理器。这个类负责计算观察、应用动作和计算奖励。"

#: ../../source/overview/core-concepts/task_workflows.rst:21
msgid ""
"Both workflows have their own advantages and disadvantages. The manager-"
"based workflow is more modular and allows different components of the "
"environment to be swapped out easily. This is useful when prototyping the "
"environment and experimenting with different configurations. On the other "
"hand, the direct workflow is more efficient and allows for more fine-grained"
" control over the environment logic. This is useful when optimizing the "
"environment for performance or when implementing complex logic that is "
"difficult to decompose into separate components."
msgstr ""
"两个工作流程各有优缺点。基于管理器的工作流程更具模块化，允许环境的不同组件轻松更换。这在原型环境和实验不同配置时非常有用。另一方面，直接式工作流程更高效，允许对环境逻辑进行更细粒度的控制。这在优化环境性能或实现复杂逻辑时非常有用，而这些复杂逻辑难以拆分为独立组件。"

#: ../../source/overview/core-concepts/task_workflows.rst:29
msgid "Manager-Based Environments"
msgstr "基于管理器的环境"

#: ../../source/overview/core-concepts/task_workflows.rst:-1
msgid "Manager-based Task Workflow"
msgstr "基于管理器的工作流"

#: ../../source/overview/core-concepts/task_workflows.rst:41
msgid ""
"Manager-based environments promote modular implementations of tasks by "
"decomposing it into individually managed components. Each component of the "
"task, such as calculating rewards, observations, etc... can be specified as "
"configurations for a corresponding manager. These managers define "
"configurable functions that are responsible for executing the specific "
"computations as needed. Coordinating a collection of different managers is "
"handled by an Environment class that inherits from "
":class:`envs.ManagerBasedEnv`. Configurations likewise must all inherit from"
" :class:`envs.ManagerBasedEnvCfg`."
msgstr ""
"基于管理器的环境通过将任务分解为单独管理的组件，促进了任务的模块化实现。任务的每个组件，例如计算奖励、观察等，可以作为相应管理器的配置来指定。这些管理器定义了可配置的函数，负责在需要时执行特定的计算。不同管理器的协调由继承自"
" :class:`envs.ManagerBasedEnv` 的环境类来处理。配置同样必须全部继承自 "
":class:`envs.ManagerBasedEnvCfg` 。"

#: ../../source/overview/core-concepts/task_workflows.rst:43
msgid ""
"When developing new training environments, it is often beneficial to break "
"the environment into independent components.  This can be highly effective "
"for collaboration, as it lets individual developers focus on different "
"aspects of the environment, while allowing those disparate efforts to be "
"joined back together into a single runnable task. For example, you may have "
"multiple robots with differing sensoriums, requiring different observation "
"managers to process those sensory data into a form that's useful for "
"downstream components.  You might have multiple members on the team with "
"different ideas about what the reward should be to achieve your goals, and "
"by having each one develop their own reward manager, you can swap and test "
"as you see fit. The modular nature of the manager workflow is essential for "
"more complex projects!"
msgstr ""
"在开发新的训练环境时，将环境分解为独立的组件通常是有益的。这对于协作非常有效，因为它允许个别开发人员专注于环境的不同方面，同时允许将这些不同的努力重新组合成一个单独的可执行任务。例如，您可能有多个具有不同感官系统的机器人，要求不同的观察管理器将这些传感数据处理成对下游组件有用的形式。您可能有多个团队成员，他们对于实现目标的奖励应该是什么有不同的看法，通过让每个人开发自己的奖励管理器，您可以根据需要进行替换和测试。管理器工作流的模块化特性对于更复杂的项目至关重要！"

#: ../../source/overview/core-concepts/task_workflows.rst:45
msgid ""
"For reinforcement learning, much of this has been done for you already! In "
"most cases, it will be enough to write your environment to inherit from "
":class:`envs.ManagerBasedRLEnv` and and your configuration from "
":class:`envs.ManagerBasedRLEnvCfg`."
msgstr ""
"对于强化学习，很多工作已经为您完成！在大多数情况下，您只需要编写您的环境继承自 :class:`envs.ManagerBasedRLEnv` "
"，并且您的配置继承自 :class:`envs.ManagerBasedRLEnvCfg` 。"

#: ../../source/overview/core-concepts/task_workflows.rst
msgid ""
"Example for defining the reward function for the Cartpole task using the "
"manager-style"
msgstr "用于使用管理器样式定义Cartpole任务的奖励函数的示例"

#: ../../source/overview/core-concepts/task_workflows.rst:51
msgid ""
"The following class is a part of the Cartpole environment configuration "
"class. The :class:`RewardsCfg` class defines individual terms that compose "
"the reward function. Each reward term is defined by its function "
"implementation, weight and additional parameters to be passed to the "
"function. Users can define multiple reward terms and their weights to be "
"used in the reward function."
msgstr ""
"以下类是 Cartpole 环境配置类的一部分。 :class:`RewardsCfg` "
"类定义了构成奖励函数的各个项。每个奖励项由其函数实现、权重和要传递给函数的附加参数定义。用户可以定义多个奖励项及其权重，以用于奖励函数。"

#: ../../source/overview/core-concepts/task_workflows.rst:62
msgid ""
"We provide a more detailed tutorial for setting up an environment using the "
"manager-based workflow at :ref:`tutorial-create-manager-rl-env`."
msgstr ""
"我们为使用基于管理器的工作流设置环境提供了更详细的教程，位于 :ref:`tutorial-create-manager-rl-env` 。"

#: ../../source/overview/core-concepts/task_workflows.rst:67
msgid "Direct Environments"
msgstr "直接式的环境"

#: ../../source/overview/core-concepts/task_workflows.rst:-1
msgid "Direct-based Task Workflow"
msgstr "基于直接式的任务工作流"

#: ../../source/overview/core-concepts/task_workflows.rst:79
msgid ""
"The direct-style environment aligns more closely with traditional "
"implementations of environments from other libraries. A single class "
"implements the reward function, observation function, resets, and all the "
"other components of the environment. This approach does not require the "
"manager classes. Instead, users are provided the complete freedom to "
"implement their task through the APIs of either :class:`envs.DirectRLEnv` or"
" :class:`envs.DirectMARLEnv`. All direct task environments must inherit from"
" one of these two classes. Direct environments still require configurations "
"to be defined, specifically by inheriting from either "
":class:`envs.DirectRLEnvCfg` or :class:`envs.DirectMARLEnvCfg`. This "
"workflow may be the most familiar for users migrating from the "
"`IsaacGymEnvs`_ and `OmniIsaacGymEnvs`_ frameworks."
msgstr ""
"直接风格环境与其他库中环境的传统实现更为接近。一个单一的类实现了奖励函数、观察函数、重置函数以及环境的所有其他组件。该方法不需要管理类。相反，用户可以通过"
" :class:`envs.DirectRLEnv` 或 :class:`envs.DirectMARLEnv` 的 API "
"完全自由地实现他们的任务。所有直接任务环境必须继承这两个类中的一个。直接环境仍然需要定义配置，具体来说是通过继承 "
":class:`envs.DirectRLEnvCfg` 或 :class:`envs.DirectMARLEnvCfg` 。对于从 "
"`IsaacGymEnvs`_ 和 `OmniIsaacGymEnvs`_ 框架迁移过来的用户来说，这种工作流程可能是最熟悉的。"

#: ../../source/overview/core-concepts/task_workflows.rst
msgid ""
"Example for defining the reward function for the Cartpole task using the "
"direct-style"
msgstr "为 Cartpole 任务定义奖励函数的示例，使用直接式风格"

#: ../../source/overview/core-concepts/task_workflows.rst:89
msgid ""
"The following function is a part of the Cartpole environment class and is "
"responsible for computing the rewards."
msgstr "以下函数是Cartpole环境类的一部分，负责计算奖励。"

#: ../../source/overview/core-concepts/task_workflows.rst:96
msgid ""
"It calls the :meth:`compute_rewards` function which is Torch JIT compiled "
"for performance benefits."
msgstr "它调用了 :meth:`compute_rewards` 函数，该函数经过Torch JIT编译以获得性能优势。"

#: ../../source/overview/core-concepts/task_workflows.rst:102
msgid ""
"This approach provides more transparency in the implementations of the "
"environments, as logic is defined within the task class instead of "
"abstracted with the use of managers. This may be beneficial when "
"implementing complex logic that is difficult to decompose into separate "
"components. Additionally, the direct-style implementation may bring more "
"performance benefits for the environment, as it allows implementing large "
"chunks of logic with optimized frameworks such as `PyTorch JIT`_ or `Warp`_."
" This may be valuable when scaling up training tremendously which requires "
"optimizing individual operations in the environment."
msgstr ""
"这种方法提供了更高的透明度，因为逻辑在任务类中定义，而不是通过管理器进行抽象。当实现复杂的逻辑时，这可能是有益的，因为这些逻辑难以分解成独立的组件。此外，直接式风格的实现可能会为环境带来更多的性能收益，因为它允许使用优化框架，如"
" `PyTorch JIT`_ 或 `Warp`_ 来实现大量逻辑。当需要大规模训练并优化环境中的单个操作时，这可能是有价值的。"

#: ../../source/overview/core-concepts/task_workflows.rst:111
msgid ""
"We provide a more detailed tutorial for setting up a RL environment using "
"the direct workflow at :ref:`tutorial-create-direct-rl-env`."
msgstr ""
"我们为使用直接式工作流程设置强化学习环境提供了更详细的教程，可参考 :ref:`tutorial-create-direct-rl-env` 。"
