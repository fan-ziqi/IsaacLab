# SOME DESCRIPTIVE TITLE.
# Copyright (C) 2022-2025, The Isaac Lab Project Developers.
# This file is distributed under the same license as the Isaac Lab package.
# FIRST AUTHOR <EMAIL@ADDRESS>, 2025.
#
msgid ""
msgstr ""
"Project-Id-Version: Isaac Lab 2.0.1\n"
"Report-Msgid-Bugs-To: \n"
"POT-Creation-Date: 2025-03-04 11:21+0800\n"
"PO-Revision-Date: YEAR-MO-DA HO:MI+ZONE\n"
"Last-Translator: Ziqi Fan <fanziqi614@gmail.com>\n"
"Language-Team: zh_CN <LL@li.org>\n"
"Language: zh_CN\n"
"MIME-Version: 1.0\n"
"Content-Type: text/plain; charset=utf-8\n"
"Content-Transfer-Encoding: 8bit\n"
"Plural-Forms: nplurals=1; plural=0;\n"
"Generated-By: Babel 2.17.0\n"

#: ../../source/overview/core-concepts/sensors/camera.rst:6
msgid "Camera"
msgstr "相机"

#: ../../source/overview/core-concepts/sensors/camera.rst:8
msgid ""
"Camera sensors are uniquely defined by the use of the ``render_product``, a "
"structure for managing data generated by the rendering pipeline (images). "
"Isaac Lab provides the ability to fully control how these renderings are "
"created through camera parameters like focal length, pose, type, etc... and "
"what kind of data you want to render through the use of Annotators, allowing"
" you to record not only RGB, but also Instance segmentation, object pose, "
"object ID, etc..."
msgstr ""
"相机传感器通过使用 ``render_product`` 独特地定义，它是一个用于管理由渲染管线（图像）生成的数据的结构。Isaac Lab "
"提供了完全控制这些渲染如何通过相机参数（如焦距、姿态、类型等）创建的能力，以及通过使用 "
"Annotators，您可以控制想要渲染的数据类型，允许您记录不仅仅是 RGB，还包括实例分割、物体姿态、物体 ID 等。"

#: ../../source/overview/core-concepts/sensors/camera.rst:10
msgid ""
"Rendered images are unique among the supported data types in Isaac Lab due "
"to the inherently large bandwidth requirements for moving those data. A "
"single 800 x 600 image with 32-bit color (a single float per pixel) clocks "
"in at just under 2 MB. If we render at 60 fps and record every frame, that "
"camera needs to move 120 MB/s. Multiply this by the number of cameras in an "
"environment and environments in a simulation, and you can quickly see how "
"scaling a naive vectorization of camera data could lead to bandwidth "
"challenges. NVIDIA's Isaac Lab leverages our expertise in GPU hardware to "
"provide an API that specifically addresses these scaling challenges in the "
"rendering pipeline."
msgstr ""
"渲染的图像在 Isaac Lab 中是支持的数据类型中独特的，因为移动这些数据本身就需要极大的带宽。单个 800 x 600 图像，采用 32 "
"位颜色（每个像素一个浮动点），大小接近 2 MB。如果我们以 60 fps 渲染并记录每一帧，那么该摄像头需要每秒传输 120 "
"MB。将此值乘以环境中的摄像头数量以及仿真中的环境数量，你可以很快看到，摄像头数据的朴素向量化如何可能导致带宽问题。 NVIDIA 的 Isaac "
"Lab 利用我们在 GPU 硬件方面的专业知识，提供了一个 API，专门解决渲染管线中这些扩展性问题。"

#: ../../source/overview/core-concepts/sensors/camera.rst:13
msgid "Tiled Rendering"
msgstr "平铺渲染"

#: ../../source/overview/core-concepts/sensors/camera.rst:17
msgid "This feature is only available from Isaac Sim version 4.2.0 onwards."
msgstr "这个功能仅在 Isaac Sim 版本 4.2.0 及以后版本中可用。"

#: ../../source/overview/core-concepts/sensors/camera.rst:19
msgid ""
"Tiled rendering in combination with image processing networks require heavy "
"memory resources, especially at larger resolutions. We recommend running 512"
" cameras in the scene on RTX 4090 GPUs or similar."
msgstr ""
"分块渲染结合图像处理网络需要大量的内存资源，尤其是在更高分辨率下。我们建议在 RTX 4090 GPU 或类似设备上运行 512 台摄像头。"

#: ../../source/overview/core-concepts/sensors/camera.rst:22
msgid ""
"The Tiled Rendering APIs provide a vectorized interface for collecting data "
"from camera sensors. This is useful for reinforcement learning environments "
"where parallelization can be exploited to accelerate data collection and "
"thus the training loop. Tiled rendering works by using a single "
"``render_product`` for **all** clones of a single camera in the scene. The "
"desired dimensions of a single image and the number of environments are used"
" to compute a much larger ``render_product``, consisting of the tiled "
"individual renders from the separate clones of the camera. When all cameras "
"have populated their buffers the render product is \"completed\" and can be "
"moved around as a single, large image, dramatically reducing the overhead "
"for moving the data from the host to the device, for example.  Only a single"
" call is used to synchronize the device data, instead of one call per "
"camera, and this is a big part of what makes the Tiled Rendering API more "
"efficient for working with vision data."
msgstr ""
"Tiled Rendering API "
"提供了一个向量化接口，用于从相机传感器收集数据。这对于强化学习环境非常有用，因为可以利用并行化来加速数据收集，从而加快训练循环。Tiled "
"渲染通过使用一个单一的 ``render_product`` 来处理场景中单个相机的 **所有** "
"克隆。单个图像的期望尺寸和环境的数量用于计算一个更大的 ``render_product`` "
"，由来自相机不同克隆的单个渲染拼接而成。当所有相机填充完它们的缓冲区后，渲染产品就被 \"完成\" "
"并可以作为一个单一的大图像进行移动，从而显著减少将数据从主机传输到设备的开销。例如，设备数据同步只使用一次调用，而不是每个相机一次调用，这也是 "
"Tiled Rendering API 在处理视觉数据时更加高效的一个重要原因。"

#: ../../source/overview/core-concepts/sensors/camera.rst:24
msgid ""
"Isaac Lab provides tiled rendering APIs for RGB, depth, along with other "
"annotators through the :class:`~sensors.TiledCamera` class. Configurations "
"for the tiled rendering APIs can be defined through the "
":class:`~sensors.TiledCameraCfg` class, specifying parameters such as the "
"regex expression for all camera paths, the transform for the cameras, the "
"desired data type, the type of cameras to add to the scene, and the camera "
"resolution."
msgstr ""
"Isaac Lab 提供了用于 RGB、深度以及其他注释器的瓦片渲染 API，通过 :class:`~sensors.TiledCamera` "
"类。瓦片渲染 API 的配置可以通过 :class:`~sensors.TiledCameraCfg` "
"类来定义，指定诸如所有摄像机路径的正则表达式、摄像机的变换、所需的数据类型、要添加到场景中的摄像机类型以及摄像机分辨率等参数。"

#: ../../source/overview/core-concepts/sensors/camera.rst:39
msgid ""
"To access the tiled rendering interface, a :class:`~sensors.TiledCamera` "
"object can be created and used to retrieve data from the cameras."
msgstr "要访问平铺渲染接口，可以创建一个 :class:`~sensors.TiledCamera` 对象并使用它从相机中获取数据。"

#: ../../source/overview/core-concepts/sensors/camera.rst:47
msgid ""
"The returned data will be transformed into the shape (num_cameras, height, "
"width, num_channels), which can be used directly as observation for "
"reinforcement learning."
msgstr ""
"返回的数据将被转换为形状 (num_cameras, height, width, num_channels)，可以直接作为强化学习的观测值使用。"

#: ../../source/overview/core-concepts/sensors/camera.rst:49
msgid ""
"When working with rendering, make sure to add the ``--enable_cameras`` "
"argument when launching the environment. For example:"
msgstr "在进行渲染时，确保在启动环境时添加 ``--enable_cameras`` 参数。例如: "

#: ../../source/overview/core-concepts/sensors/camera.rst:57
msgid "Annotators"
msgstr "标注者"

#: ../../source/overview/core-concepts/sensors/camera.rst:59
msgid ""
"Both :class:`~sensors.TiledCamera` and :class:`~sensors.Camera` classes "
"provide APIs for retrieving various types annotator data from replicator:"
msgstr ""
"两个 :class:`~sensors.TiledCamera` 和 :class:`~sensors.Camera` 类提供了从 replicator"
" 获取各种类型标注器数据的 API。"

#: ../../source/overview/core-concepts/sensors/camera.rst:61
msgid "``\"rgb\"``: A 3-channel rendered color image."
msgstr "``\"rgb\"``: 一种 3 通道渲染的彩色图像。"

#: ../../source/overview/core-concepts/sensors/camera.rst:62
msgid "``\"rgba\"``: A 4-channel rendered color image with alpha channel."
msgstr "``\"rgba\"``: 一个具有 alpha 通道的 4 通道渲染颜色图像。"

#: ../../source/overview/core-concepts/sensors/camera.rst:63
msgid ""
"``\"distance_to_camera\"``: An image containing the distance to camera "
"optical center."
msgstr "``\"distance_to_camera\"``: 一张包含到相机光心的距离的图像。"

#: ../../source/overview/core-concepts/sensors/camera.rst:64
msgid ""
"``\"distance_to_image_plane\"``: An image containing distances of 3D points "
"from camera plane along camera's z-axis."
msgstr "``\"distance_to_image_plane\"``: 一张包含从相机平面沿相机 z 轴方向测量的 3D 点距离的图像。"

#: ../../source/overview/core-concepts/sensors/camera.rst:65
msgid "``\"depth\"``: The same as ``\"distance_to_image_plane\"``."
msgstr "``\"depth\"``: 与 ``\"distance_to_image_plane\"`` 相同。"

#: ../../source/overview/core-concepts/sensors/camera.rst:66
msgid ""
"``\"normals\"``: An image containing the local surface normal vectors at "
"each pixel."
msgstr "``\"法线\"``: 一张包含每个像素的局部表面法线向量的图像。"

#: ../../source/overview/core-concepts/sensors/camera.rst:67
msgid ""
"``\"motion_vectors\"``: An image containing the motion vector data at each "
"pixel."
msgstr "``\"motion_vectors\"``: 包含每个像素的运动矢量数据的图像。"

#: ../../source/overview/core-concepts/sensors/camera.rst:68
msgid "``\"semantic_segmentation\"``: The semantic segmentation data."
msgstr "``\"semantic_segmentation\"``: 语义分割数据。"

#: ../../source/overview/core-concepts/sensors/camera.rst:69
msgid "``\"instance_segmentation_fast\"``: The instance segmentation data."
msgstr "``\"instance_segmentation_fast\"``: 实例分割数据."

#: ../../source/overview/core-concepts/sensors/camera.rst:70
msgid "``\"instance_id_segmentation_fast\"``: The instance id segmentation data."
msgstr "``\"instance_id_segmentation_fast\"``: 实例 ID 分割数据。"

#: ../../source/overview/core-concepts/sensors/camera.rst:73
msgid "RGB and RGBA"
msgstr "RGB 和 RGBA"

#: ../../source/overview/core-concepts/sensors/camera.rst:-1
msgid "A scene captured in RGB"
msgstr "一个场景捕捉在 RGB"

#: ../../source/overview/core-concepts/sensors/camera.rst:80
msgid ""
"``rgb`` data type returns a 3-channel RGB colored image of type "
"``torch.uint8``, with dimension (B, H, W, 3)."
msgstr ""
"``rgb`` 数据类型返回一个 3 通道的 RGB 彩色图像，类型为 ``torch.uint8``, 维度为 (B, H, W, 3)。"

#: ../../source/overview/core-concepts/sensors/camera.rst:82
msgid ""
"``rgba`` data type returns a 4-channel RGBA colored image of type "
"``torch.uint8``, with dimension (B, H, W, 4)."
msgstr ""
"``rgba`` 数据类型返回一个 4 通道的 RGBA 彩色图像，类型为 ``torch.uint8``, 维度为 (B, H, W, 4)。"

#: ../../source/overview/core-concepts/sensors/camera.rst:84
msgid ""
"To convert the ``torch.uint8`` data to ``torch.float32``, divide the buffer "
"by 255.0 to obtain a ``torch.float32`` buffer containing data from 0 to 1."
msgstr ""
"将 ``torch.uint8`` 数据转换为 ``torch.float32`` 时，使用 255.0 除以缓冲区，得到一个 "
"``torch.float32`` 缓冲区，其中的数据范围从 0 到 1。"

#: ../../source/overview/core-concepts/sensors/camera.rst:87
msgid "Depth and Distances"
msgstr "深度和距离"

#: ../../source/overview/core-concepts/sensors/camera.rst:94
msgid ""
"``distance_to_camera`` returns a single-channel depth image with distance to"
" the camera optical center. The dimension for this annotator is (B, H, W, 1)"
" and has type ``torch.float32``."
msgstr ""
"``distance_to_camera`` 返回一个单通道深度图像，表示到相机光学中心的距离。此注释器的维度为 (B, H, W, 1)，数据类型为 "
"``torch.float32`` 。"

#: ../../source/overview/core-concepts/sensors/camera.rst:96
msgid ""
"``distance_to_image_plane`` returns a single-channel depth image with "
"distances of 3D points from the camera plane along the camera's Z-axis. The "
"dimension for this annotator is (B, H, W, 1) and has type ``torch.float32``."
msgstr ""
"``distance_to_image_plane`` 返回一个单通道深度图像，表示 3D 点沿着相机 Z 轴到相机平面的距离。该标注器的维度为 (B,"
" H, W, 1)，类型为 ``torch.float32`` 。"

#: ../../source/overview/core-concepts/sensors/camera.rst:98
msgid ""
"``depth`` is provided as an alias for ``distance_to_image_plane`` and will "
"return the same data as the ``distance_to_image_plane`` annotator, with "
"dimension (B, H, W, 1) and type ``torch.float32``."
msgstr ""
"``depth`` 是 ``distance_to_image_plane`` 的别名，并将返回与 "
"``distance_to_image_plane`` 注释器相同的数据，维度为 (B, H, W, 1)，类型为 ``torch.float32`` "
"。"

#: ../../source/overview/core-concepts/sensors/camera.rst:101
msgid "Normals"
msgstr "法线"

#: ../../source/overview/core-concepts/sensors/camera.rst:108
msgid ""
"``normals`` returns an image containing the local surface normal vectors at "
"each pixel. The buffer has dimension (B, H, W, 3), containing the (x, y, z) "
"information for each vector, and has data type ``torch.float32``."
msgstr ""
"``normals`` 返回一张图像，包含每个像素处的局部表面法向量。该缓冲区的维度为 (B, H, W, 3)，包含每个向量的 (x, y, z) "
"信息，数据类型为 ``torch.float32`` 。"

#: ../../source/overview/core-concepts/sensors/camera.rst:111
msgid "Motion Vectors"
msgstr "运动向量"

#: ../../source/overview/core-concepts/sensors/camera.rst:113
msgid ""
"``motion_vectors`` returns the per-pixel motion vectors in image space, with"
" a 2D array of motion vectors representing the relative motion of a pixel in"
" the camera’s viewport between frames. The buffer has dimension (B, H, W, "
"2), representing x - the motion distance in the horizontal axis (image "
"width) with movement to the left of the image being positive and movement to"
" the right being negative and y - motion distance in the vertical axis "
"(image height) with movement towards the top of the image being positive and"
" movement to the bottom being negative. The data type is ``torch.float32``."
msgstr ""
"``motion_vectors`` 返回图像空间中的每个像素的运动向量，运动向量的二维数组表示像素在相机视口中在帧与帧之间的相对运动。缓冲区的维度为 "
"(B, H, W, 2)，其中 x 代表水平方向上的运动距离（图像宽度），向左移动时为正，向右移动时为负；y "
"代表垂直方向上的运动距离（图像高度），向上移动时为正，向下移动时为负。数据类型是 ``torch.float32`` 。"

#: ../../source/overview/core-concepts/sensors/camera.rst:116
msgid "Semantic Segmentation"
msgstr "语义分割"

#: ../../source/overview/core-concepts/sensors/camera.rst:123
msgid ""
"``semantic_segmentation`` outputs semantic segmentation of each entity in "
"the camera’s viewport that has semantic labels. In addition to the image "
"buffer, an ``info`` dictionary can be retrieved with "
"``tiled_camera.data.info['semantic_segmentation']`` containing ID to labels "
"information."
msgstr ""
"``semantic_segmentation`` 输出相机视口中具有语义标签的每个实体的语义分割。除了图像缓冲区外，还可以通过 "
"``tiled_camera.data.info['semantic_segmentation']`` 获取一个 ``info`` 字典，其中包含 ID"
" 到标签的信息。"

#: ../../source/overview/core-concepts/sensors/camera.rst:125
msgid ""
"If ``colorize_semantic_segmentation=True`` in the camera config, a 4-channel"
" RGBA image will be returned with dimension (B, H, W, 4) and type "
"``torch.uint8``. The info ``idToLabels`` dictionary will be the mapping from"
" color to semantic labels."
msgstr ""
"如果 ``colorize_semantic_segmentation=True`` 在相机配置中，返回的将是一个具有维度 (B, H, W, 4) "
"和类型 ``torch.uint8`` 的 4 通道 RGBA 图像。信息 ``idToLabels`` 字典将是从颜色到语义标签的映射。"

#: ../../source/overview/core-concepts/sensors/camera.rst:127
msgid ""
"If ``colorize_semantic_segmentation=False``, a buffer of dimension (B, H, W,"
" 1) of type ``torch.int32`` will be returned, containing the semantic ID of "
"each pixel. The info ``idToLabels`` dictionary will be the mapping from "
"semantic ID to semantic labels."
msgstr ""
"如果 ``colorize_semantic_segmentation=False``, 则会返回一个维度为 (B, H, W, 1) 且类型为 "
"``torch.int32`` 的缓冲区，包含每个像素的语义 ID。信息 ``idToLabels`` 字典将是从语义 ID 到语义标签的映射。"

#: ../../source/overview/core-concepts/sensors/camera.rst:130
msgid "Instance ID Segmentation"
msgstr "实例 ID 分割"

#: ../../source/overview/core-concepts/sensors/camera.rst:137
msgid ""
"``instance_id_segmentation_fast`` outputs instance ID segmentation of each "
"entity in the camera’s viewport. The instance ID is unique for each prim in "
"the scene with different paths. In addition to the image buffer, an ``info``"
" dictionary can be retrieved with "
"``tiled_camera.data.info['instance_id_segmentation_fast']`` containing ID to"
" labels information."
msgstr ""
"``instance_id_segmentation_fast`` 输出相机视口中每个实体的实例 ID 分割。每个场景中的 prim 都有唯一的实例 "
"ID，路径不同。除了图像缓冲区，还可以通过 "
"``tiled_camera.data.info['instance_id_segmentation_fast']`` 获取一个 ``info`` "
"字典，包含 ID 到标签的信息。"

#: ../../source/overview/core-concepts/sensors/camera.rst:139
msgid ""
"The main difference between ``instance_id_segmentation_fast`` and "
"``instance_segmentation_fast`` are that instance segmentation annotator goes"
" down the hierarchy to the lowest level prim which has semantic labels, "
"where instance ID segmentation always goes down to the leaf prim."
msgstr ""
"``instance_id_segmentation_fast`` 和 ``instance_segmentation_fast`` "
"之间的主要区别在于，实例分割注释器会一直向下层级遍历到具有语义标签的最低级别原语，而实例 ID 分割则始终向下遍历到叶子原语。"

#: ../../source/overview/core-concepts/sensors/camera.rst:141
msgid ""
"If ``colorize_instance_id_segmentation=True`` in the camera config, a "
"4-channel RGBA image will be returned with dimension (B, H, W, 4) and type "
"``torch.uint8``. The info ``idToLabels`` dictionary will be the mapping from"
" color to USD prim path of that entity."
msgstr ""
"如果 ``colorize_instance_id_segmentation=True`` 在相机配置中，将返回一个4通道的RGBA图像，尺寸为(B, "
"H, W, 4)，类型为 ``torch.uint8`` 。信息 ``idToLabels`` 字典将是从颜色到该实体的USD prim路径的映射。"

#: ../../source/overview/core-concepts/sensors/camera.rst:143
msgid ""
"If ``colorize_instance_id_segmentation=False``, a buffer of dimension (B, H,"
" W, 1) of type ``torch.int32`` will be returned, containing the instance ID "
"of each pixel. The info ``idToLabels`` dictionary will be the mapping from "
"instance ID to USD prim path of that entity."
msgstr ""
"如果 ``colorize_instance_id_segmentation=False``, 则返回一个维度为 (B, H, W, 1) 且类型为 "
"``torch.int32`` 的缓冲区，其中包含每个像素的实例 ID。信息 ``idToLabels`` 字典将是实例 ID 到该实体的 USD "
"prim 路径的映射。"

#: ../../source/overview/core-concepts/sensors/camera.rst:146
msgid "Instance Segmentation"
msgstr "实例分割"

#: ../../source/overview/core-concepts/sensors/camera.rst:153
msgid ""
"``instance_segmentation_fast`` outputs instance segmentation of each entity "
"in the camera’s viewport. In addition to the image buffer, an ``info`` "
"dictionary can be retrieved with "
"``tiled_camera.data.info['instance_segmentation_fast']`` containing ID to "
"labels and ID to semantic information."
msgstr ""
"``instance_segmentation_fast`` 输出摄像机视口中每个实体的实例分割。除了图像缓冲区，还可以通过 "
"``tiled_camera.data.info['instance_segmentation_fast']`` 获取 ``info`` 字典，其中包含"
" ID 到标签和 ID 到语义信息。"

#: ../../source/overview/core-concepts/sensors/camera.rst:155
msgid ""
"If ``colorize_instance_segmentation=True`` in the camera config, a 4-channel"
" RGBA image will be returned with dimension (B, H, W, 4) and type "
"``torch.uint8``."
msgstr ""
"如果 ``colorize_instance_segmentation=True`` 在相机配置中，将返回一个具有维度 (B, H, W, 4) 和类型"
" ``torch.uint8`` 的 4 通道 RGBA 图像。"

#: ../../source/overview/core-concepts/sensors/camera.rst:157
msgid ""
"If ``colorize_instance_segmentation=False``, a buffer of dimension (B, H, W,"
" 1) of type ``torch.int32`` will be returned, containing the instance ID of "
"each pixel."
msgstr ""
"如果 ``colorize_instance_segmentation=False``, 将返回一个维度为 (B, H, W, 1) 且类型为 "
"``torch.int32`` 的缓冲区，其中包含每个像素的实例 ID。"

#: ../../source/overview/core-concepts/sensors/camera.rst:159
msgid ""
"The info ``idToLabels`` dictionary will be the mapping from color to USD "
"prim path of that semantic entity. The info ``idToSemantics`` dictionary "
"will be the mapping from color to semantic labels of that semantic entity."
msgstr ""
"信息 ``idToLabels`` 字典将是从颜色到该语义实体的 USD prim 路径的映射。信息 ``idToSemantics`` "
"字典将是从颜色到该语义实体的语义标签的映射。"

#: ../../source/overview/core-concepts/sensors/camera.rst:163
msgid "Current Limitations"
msgstr "当前限制"

#: ../../source/overview/core-concepts/sensors/camera.rst:165
msgid ""
"For performance reasons, we default to using DLSS for denoising, which "
"generally provides better performance. This may result in renders of lower "
"quality, which may be especially evident at lower resolutions. Due to this, "
"we recommend using per-tile or per-camera resolution of at least 100 x 100. "
"For renders at lower resolutions, we advice setting the "
"``antialiasing_mode`` attribute in :class:`~sim.RenderCfg` to ``DLAA``, and "
"also potentially enabling ``enable_dl_denoiser``. Both of these settings "
"should help improve render quality, but also comes at a cost of performance."
" Additional rendering parameters can also be specified in "
":class:`~sim.RenderCfg`."
msgstr ""
"出于性能考虑，我们默认使用 DLSS "
"进行去噪处理，这通常能提供更好的性能。这可能导致渲染质量较低，尤其是在低分辨率下尤为明显。因此，我们建议使用每瓦片或每相机分辨率至少为 100 x "
"100。对于低分辨率的渲染，我们建议在 :class:`~sim.RenderCfg` 中设置 ``antialiasing_mode`` 属性为 "
"``DLAA``, 并且可能需要启用 ``enable_dl_denoiser`` 。这两个设置应该有助于提高渲染质量，但也会带来性能的损耗。还可以在 "
":class:`~sim.RenderCfg` 中指定其他渲染参数。"
