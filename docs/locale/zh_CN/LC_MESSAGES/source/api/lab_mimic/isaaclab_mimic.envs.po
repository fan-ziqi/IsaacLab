# SOME DESCRIPTIVE TITLE.
# Copyright (C) 2022-2024, The Isaac Lab Project Developers.
# This file is distributed under the same license as the Isaac Lab package.
# FIRST AUTHOR <EMAIL@ADDRESS>, 2025.
msgid ""
msgstr ""
"Project-Id-Version: Isaac Lab 2.0.0\n"
"Report-Msgid-Bugs-To: \n"
"POT-Creation-Date: 2025-04-26 11:51+0800\n"
"PO-Revision-Date: YEAR-MO-DA HO:MI+ZONE\n"
"Last-Translator: Ziqi Fan <fanziqi614@gmail.com>\n"
"Language: zh_CN\n"
"Language-Team: zh_CN <LL@li.org>\n"
"Plural-Forms: nplurals=1; plural=0;\n"
"MIME-Version: 1.0\n"
"Content-Type: text/plain; charset=utf-8\n"
"Content-Transfer-Encoding: 8bit\n"
"Generated-By: Babel 2.17.0\n"

#: ../../source/api/lab_mimic/isaaclab_mimic.envs.rst:2
msgid "isaaclab_mimic.envs"
msgstr ""

#: ../../source/api/lab_mimic/isaaclab_mimic.envs.rst:14
msgid "Franka Cube Stack IK Rel Mimic Env"
msgstr ""

#: ../../source/api/lab_mimic/isaaclab_mimic.envs.rst:21
msgid "Franka Cube Stack IK Rel Mimic Env Cfg"
msgstr ""

#~ msgid "Sub-package with environment wrappers for Isaac Lab Mimic."
#~ msgstr ""

#~ msgid "Classes"
#~ msgstr ""

#~ msgid ""
#~ ":py:obj:`FrankaCubeStackIKRelMimicEnv "
#~ "<isaaclab_mimic.envs.FrankaCubeStackIKRelMimicEnv>`\\"
#~ msgstr ""

#~ msgid ""
#~ "Isaac Lab Mimic environment wrapper "
#~ "class for Franka Cube Stack IK Rel"
#~ " env."
#~ msgstr ""

#~ msgid ""
#~ ":py:obj:`FrankaCubeStackIKRelMimicEnvCfg "
#~ "<isaaclab_mimic.envs.FrankaCubeStackIKRelMimicEnvCfg>`\\"
#~ msgstr ""

#~ msgid ""
#~ "Isaac Lab Mimic environment config class"
#~ " for Franka Cube Stack IK Rel "
#~ "env."
#~ msgstr ""

#~ msgid "**Methods:**"
#~ msgstr ""

#~ msgid ""
#~ ":py:obj:`get_robot_eef_pose "
#~ "<isaaclab_mimic.envs.FrankaCubeStackIKRelMimicEnv.get_robot_eef_pose>`\\"
#~ " \\(eef\\_name\\[\\, env\\_ids\\]\\)"
#~ msgstr ""

#~ msgid "Get current robot end effector pose."
#~ msgstr ""

#~ msgid ""
#~ ":py:obj:`target_eef_pose_to_action "
#~ "<isaaclab_mimic.envs.FrankaCubeStackIKRelMimicEnv.target_eef_pose_to_action>`\\"
#~ " \\(...\\[\\, noise\\, env\\_id\\]\\)"
#~ msgstr ""

#~ msgid ""
#~ "Takes a target pose and gripper "
#~ "action for the end effector controller"
#~ " and returns an action (usually a "
#~ "normalized delta pose action) to try "
#~ "and achieve that target pose."
#~ msgstr ""

#~ msgid ""
#~ ":py:obj:`action_to_target_eef_pose "
#~ "<isaaclab_mimic.envs.FrankaCubeStackIKRelMimicEnv.action_to_target_eef_pose>`\\"
#~ " \\(action\\)"
#~ msgstr ""

#~ msgid ""
#~ "Converts action (compatible with env.step) "
#~ "to a target pose for the end "
#~ "effector controller."
#~ msgstr ""

#~ msgid ""
#~ ":py:obj:`actions_to_gripper_actions "
#~ "<isaaclab_mimic.envs.FrankaCubeStackIKRelMimicEnv.actions_to_gripper_actions>`\\"
#~ " \\(actions\\)"
#~ msgstr ""

#~ msgid ""
#~ "Extracts the gripper actuation part from"
#~ " a sequence of env actions "
#~ "(compatible with env.step)."
#~ msgstr ""

#~ msgid ""
#~ ":py:obj:`get_subtask_term_signals "
#~ "<isaaclab_mimic.envs.FrankaCubeStackIKRelMimicEnv.get_subtask_term_signals>`\\"
#~ " \\(\\[env\\_ids\\]\\)"
#~ msgstr ""

#~ msgid ""
#~ "Gets a dictionary of termination signal"
#~ " flags for each subtask in a "
#~ "task."
#~ msgstr ""

#~ msgid ""
#~ ":py:obj:`__init__ "
#~ "<isaaclab_mimic.envs.FrankaCubeStackIKRelMimicEnv.__init__>`\\ "
#~ "\\(cfg\\[\\, render\\_mode\\]\\)"
#~ msgstr ""

#~ msgid "Initialize the environment."
#~ msgstr ""

#~ msgid ""
#~ ":py:obj:`close "
#~ "<isaaclab_mimic.envs.FrankaCubeStackIKRelMimicEnv.close>`\\ "
#~ "\\(\\)"
#~ msgstr ""

#~ msgid "Cleanup for the environment."
#~ msgstr ""

#~ msgid ""
#~ ":py:obj:`get_object_poses "
#~ "<isaaclab_mimic.envs.FrankaCubeStackIKRelMimicEnv.get_object_poses>`\\"
#~ " \\(\\[env\\_ids\\]\\)"
#~ msgstr ""

#~ msgid ""
#~ "Gets the pose of each object "
#~ "relevant to Isaac Lab Mimic data "
#~ "generation in the current scene."
#~ msgstr ""

#~ msgid ""
#~ ":py:obj:`get_wrapper_attr "
#~ "<isaaclab_mimic.envs.FrankaCubeStackIKRelMimicEnv.get_wrapper_attr>`\\"
#~ " \\(name\\)"
#~ msgstr ""

#~ msgid "Gets the attribute `name` from the environment."
#~ msgstr ""

#~ msgid ""
#~ ":py:obj:`has_wrapper_attr "
#~ "<isaaclab_mimic.envs.FrankaCubeStackIKRelMimicEnv.has_wrapper_attr>`\\"
#~ " \\(name\\)"
#~ msgstr ""

#~ msgid "Checks if the attribute `name` exists in the environment."
#~ msgstr ""

#~ msgid ""
#~ ":py:obj:`load_managers "
#~ "<isaaclab_mimic.envs.FrankaCubeStackIKRelMimicEnv.load_managers>`\\"
#~ " \\(\\)"
#~ msgstr ""

#~ msgid "Load the managers for the environment."
#~ msgstr ""

#~ msgid ""
#~ ":py:obj:`render "
#~ "<isaaclab_mimic.envs.FrankaCubeStackIKRelMimicEnv.render>`\\ "
#~ "\\(\\[recompute\\]\\)"
#~ msgstr ""

#~ msgid "Run rendering without stepping through the physics."
#~ msgstr ""

#~ msgid ""
#~ ":py:obj:`reset "
#~ "<isaaclab_mimic.envs.FrankaCubeStackIKRelMimicEnv.reset>`\\ "
#~ "\\(\\[seed\\, env\\_ids\\, options\\]\\)"
#~ msgstr ""

#~ msgid "Resets the specified environments and returns observations."
#~ msgstr ""

#~ msgid ""
#~ ":py:obj:`reset_to "
#~ "<isaaclab_mimic.envs.FrankaCubeStackIKRelMimicEnv.reset_to>`\\ "
#~ "\\(state\\, env\\_ids\\[\\, seed\\, "
#~ "is\\_relative\\]\\)"
#~ msgstr ""

#~ msgid "Resets specified environments to provided states."
#~ msgstr ""

#~ msgid ""
#~ ":py:obj:`seed "
#~ "<isaaclab_mimic.envs.FrankaCubeStackIKRelMimicEnv.seed>`\\ "
#~ "\\(\\[seed\\]\\)"
#~ msgstr ""

#~ msgid "Set the seed for the environment."
#~ msgstr ""

#~ msgid ""
#~ ":py:obj:`serialize "
#~ "<isaaclab_mimic.envs.FrankaCubeStackIKRelMimicEnv.serialize>`\\ "
#~ "\\(\\)"
#~ msgstr ""

#~ msgid ""
#~ "Save all information needed to re-"
#~ "instantiate this environment in a "
#~ "dictionary."
#~ msgstr ""

#~ msgid ""
#~ ":py:obj:`set_wrapper_attr "
#~ "<isaaclab_mimic.envs.FrankaCubeStackIKRelMimicEnv.set_wrapper_attr>`\\"
#~ " \\(name\\, value\\)"
#~ msgstr ""

#~ msgid "Sets the attribute `name` on the environment with `value`."
#~ msgstr ""

#~ msgid ""
#~ ":py:obj:`setup_manager_visualizers "
#~ "<isaaclab_mimic.envs.FrankaCubeStackIKRelMimicEnv.setup_manager_visualizers>`\\"
#~ " \\(\\)"
#~ msgstr ""

#~ msgid "Creates live visualizers for manager terms."
#~ msgstr ""

#~ msgid ""
#~ ":py:obj:`step "
#~ "<isaaclab_mimic.envs.FrankaCubeStackIKRelMimicEnv.step>`\\ "
#~ "\\(action\\)"
#~ msgstr ""

#~ msgid ""
#~ "Execute one time-step of the "
#~ "environment's dynamics and reset terminated"
#~ " environments."
#~ msgstr ""

#~ msgid "**Attributes:**"
#~ msgstr ""

#~ msgid ""
#~ ":py:obj:`device "
#~ "<isaaclab_mimic.envs.FrankaCubeStackIKRelMimicEnv.device>`\\"
#~ msgstr ""

#~ msgid "The device on which the environment is running."
#~ msgstr ""

#~ msgid ""
#~ ":py:obj:`is_vector_env "
#~ "<isaaclab_mimic.envs.FrankaCubeStackIKRelMimicEnv.is_vector_env>`\\"
#~ msgstr ""

#~ msgid "Whether the environment is a vectorized environment."
#~ msgstr ""

#~ msgid ""
#~ ":py:obj:`max_episode_length "
#~ "<isaaclab_mimic.envs.FrankaCubeStackIKRelMimicEnv.max_episode_length>`\\"
#~ msgstr ""

#~ msgid "Maximum episode length in environment steps."
#~ msgstr ""

#~ msgid ""
#~ ":py:obj:`max_episode_length_s "
#~ "<isaaclab_mimic.envs.FrankaCubeStackIKRelMimicEnv.max_episode_length_s>`\\"
#~ msgstr ""

#~ msgid "Maximum episode length in seconds."
#~ msgstr ""

#~ msgid ""
#~ ":py:obj:`metadata "
#~ "<isaaclab_mimic.envs.FrankaCubeStackIKRelMimicEnv.metadata>`\\"
#~ msgstr ""

#~ msgid "Metadata for the environment."
#~ msgstr ""

#~ msgid ""
#~ ":py:obj:`np_random "
#~ "<isaaclab_mimic.envs.FrankaCubeStackIKRelMimicEnv.np_random>`\\"
#~ msgstr ""

#~ msgid ""
#~ "Returns the environment's internal "
#~ ":attr:`_np_random` that if not set will"
#~ " initialise with a random seed."
#~ msgstr ""

#~ msgid ""
#~ ":py:obj:`np_random_seed "
#~ "<isaaclab_mimic.envs.FrankaCubeStackIKRelMimicEnv.np_random_seed>`\\"
#~ msgstr ""

#~ msgid ""
#~ "Returns the environment's internal "
#~ ":attr:`_np_random_seed` that if not set "
#~ "will first initialise with a random "
#~ "int as seed."
#~ msgstr ""

#~ msgid ""
#~ ":py:obj:`num_envs "
#~ "<isaaclab_mimic.envs.FrankaCubeStackIKRelMimicEnv.num_envs>`\\"
#~ msgstr ""

#~ msgid "The number of instances of the environment that are running."
#~ msgstr ""

#~ msgid ""
#~ ":py:obj:`physics_dt "
#~ "<isaaclab_mimic.envs.FrankaCubeStackIKRelMimicEnv.physics_dt>`\\"
#~ msgstr ""

#~ msgid "The physics time-step (in s)."
#~ msgstr ""

#~ msgid ""
#~ ":py:obj:`step_dt "
#~ "<isaaclab_mimic.envs.FrankaCubeStackIKRelMimicEnv.step_dt>`\\"
#~ msgstr ""

#~ msgid "The environment stepping time-step (in s)."
#~ msgstr ""

#~ msgid ""
#~ ":py:obj:`unwrapped "
#~ "<isaaclab_mimic.envs.FrankaCubeStackIKRelMimicEnv.unwrapped>`\\"
#~ msgstr ""

#~ msgid "Returns the base non-wrapped environment."
#~ msgstr ""

#~ msgid ":py:obj:`cfg <isaaclab_mimic.envs.FrankaCubeStackIKRelMimicEnv.cfg>`\\"
#~ msgstr ""

#~ msgid "Configuration for the environment."
#~ msgstr ""

#~ msgid ""
#~ "Get current robot end effector pose. "
#~ "Should be the same frame as used"
#~ " by the robot end-effector "
#~ "controller."
#~ msgstr ""

#~ msgid "参数"
#~ msgstr ""

#~ msgid "Name of the end effector."
#~ msgstr ""

#~ msgid ""
#~ "Environment indices to get the pose "
#~ "for. If None, all envs are "
#~ "considered."
#~ msgstr ""

#~ msgid "返回"
#~ msgstr ""

#~ msgid "A torch.Tensor eef pose matrix. Shape is (len(env_ids), 4, 4)"
#~ msgstr ""

#~ msgid ""
#~ "Takes a target pose and gripper "
#~ "action for the end effector controller"
#~ " and returns an action (usually a "
#~ "normalized delta pose action) to try "
#~ "and achieve that target pose. Noise "
#~ "is added to the target pose action"
#~ " if specified."
#~ msgstr ""

#~ msgid "Dictionary of 4x4 target eef pose for each end-effector."
#~ msgstr ""

#~ msgid "Dictionary of gripper actions for each end-effector."
#~ msgstr ""

#~ msgid "Noise to add to the action. If None, no noise is added."
#~ msgstr ""

#~ msgid "Environment index to get the action for."
#~ msgstr ""

#~ msgid "An action torch.Tensor that's compatible with env.step()."
#~ msgstr ""

#~ msgid ""
#~ "Converts action (compatible with env.step) "
#~ "to a target pose for the end "
#~ "effector controller. Inverse of "
#~ "@target_eef_pose_to_action. Usually used to "
#~ "infer a sequence of target controller"
#~ " poses from a demonstration trajectory "
#~ "using the recorded actions."
#~ msgstr ""

#~ msgid "Environment action. Shape is (num_envs, action_dim)"
#~ msgstr ""

#~ msgid "A dictionary of eef pose torch.Tensor that @action corresponds to"
#~ msgstr ""

#~ msgid ""
#~ "environment actions. The shape is "
#~ "(num_envs, num steps in a demo, "
#~ "action_dim)."
#~ msgstr ""

#~ msgid ""
#~ "A dictionary of torch.Tensor gripper "
#~ "actions. Key to each dict is an"
#~ " eef_name."
#~ msgstr ""

#~ msgid ""
#~ "Gets a dictionary of termination signal"
#~ " flags for each subtask in a "
#~ "task. The flag is 1 when the "
#~ "subtask has been completed and 0 "
#~ "otherwise. The implementation of this "
#~ "method is required if intending to "
#~ "enable automatic subtask term signal "
#~ "annotation when running the dataset "
#~ "annotation tool. This method can be "
#~ "kept unimplemented if intending to use"
#~ " manual subtask term signal annotation."
#~ msgstr ""

#~ msgid ""
#~ "Environment indices to get the "
#~ "termination signals for. If None, all"
#~ " envs are considered."
#~ msgstr ""

#~ msgid "A dictionary termination signal flags (False or True) for each subtask."
#~ msgstr ""

#~ msgid "The configuration for the environment."
#~ msgstr ""

#~ msgid ""
#~ "The render mode for the environment. "
#~ "Defaults to None, which is similar "
#~ "to ``\"human\"``."
#~ msgstr ""

#~ msgid ""
#~ "A dictionary that maps object names "
#~ "to object pose matrix (4x4 torch.Tensor)"
#~ msgstr ""

#~ msgid ""
#~ "This function is responsible for "
#~ "creating the various managers (action, "
#~ "observation, events, etc.) for the "
#~ "environment. Since the managers require "
#~ "access to physics handles, they can "
#~ "only be created after the simulator "
#~ "is reset (i.e. played for the "
#~ "first time)."
#~ msgstr ""

#~ msgid ""
#~ "In case of standalone application (when"
#~ " running simulator from Python), the "
#~ "function is called automatically when "
#~ "the class is initialized."
#~ msgstr ""

#~ msgid ""
#~ "However, in case of extension mode, "
#~ "the user must call this function "
#~ "manually after the simulator is reset."
#~ " This is because the simulator is "
#~ "only reset when the user calls "
#~ ":meth:`SimulationContext.reset_async` and it isn't"
#~ " possible to call async functions in"
#~ " the constructor."
#~ msgstr ""

#~ msgid "Instances of `np.random.Generator`"
#~ msgstr ""

#~ msgid ""
#~ "If :attr:`np_random_seed` was set directly "
#~ "instead of through :meth:`reset` or "
#~ ":meth:`set_np_random_through_seed`, the seed will"
#~ " take the value -1."
#~ msgstr ""

#~ msgid ""
#~ "the seed of the current `np_random` "
#~ "or -1, if the seed of the "
#~ "rng is unknown"
#~ msgstr ""

#~ msgid "返回类型"
#~ msgstr ""

#~ msgid ""
#~ "This is the lowest time-decimation "
#~ "at which the simulation is happening."
#~ msgstr ""

#~ msgid "By convention, if mode is:"
#~ msgstr ""

#~ msgid ""
#~ "**human**: Render to the current display"
#~ " and return nothing. Usually for "
#~ "human consumption."
#~ msgstr ""

#~ msgid ""
#~ "**rgb_array**: Return an numpy.ndarray with"
#~ " shape (x, y, 3), representing RGB"
#~ " values for an x-by-y pixel image,"
#~ " suitable for turning into a video."
#~ msgstr ""

#~ msgid ""
#~ "Whether to force a render even if"
#~ " the simulator has already rendered "
#~ "the scene. Defaults to False."
#~ msgstr ""

#~ msgid ""
#~ "The rendered image as a numpy "
#~ "array if mode is \"rgb_array\". "
#~ "Otherwise, returns None."
#~ msgstr ""

#~ msgid "抛出"
#~ msgstr ""

#~ msgid ""
#~ "If mode is set to \"rgb_data\" and"
#~ " simulation render mode does not "
#~ "support it.     In this case, the "
#~ "simulation render mode must be set "
#~ "to ``RenderMode.PARTIAL_RENDERING``     or "
#~ "``RenderMode.FULL_RENDERING``."
#~ msgstr ""

#~ msgid "If an unsupported rendering mode is specified."
#~ msgstr ""

#~ msgid ""
#~ "This function calls the :meth:`_reset_idx` "
#~ "function to reset the specified "
#~ "environments. However, certain operations, "
#~ "such as procedural terrain generation, "
#~ "that happened during initialization are "
#~ "not repeated."
#~ msgstr ""

#~ msgid ""
#~ "The seed to use for randomization. "
#~ "Defaults to None, in which case "
#~ "the seed is not set."
#~ msgstr ""

#~ msgid ""
#~ "The environment ids to reset. Defaults"
#~ " to None, in which case all "
#~ "environments are reset."
#~ msgstr ""

#~ msgid ""
#~ "Additional information to specify how "
#~ "the environment is reset. Defaults to"
#~ " None.  .. note:: This argument is"
#~ " used for compatibility with Gymnasium "
#~ "environment definition."
#~ msgstr ""

#~ msgid ""
#~ "Additional information to specify how "
#~ "the environment is reset. Defaults to"
#~ " None."
#~ msgstr ""

#~ msgid ""
#~ "This argument is used for compatibility"
#~ " with Gymnasium environment definition."
#~ msgstr ""

#~ msgid "A tuple containing the observations and extras."
#~ msgstr ""

#~ msgid ""
#~ "This function resets the environments to"
#~ " the provided states. The state is"
#~ " a dictionary containing the state of"
#~ " the scene entities. Please refer to"
#~ " :meth:`InteractiveScene.get_state` for the "
#~ "format."
#~ msgstr ""

#~ msgid ""
#~ "The function is different from the "
#~ ":meth:`reset` function as it resets the"
#~ " environments to specific states, instead"
#~ " of using the randomization events "
#~ "for resetting the environments."
#~ msgstr ""

#~ msgid ""
#~ "The state to reset the specified "
#~ "environments to. Please refer to "
#~ ":meth:`InteractiveScene.get_state` for the format."
#~ msgstr ""

#~ msgid ""
#~ "If set to True, the state is "
#~ "considered relative to the environment "
#~ "origins. Defaults to False."
#~ msgstr ""

#~ msgid "The seed for random generator. Defaults to -1."
#~ msgstr ""

#~ msgid "The seed used for random generator."
#~ msgstr ""

#~ msgid ""
#~ "Save all information needed to re-"
#~ "instantiate this environment in a "
#~ "dictionary. This is the same as "
#~ "@env_meta - environment metadata stored "
#~ "in hdf5 datasets, and used in "
#~ "utils/env_utils.py."
#~ msgstr ""

#~ msgid ""
#~ "Unlike the :class:`ManagerBasedEnv.step` class, "
#~ "the function performs the following "
#~ "operations:"
#~ msgstr ""

#~ msgid "Process the actions."
#~ msgstr ""

#~ msgid "Perform physics stepping."
#~ msgstr ""

#~ msgid "Perform rendering if gui is enabled."
#~ msgstr ""

#~ msgid ""
#~ "Update the environment counters and "
#~ "compute the rewards and terminations."
#~ msgstr ""

#~ msgid "Reset the environments that terminated."
#~ msgstr ""

#~ msgid "Compute the observations."
#~ msgstr ""

#~ msgid "Return the observations, rewards, resets and extras."
#~ msgstr ""

#~ msgid ""
#~ "The actions to apply on the "
#~ "environment. Shape is (num_envs, action_dim)."
#~ msgstr ""

#~ msgid ""
#~ "A tuple containing the observations, "
#~ "rewards, resets (terminated and truncated) "
#~ "and extras."
#~ msgstr ""

#~ msgid "This is the time-step at which the environment steps forward."
#~ msgstr ""

#~ msgid "The base non-wrapped :class:`gymnasium.Env` instance"
#~ msgstr ""

#~ msgid ""
#~ "基类：:py:class:`~isaaclab_tasks.manager_based.manipulation.stack.config.franka.stack_ik_rel_env_cfg.FrankaCubeStackEnvCfg`,"
#~ " :py:class:`~isaaclab.envs.mimic_env_cfg.MimicEnvCfg`"
#~ msgstr ""

#~ msgid ""
#~ ":py:obj:`__init__ "
#~ "<isaaclab_mimic.envs.FrankaCubeStackIKRelMimicEnvCfg.__init__>`\\ "
#~ "\\(\\[datagen\\_config\\, subtask\\_configs\\, ...\\]\\)"
#~ msgstr ""

#~ msgid "**Classes:**"
#~ msgstr ""

#~ msgid ""
#~ ":py:obj:`ui_window_class_type "
#~ "<isaaclab_mimic.envs.FrankaCubeStackIKRelMimicEnvCfg.ui_window_class_type>`\\"
#~ msgstr ""

#~ msgid ""
#~ ":py:class:`~isaaclab.envs.ui.manager_based_rl_env_window.ManagerBasedRLEnvWindow`"
#~ " 的别名"
#~ msgstr ""

#~ msgid ""
#~ ":py:obj:`viewer "
#~ "<isaaclab_mimic.envs.FrankaCubeStackIKRelMimicEnvCfg.viewer>`\\"
#~ msgstr ""

#~ msgid "Viewer configuration."
#~ msgstr ""

#~ msgid ""
#~ ":py:obj:`sim "
#~ "<isaaclab_mimic.envs.FrankaCubeStackIKRelMimicEnvCfg.sim>`\\"
#~ msgstr ""

#~ msgid "Physics simulation configuration."
#~ msgstr ""

#~ msgid ""
#~ ":py:obj:`seed "
#~ "<isaaclab_mimic.envs.FrankaCubeStackIKRelMimicEnvCfg.seed>`\\"
#~ msgstr ""

#~ msgid "The seed for the random number generator."
#~ msgstr ""

#~ msgid ""
#~ ":py:obj:`decimation "
#~ "<isaaclab_mimic.envs.FrankaCubeStackIKRelMimicEnvCfg.decimation>`\\"
#~ msgstr ""

#~ msgid "Number of control action updates @ sim dt per policy dt."
#~ msgstr ""

#~ msgid ""
#~ ":py:obj:`scene "
#~ "<isaaclab_mimic.envs.FrankaCubeStackIKRelMimicEnvCfg.scene>`\\"
#~ msgstr ""

#~ msgid "Scene settings."
#~ msgstr ""

#~ msgid ""
#~ ":py:obj:`recorders "
#~ "<isaaclab_mimic.envs.FrankaCubeStackIKRelMimicEnvCfg.recorders>`\\"
#~ msgstr ""

#~ msgid "Recorder settings."
#~ msgstr ""

#~ msgid ""
#~ ":py:obj:`observations "
#~ "<isaaclab_mimic.envs.FrankaCubeStackIKRelMimicEnvCfg.observations>`\\"
#~ msgstr ""

#~ msgid "Observation space settings."
#~ msgstr ""

#~ msgid ""
#~ ":py:obj:`actions "
#~ "<isaaclab_mimic.envs.FrankaCubeStackIKRelMimicEnvCfg.actions>`\\"
#~ msgstr ""

#~ msgid "Action space settings."
#~ msgstr ""

#~ msgid ""
#~ ":py:obj:`events "
#~ "<isaaclab_mimic.envs.FrankaCubeStackIKRelMimicEnvCfg.events>`\\"
#~ msgstr ""

#~ msgid "Event settings."
#~ msgstr ""

#~ msgid ""
#~ ":py:obj:`rerender_on_reset "
#~ "<isaaclab_mimic.envs.FrankaCubeStackIKRelMimicEnvCfg.rerender_on_reset>`\\"
#~ msgstr ""

#~ msgid ""
#~ "Whether a render step is performed "
#~ "again after at least one environment "
#~ "has been reset."
#~ msgstr ""

#~ msgid ""
#~ ":py:obj:`wait_for_textures "
#~ "<isaaclab_mimic.envs.FrankaCubeStackIKRelMimicEnvCfg.wait_for_textures>`\\"
#~ msgstr ""

#~ msgid "True to wait for assets to be loaded completely, False otherwise."
#~ msgstr ""

#~ msgid ""
#~ ":py:obj:`is_finite_horizon "
#~ "<isaaclab_mimic.envs.FrankaCubeStackIKRelMimicEnvCfg.is_finite_horizon>`\\"
#~ msgstr ""

#~ msgid ""
#~ "Whether the learning task is treated "
#~ "as a finite or infinite horizon "
#~ "problem for the agent."
#~ msgstr ""

#~ msgid ""
#~ ":py:obj:`episode_length_s "
#~ "<isaaclab_mimic.envs.FrankaCubeStackIKRelMimicEnvCfg.episode_length_s>`\\"
#~ msgstr ""

#~ msgid "Duration of an episode (in seconds)."
#~ msgstr ""

#~ msgid ""
#~ ":py:obj:`rewards "
#~ "<isaaclab_mimic.envs.FrankaCubeStackIKRelMimicEnvCfg.rewards>`\\"
#~ msgstr ""

#~ msgid "Reward settings."
#~ msgstr ""

#~ msgid ""
#~ ":py:obj:`terminations "
#~ "<isaaclab_mimic.envs.FrankaCubeStackIKRelMimicEnvCfg.terminations>`\\"
#~ msgstr ""

#~ msgid "Termination settings."
#~ msgstr ""

#~ msgid ""
#~ ":py:obj:`curriculum "
#~ "<isaaclab_mimic.envs.FrankaCubeStackIKRelMimicEnvCfg.curriculum>`\\"
#~ msgstr ""

#~ msgid "Curriculum settings."
#~ msgstr ""

#~ msgid ""
#~ ":py:obj:`commands "
#~ "<isaaclab_mimic.envs.FrankaCubeStackIKRelMimicEnvCfg.commands>`\\"
#~ msgstr ""

#~ msgid "Command settings."
#~ msgstr ""

#~ msgid "Viewer configuration. Default is ViewerCfg()."
#~ msgstr ""

#~ msgid "Physics simulation configuration. Default is SimulationCfg()."
#~ msgstr ""

#~ msgid ""
#~ "The seed for the random number "
#~ "generator. Defaults to None, in which"
#~ " case the seed is not set."
#~ msgstr ""

#~ msgid ""
#~ "The seed is set at the beginning"
#~ " of the environment initialization. This"
#~ " ensures that the environment creation "
#~ "is deterministic and behaves similarly "
#~ "across different runs."
#~ msgstr ""

#~ msgid ""
#~ "For instance, if the simulation dt "
#~ "is 0.01s and the policy dt is "
#~ "0.1s, then the decimation is 10. "
#~ "This means that the control action "
#~ "is updated every 10 simulation steps."
#~ msgstr ""

#~ msgid ""
#~ "Please refer to the "
#~ ":class:`isaaclab.scene.InteractiveSceneCfg` class for "
#~ "more details."
#~ msgstr ""

#~ msgid "Recorder settings. Defaults to recording nothing."
#~ msgstr ""

#~ msgid ""
#~ "Please refer to the "
#~ ":class:`isaaclab.managers.RecorderManager` class for "
#~ "more details."
#~ msgstr ""

#~ msgid ""
#~ "Please refer to the "
#~ ":class:`isaaclab.managers.ObservationManager` class for"
#~ " more details."
#~ msgstr ""

#~ msgid ""
#~ "Please refer to the "
#~ ":class:`isaaclab.managers.ActionManager` class for "
#~ "more details."
#~ msgstr ""

#~ msgid ""
#~ "Event settings. Defaults to the basic"
#~ " configuration that resets the scene "
#~ "to its default state."
#~ msgstr ""

#~ msgid ""
#~ "Please refer to the "
#~ ":class:`isaaclab.managers.EventManager` class for "
#~ "more details."
#~ msgstr ""

#~ msgid ""
#~ "Whether a render step is performed "
#~ "again after at least one environment "
#~ "has been reset. Defaults to False, "
#~ "which means no render step will be"
#~ " performed after reset."
#~ msgstr ""

#~ msgid ""
#~ "When this is False, data collected "
#~ "from sensors after performing reset will"
#~ " be stale and will not reflect "
#~ "the latest states in simulation caused"
#~ " by the reset."
#~ msgstr ""

#~ msgid ""
#~ "When this is True, an extra render"
#~ " step will be performed to update "
#~ "the sensor data to reflect the "
#~ "latest states from the reset. This "
#~ "comes at a cost of performance as"
#~ " an additional render step will be"
#~ " performed after each time an "
#~ "environment is reset."
#~ msgstr ""

#~ msgid ""
#~ "True to wait for assets to be "
#~ "loaded completely, False otherwise. Defaults"
#~ " to True."
#~ msgstr ""

#~ msgid ""
#~ "Whether the learning task is treated "
#~ "as a finite or infinite horizon "
#~ "problem for the agent. Defaults to "
#~ "False, which means the task is "
#~ "treated as an infinite horizon problem."
#~ msgstr ""

#~ msgid "This flag handles the subtleties of finite and infinite horizon tasks:"
#~ msgstr ""

#~ msgid ""
#~ "**Finite horizon**: no penalty or "
#~ "bootstrapping value is required by the"
#~ " the agent for running out of "
#~ "time. However, the environment still "
#~ "needs to terminate the episode after "
#~ "the time limit is reached."
#~ msgstr ""

#~ msgid ""
#~ "**Infinite horizon**: the agent needs to"
#~ " bootstrap the value of the state "
#~ "at the end of the episode. This"
#~ " is done by sending a time-"
#~ "limit (or truncated) done signal to "
#~ "the agent, which triggers this "
#~ "bootstrapping calculation."
#~ msgstr ""

#~ msgid ""
#~ "If True, then the environment is "
#~ "treated as a finite horizon problem "
#~ "and no time-out (or truncated) "
#~ "done signal is sent to the agent."
#~ " If False, then the environment is"
#~ " treated as an infinite horizon "
#~ "problem and a time-out (or "
#~ "truncated) done signal is sent to "
#~ "the agent."
#~ msgstr ""

#~ msgid ""
#~ "The base :class:`ManagerBasedRLEnv` class does"
#~ " not use this flag directly. It "
#~ "is used by the environment wrappers "
#~ "to determine what type of done "
#~ "signal to send to the corresponding "
#~ "learning agent."
#~ msgstr ""

#~ msgid ""
#~ "Based on the decimation rate and "
#~ "physics time step, the episode length"
#~ " is calculated as:"
#~ msgstr ""

#~ msgid ""
#~ "For example, if the decimation rate "
#~ "is 10, the physics time step is"
#~ " 0.01, and the episode length is "
#~ "10 seconds, then the episode length "
#~ "in steps is 100."
#~ msgstr ""

#~ msgid ""
#~ "Please refer to the "
#~ ":class:`isaaclab.managers.RewardManager` class for "
#~ "more details."
#~ msgstr ""

#~ msgid ""
#~ "Please refer to the "
#~ ":class:`isaaclab.managers.TerminationManager` class for"
#~ " more details."
#~ msgstr ""

#~ msgid ""
#~ "Curriculum settings. Defaults to None, "
#~ "in which case no curriculum is "
#~ "applied."
#~ msgstr ""

#~ msgid ""
#~ "Please refer to the "
#~ ":class:`isaaclab.managers.CurriculumManager` class for "
#~ "more details."
#~ msgstr ""

#~ msgid ""
#~ "Command settings. Defaults to None, in"
#~ " which case no commands are "
#~ "generated."
#~ msgstr ""

#~ msgid ""
#~ "Please refer to the "
#~ ":class:`isaaclab.managers.CommandManager` class for "
#~ "more details."
#~ msgstr ""

